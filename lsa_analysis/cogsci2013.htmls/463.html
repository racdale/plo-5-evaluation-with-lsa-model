<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">

<HTML>

<HEAD>
  <LINK rel=stylesheet HREF="../../style/style.css">
  <TITLE></TITLE>
</HEAD>

<BODY>

  <div id=pageheader>
    <div id=logo><a href="http://cognitivesciencesociety.org/conference2013/index.html"><img src="../../style/logo.png" title="CogSci 2013 logo" alt="CogSci 2013 logo"></a></div>
    <div id=title></div>
    <br clear=both>
    <div id=menubar>
      <ul>
	<li><a href="../../index.html">Table of Contents</a>
      </ul>
    </div>
  </div>

  <div id=pagebody>

    

	<h1>Here&#8217;s not looking at you, kid! Unaddressed recipients benefit from co-speech gestures when speech processing suffers</h1>

    
	  <ul>
    	    <li>Judith Holler, <em>Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands</em>
    	    <li>Louise Schubotz, <em>Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands</em>
    	    <li>Spencer Kelly, <em>Colgate University, Hamilton, NY, USA</em>
    	    <li>Peter Hagoort, <em>Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands</em>
    	    <li>Manuela  Schuetze, <em>Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands</em>
    	    <li>Asli Ozyurek, <em>Radboud University Nijmegen</em>
                    	  </ul>

    

	<h2>Abstract</h2>

          <p id=abstract>In human face-to-face communication, language comprehension is a
      multi-modal, situated activity. However, little is known about how we combine
      information from these different modalities, and how perceived communicative
      intentions, often signaled through visual signals, such as eye gaze, may
      influence this processing. We address this question by simulating a triadic
      communication context in which a speaker alternated her gaze between two
      different recipients. Participants thus viewed speech-only or speech+gesture
      object-related utterances when being addressed (direct gaze) or unaddressed
      (averted gaze). Two object images followed each message and participants&#8217;
      task was to choose the object that matched the message. Unaddressed recipients
      responded significantly slower than addressees for speech-only utterances.
      However, perceiving the same speech accompanied by gestures sped them up to a
      level identical to that of addressees. That is, when speech processing suffers
      due to not being addressed, gesture processing remains intact and enhances the
      comprehension of a speaker&#8217;s message. </p>

    





	  <ul>


	    <li id=files>The Paper: <a href="paper0463.pdf">Here&#8217;s not looking at you, kid! Unaddressed recipients benefit from co-speech gestures when speech processing suffers</a>


	  </ul>

	<p><br><a href="../../index.html">Back to Table of Contents</a>

  </div>

  <div id=pagefooter>
  </div>

</BODY>
</HTML>

