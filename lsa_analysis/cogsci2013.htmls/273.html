<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">

<HTML>

<HEAD>
  <LINK rel=stylesheet HREF="../../style/style.css">
  <TITLE></TITLE>
</HEAD>

<BODY>

  <div id=pageheader>
    <div id=logo><a href="http://cognitivesciencesociety.org/conference2013/index.html"><img src="../../style/logo.png" title="CogSci 2013 logo" alt="CogSci 2013 logo"></a></div>
    <div id=title></div>
    <br clear=both>
    <div id=menubar>
      <ul>
	<li><a href="../../index.html">Table of Contents</a>
      </ul>
    </div>
  </div>

  <div id=pagebody>

    

	<h1>Is Lexical Access Driven by Temporal Order or Perceptual Salience? Evidence from  British Sign Language</h1>

    
	  <ul>
    	    <li>Robin L. Thompson, <em>Deafness, Cognition and Language Research Centre, Department of Cognitive, Perceptual and Brain Sciences  University College London</em>
    	    <li>David P. Vinson, <em>Department of Cognitive, Perceptual and Brain Sciences  University College London</em>
    	    <li>Neil Fox, <em>Department of Cognitive, Perceptual and Brain Sciences  University College London</em>
    	    <li>Gabriella Vigliocco, <em>Deafness, Cognition and Language Research Centre, Department of Cognitive, Perceptual and Brain Sciences  University College London</em>
                            	  </ul>

    

	<h2>Abstract</h2>

          <p id=abstract>While processing spoken language, people look towards relevant
      objects, and the time course of their gaze(s) can inform us about online language
      processing (Tanenhaus et al, 1995). Here, we investigate lexical recognition in
      British Sign Language (BSL) using a visual world paradigm, the first such study
      using a signed language.  Comprehension of spoken words and signs could be driven
      by temporal constraints regardless of modality (&#8220;first in, first
      processed&#8221;), or by perceptual salience which differs for speech
      (auditorialy perceived) and sign (visually perceived). Deaf BSL signers looked
      more often to semantically related distracter pictures than to unrelated
      pictures, replicating studies using acoustically-presented speech. For
      phonologically related pictures, gaze increased only for those sharing visually
      salient phonological features (i.e., location and movement features). Results are
      discussed in the context of language processing in different modalities. Overall,
      we conclude that lexical processing for both speech and sign is likely driven by
      perceptual salience and that potential differences in processing emerge from
      differences between visual and auditory systems.</p>

    





	  <ul>


	    <li id=files>The Paper: <a href="paper0273.pdf">Is Lexical Access Driven by Temporal Order or Perceptual Salience? Evidence from  British Sign Language</a>


	  </ul>

	<p><br><a href="../../index.html">Back to Table of Contents</a>

  </div>

  <div id=pagefooter>
  </div>

</BODY>
</HTML>

