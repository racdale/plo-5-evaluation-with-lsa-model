<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">

<HTML>

<HEAD>
  <LINK rel=stylesheet HREF="../../style/style.css">
  <TITLE></TITLE>
</HEAD>

<BODY>

  <div id=pageheader>
    <div id=logo><a href="http://cognitivesciencesociety.org/conference2013/index.html"><img src="../../style/logo.png" title="CogSci 2013 logo" alt="CogSci 2013 logo"></a></div>
    <div id=title></div>
    <br clear=both>
    <div id=menubar>
      <ul>
	<li><a href="../../index.html">Table of Contents</a>
      </ul>
    </div>
  </div>

  <div id=pagebody>

    

	<h1>A soft barrier model for predicting human visuomotor behavior in a driving task</h1>

    
	  <ul>
    	    <li>Leif Johnson, <em>The University of Texas at Austin, Austin, TX, USA</em>
    	    <li>Brian Sullivan, <em>Smith-Kettlewell Eye Research Institute, San Francisco, CA, USA</em>
    	    <li>Mary Hayhoe, <em>The University of Texas at Austin, Austin, TX, USA</em>
    	    <li>Dana Ballard, <em>The University of Texas at Austin, Austin, TX, USA</em>
                            	  </ul>

    

	<h2>Abstract</h2>

          <p id=abstract>We present a task-based model of human gaze allocation in a
      driving environment. When engaged in natural tasks, gaze is predominantly
      directed towards task relevant objects. In particular in a multi-task scenario
      such as driving, human drivers must access multiple perceptual cues that can be
      used for effective control. Our model uses visual task modules that require
      multiple independent sources of information for control, analogous to human
      foveation on different task-relevant objects. Building on the framework described
      by Sprague and Ballard (2003), we use a modular structure to feed information to
      a set of PID controllers that drive a simulated car and introduce a barrier model
      for gaze selection. The softmax barrier model uses performance thresholds to
      represent task importance across modules and allows noise to be added to any
      module to represent task uncertainty. Results from the model compare favorably
      with human gaze data gathered from subjects driving in a virtual environment.</p>

    





	  <ul>


	    <li id=files>The Paper: <a href="paper0145.pdf">A soft barrier model for predicting human visuomotor behavior in a driving task</a>


	  </ul>

	<p><br><a href="../../index.html">Back to Table of Contents</a>

  </div>

  <div id=pagefooter>
  </div>

</BODY>
</HTML>

