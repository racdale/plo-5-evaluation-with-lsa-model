<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">

<HTML>

<HEAD>
  <LINK rel=stylesheet HREF="../../style/style.css">
  <TITLE></TITLE>
</HEAD>

<BODY>

  <div id=pageheader>
    <div id=logo><a href="http://cognitivesciencesociety.org/conference2013/index.html"><img src="../../style/logo.png" title="CogSci 2013 logo" alt="CogSci 2013 logo"></a></div>
    <div id=title></div>
    <br clear=both>
    <div id=menubar>
      <ul>
	<li><a href="../../index.html">Table of Contents</a>
      </ul>
    </div>
  </div>

  <div id=pagebody>

    

	<h1>Learning hierarchical categories in deep neural networks</h1>

    
	  <ul>
    	    <li>Andrew M. Saxe, <em>Stanford University</em>
    	    <li>James L. McClelland, <em>Stanford University</em>
    	    <li>Surya Ganguli, <em>Stanford University</em>
                                	  </ul>

    

	<h2>Abstract</h2>

          <p id=abstract>Psychological experiments have revealed remarkable regularities in
      the developmental time course of cognition. Infants generally acquire broad
      categorical distinctions (i.e., plant/animal) before finer ones (i.e.,
      bird/fish), and periods of little change are often punctuated by stage-like
      transitions. This pattern of progressive differentiation has also been seen in
      neural network models as they learn from exposure to training data.  Our work
      explains why the networks exhibit these phenomena. We find solutions to the
      dynamics of error-correcting learning in linear three layer neural networks.
      These solutions link the statistics of the training set and the dynamics of
      learning in the network, and characterize formally how learning leads to the
      emergence of structured representations for arbitrary training environments. We
      then consider training a neural network on data generated by a hierarchically
      structured probabilistic generative process. Our results reveal that, for a broad
      class of such structures, the learning dynamics must exhibit progressive,
      coarse-to-fine differentiation with stage-like transitions punctuating longer
      dormant periods.</p>

    





	  <ul>


	    <li id=files>The Paper: <a href="paper0243.pdf">Learning hierarchical categories in deep neural networks</a>


	  </ul>

	<p><br><a href="../../index.html">Back to Table of Contents</a>

  </div>

  <div id=pagefooter>
  </div>

</BODY>
</HTML>

