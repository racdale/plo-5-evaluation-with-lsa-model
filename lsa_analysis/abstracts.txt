external representations of thought—maps, diagrams,       sketches, and the like—are ancient inventions that serve thought and       communication in numerous ways. a number of cognitive scientists have       investigated roles these representations play in cognition (see, e.g., donald,       1991; larkin & simon, 1987; norman, 1993; schön, 1983). they are created and       used by school students, by architects and designers, by mathematicians and       scientists, by musicians, dancers, and artists. people design and use diagrams to       spatialize thought and make it public, to work through ideas and clarify       thinking, to reduce working memory load, to communicate ideas to others, to       promote collaborative work by providing an external representation that can be       pointed to and animated by gestures and collectively revised. considerable       research has shown that well-designed diagrams promote thought, creativity,       discovery, and communication. diagrams can map abstract thought to space,       allowing spatial reasoning to promote abstract reasoning. 
this half-day workshop will demonstrate how to build custom       web-based experiments that rely on participants from amazon mechanical turk       (amt). attendees will learn how to deploy web-based experiments using psiturk, a       python-based platform that simplifies the process of setting up experiments and       interacting with amt. no prior knowledge about amt is necessary, but participants       are encouraged to download and set up the psiturk platform before attending the       workshop if they would like to follow along during the demonstration. the       workshop will also discuss the benefits and drawbacks of running experiments       online and address concerns about the quality of data obtained via amt or other       web-based services.       
interpersonal interaction, especially in face-to-face       circumstances, requires coordination (clark, 1996). this involves many subtle       behaviors, controlled carefully in the context of another person, from eye       movements and gestures, to choice of words and beyond. several new directions       have pursued this microstructure of interpersonal interaction. first, with       advances in sensing and computing techniques, we have the capability to process       visual, audio and other sensory data collected from real-world interactions.       second, researchers in developmental robotics have investigated mechanisms of       interpersonal coordination, to model and implement social systems. third,       research on virtual agents has developed new models of embodied human-agent       interaction. together these strands of research offer new insight into human       social dynamics, and the means to implement and test theories in robotics and       virtual agents. bringing them together in one workshop is an opportunity to       convey these new methods, and find shared interests and synergies among different       approaches and different fields.
the goal of women in cognitive science (wics) is to increase       attention to the situation of women cognitive scientists, to better understand       the reasons for existing problems of under representation in key positions, and       to provide a forum for professional development that encourages both junior and       senior male and female scientists to consider the ways in which they might work       with their own home institutions to effect change.       the css 2013 interactive panel discussion will bring together american and       european researchers in cognitive science to discuss national and international       collaborations as a tool toward professional advancement and visibility and why       this is important to one's career development. invited speakers include r. harald       baayen (eberhard karls university, tübingen), melody dye (indiana       university, bloomington), pernille hemmer (rutgers university), lael schooler       (max planck institute for human development, berlin), anne warlaumont,       (university, of california, merced). speakers will describe and contrast varied       ways to initiate and goals for international and virtual collaborations. *laurie       feldman will serve as moderator.       
reference is a key mechanism in human communication which has long       been studied in different areas of cognitive science. the pre-cogsci 2013       workshop, which focusses on the production/generation of referring expressions,       follows in the footsteps of two earlier cogsci workshops in seeking to forge       closer links between the approaches that are associated with the different       disciplines, with special attention to psycholinguistics and computational       linguistics.  peer-reviewed contributions on all aspects of the       production/generation of referring expressions are solicited. special themes of       the workshop will include: (1) collaborative reference, (2) nondeterminism in       production, (3) interaction between comprehension and production, and (4)       combinations with research in vision. there will be invited presentations by herb       clark and by noah goodman.
there has been tremendous growth recently in theories that attempt       to provide more comprehensive accounts of the foundational mechanisms of human       cognition. such theories have taken a variety of forms, and have focused on       different levels of analysis. the diversity is important and necessary, but can       serve as a barrier to interaction, comparison, and integration, even at venues       like the annual meeting of the cognitive science society that should foster such       dialogue. this workshop is intended to bring together individuals working on       integrative models of human cognition, to emphasize shared motivations and goals.       ultimately, building scientific communities that bridge levels of analysis,       methodologies, and theoretical approaches to work toward more comprehensive       theories will be critical to the addressing the central goal of the cognitive       science society – understanding the nature of the human mind.
deception can be advantageous to a deceiver when the truth       conflicts with his or her goals - be they personal or social, selfless or       selfish. thus it is that people regularly use deception to avoid conflict with       others, to avoid punishment or embarrassment, to fit into a group, to harm,       protect or help others, and for material or non-material benefit to themselves.       while there are many ways in which people can deceive, for example, by choosing       to fabricate rather than to tell a half-truth, there are always cost-benefit       trade-offs,       regardless of the strategy a person chooses. understanding why people deceive in       everyday life situations, how they do it, why they choose one strategy over       another, and why sometimes they might choose not to deceive at all, even in       the absence of any serious anticipated cost, will enable us to build richer       models of socially intelligent behavior--models that could be employed in       computational systems designed to facilitate enterprises such as elder care,       tutoring, and professional training. in this workshop, we aim to address       three basic questions: (1) what factors lead people to deceive? (2) what makes       them decide to deceive one way rather than another? and (3) how can we model       these factors computationally?
this is a workshop proposal.
gaze behavior provides fundamental mechanisms for sharing mental       states       such as goals and desires and helps to ground communicative content.       responding to or leading someone's gaze to a location or an object of       interest thus may result in a situation of joint attention -- a       referential triad between two individuals and an entity in the       environment. since people often look at what they attend to and where       they intend to act, joint attention is considered fundamental to an       understanding of other minds and the interaction with them.       this workshop aims to explore how traditionally separate research areas       such as social cognition/neuroscience, psycholinguistics, human-computer       interaction and developmental psychology contribute to an understanding       of the general phenomenon of gaze-following and joint attention from       different perspectives -- and how these fields can benefit and learn       from each other, e.g. by comparing different approaches and methodologies. 
the general format of the tutorial will be a half-day introduction       to research in the field of complex network analysis followed by a more detailed       study of a specific research project on language acquisition. in the course of       the more detailed study participants will have an opportunity to perform some       statistical and hypothesis testing on networks while learning interpretations and       meaning of network analysis techniques.
we have recently created the world's largest biologically       realistic brain model that is capable of performing tasks (eliasmith et al.,       2012). this model uses 2.5 million spiking neurons, takes visual input from a       28x28 pixel visual field, and controls a physically modelled arm. by presenting       different visual inputs, the model can perform eight different tasks, including       memorizing and writing a list of numbers, single-digit addition via counting, and       flexible pattern completion in the raven's matrices task. this tutorial is meant       to introduce the software toolkit and theoretical background that would allow       other researchers to build their own models using the same architecture, allowing       them to explore other tasks and brain functions. this tool supports a novel       cognitive architecture (spa; the semantic pointer architecture) that directly       connects neuroscience with cognitive science.       
virtual humans (vhs) are digital anthropomorphic characters       that exist within virtual worlds but are designed to perceive,       understand and interact with real-world humans. although       typically conceived as practical tools to assist in a       range of application (e.g., hci, training and entertainment),       the technology is gaining interest as a methodological tool       for studying human cognition. vhs not only simulate the       cognitive abilities of people, but also many of the embodied       and social aspects of human behavior more traditionally       studied in fields outside of cognitive science. by integrating       multiple cognitive capabilities (e.g., language, gesture, emotion,       and the control problems associated with navigating       and interacting with a simulated virtual world) and requiring       these processes to support real-time interactions with people,       vhs create a unique and challenging environment within       which to develop and validate cognitive theories. in this       tutorial, we will review recent advances in vh technologies,       demonstrate examples of use of vhs in cognitive science       research and provide hands on training using our virtual       human toolkit (http://vhtoolkit.ict.usc.edu/).
fast and frugal trees (ffts) are a quintessential family of simple       heuristics that allow effective and efficient binary classification decisions and       often perform remarkably well when compared to more complex methods.  this       half-day tutorial will familiarize participants with examples of ffts and       elucidate the theoretical link between ffts and signal detection theory (sdt).  a       range of presentations, practical exercises and interactive tools will enable       participants to construct and evaluate ffts for different data sets.        keywords: fast and frugal trees; binary classifications; simple heuristics;       signal detection theory; validity; robustness 
this tutorial introduces why and how to build cognitive models       using quantum probability (qp) theory. in the tutorial, we will show that qp is       inherently consistent with deeply rooted psychological conceptions and       intuitions. it offers a fresh conceptual framework for explaining some puzzling       empirical findings of cognition, and provides a rich new source of alternative       formal tools, compared to classical probability (cp) theory, for cognitive       modeling. 
the objective of this tutorial is to provide participants with an       accessible introduction to mixture models (mms) and hidden markov models (hmms)       and the necessary skills to apply them in their own research. these models are       particularly useful to analyse aspects of cognition which are best understood in       terms of discrete types and states (e.g., when people are expected to apply       distinct strategies when performing a task). mms and hmms allow one to extract       such types/states even when they are not known exactly beforehand. we will       provide an intuitive introduction to the underlying theory of mms and hmms and       will show how to apply the models in practice using freely available software.       throughout the tutorial, the techniques are illustrated with real data relevant       to a cognitive science audience. participants are encouraged to bring their       laptop to follow the examples and apply the techniques to their own data. 
dynamical field theory (dft) offers a framework for thinking about       representation-in-the-moment in neural systems and changes in thinking over       learning and development. dynamic neural fields are formalizations of how neural       populations represent the continuous dimensions that characterize perceptual       features, movements, and cognitive decisions. dft has been used across a variety       of contexts including studies of working memory, word learning, executive       function, and autonomous robotics. one obstacle for researchers wishing to use       dft has been that the mathematical and technical skills required to make these       concepts operational are not part of the standard repertoire of cognitive       scientists. the goal of this tutorial is to provide the training and tools to       overcome this obstacle. we will provide a systematic introduction to the central       concepts of dft and their grounding in both dynamical systems concepts and       neurophysiology. we will provide all needed background and give participants       hands-on experience using interactive simulators in matlab. 
this tutorial will support researchers who consider using, or have       already collected, verbal protocols as data. after discussing the extent to which       language can be useful to identify cognitive processes and principles, we will       examine each step of the process from data collection via transcription,       analysis, and triangulation. the main emphasis will lie on the systematic       analysis of linguistic choices, aiming to identify indicators for specific       cognitive phenomena that are of interest for the research purpose at hand.       participants are encouraged to contribute actively to this tutorial by bringing       ideas and samples from their own research, pertaining to each step of the       research process. email-based communication in advance of the tutorial will       ensure a lively and highly interactive tutorial, supporting ongoing research in a       practical way rather than theorizing about potential benefits.
many computational- or rational-level models of cognition       postulate computations that appear to be computationally intractable (e.g.,       np-hard or worse). formally, this means that the postulated computations consume       an exponential amount of time. informally, this means that the postulated       computations do not scale in any obvious way to explain how the modeled cognitive       capacities can operate in the real world outside the lab. this problem of       intractability is quite common in cognitive science. it is observed in       practically all domains of cognition, including, for instance, perception,       language, reasoning, categorization, decision-making, and motor planning. it is       also not specific to any particular class of models, as it can arise for       symbolic, connectionist, probabilistic (e.g. bayesian), dynamical, logic-based,       and even heuristic models of cognition.
joint action is an increasingly popular topic in cognitive       science. this popularity reflects a recent theoretical trend of postulating, in       one way or another, that human perception, action, and cognition are geared to       enable successful coordination and communica¬tion with others. the speakers       in the symposium will provide an overview of current progress in joint action       research. their contributions will address a wide range of phenomena ranging from       tight temporal coordination to shared planning and discourse processes. together,       the contributions will illustrate that social constraints affect cognitive       processing in a deeper sense than the more traditional notion of specific modules       for social perception and social reasoning would suggest.
in humans, gestural communication is closely intertwined with       language: adults perform a variety of manual gestures, head movements and body       postures while they are talking, children use gestures before they start to       speak, and highly conventionalized sign systems can even replace spoken language.       because of this role of gestures for human com-munication, theories of language       evolution often propose a gestural origin of language. in searching for the       evolutionary roots of language, a comparative approach is often used to       investigate whether any precursors to human language are also present in our       closest relatives, the great apes, because of our shared phylogenetic history.       therefore, the aim of this symposium is to present recent progress in the field       of language evolution from both a developmental and compa-rative perspective and       to discuss the question if and to what extent a comparison with nonhuman primates       is suitable to shed light on possible scenarios of language evolution.
the nature and extent of human rationality is an issue of ongoing       debate. in the last two decades, this debate has been enlivened by the       development and application of new theoretical frameworks. these include bayesian       notions of adjusting and using uncertain beliefs in an inductive manner as well       as deductive probability-based logics as normative guidelines against which to       weigh human judgments and decisions; the notion of ecological rationality based       on lean and frugal heuristics well adapted to the structure of the environment;       the notion of meta-cognitive myopia according to which people are accurate and       sensitive in the processing the information in a given sample of observations,       but are blind and naive to the history and validity of the sampled data; and game       theory.
traditional views of cognition, cognitive development, and word       learning have viewed knowledge as divorced from processes of perceiving and       acting. linda smith has championed a dynamic, mechanistic, and processoriented       view of cognition and focused on questions of development. she has shown how       knowledge is embedded in, distributed across, and inseparable from the processes       of perceiving and acting in the world. in so doing, she has enabled a new       understanding of the nature of cognition and of how new ways of thinking come to       be. this rumelhart symposium in her honor illustrates how this focus on       developmental process changes the questions asked and our resulting understanding       of cognition. the five speakers will examine the developmental process of word       learning from different vantage points ranging from perceptual to social to       cognitive, and spanning multiple periods from the first words to rapid vocabulary       growth to the building of semantic networks.
the annual glushko dissertation prize in cognitive       science was established in 2011 as a way to promote future       growth in cognitive science, and encourage students to       engage in interdisciplinary efforts to understand minds. the       prize is jointly sponsored by the cognitive science society       and the robert j. glushko and pamela samuelson foundation,       and honors young researchers conducting ground       breaking research in cognitive science. the immediate goal       is to recognize outstanding efforts to bridge between the       areas that impinge on cognitive science and create theories       of general interest to the multiple fields concerned with       scientifically understanding the nature of minds and       intelligent systems. encouraging junior researchers to       engage in these enterprises is one of the best ways to assure       a robust future for cognitive science. the overarching goal       is to promote a unified cognitive science, consistent with the       belief that understanding how minds work will require the       synthesis of many different empirical methods, formal tools,       and analytic theories.       this symposium showcases the phd research projects       of the 2013 winners of the glushko dissertation prizes.       2013 marks the first year that a symposium has been formed       to assemble and showcase glushko prize winners’ research.       the prize-winning projects involve research on linguistic       compositionality, understanding pictorial narratives, learning       object-to-name mappings from complex environments,       spatial problem solving, and visual awareness. the recruited       research methods include neuroimaging, computational       modeling, formal linguistic modeling, corpus analysis,       psychological experiments, and theoretical analysis. taken       as a whole, the research projects strongly reinforces the       view that contemporary cognitive science research is highly       diverse, rigorous, creative, and fertile.
the nature of intentions is a perpetual locus of interest for       investigators of the human mind. both occidental and oriental philosophical       traditions treat intentions as the root of behavior; and many possible       classifications have been offered in order to try to systematize the different       types of intention. moreover, recognition of intentions in others appears to be       central to child development, and necessary for becoming a competent member of       the society.        recent work in the social neurosciences has focused, in particular, on social       intentions, which may underpin the human predisposition toward joint,       collaborative behavior. communicative intentions are particularly central, yet       have a puzzling recursive form.
since the cognitive revolution, a widely held assumption has       been that—whereas content may vary across cultures—cognitive       processes would be universal, especially those on the       more basic levels. even if scholars do not fully subscribe to       this assumption, they often conceptualize, or tend to investigate,       cognition as if it were universal (henrich, heine, &       norenzayan, 2010). the insight that universality must not be       presupposed but scrutinized is now gaining ground, and cognitive       diversity has become one of the hot (and controversial)       topics in the field (norenzayan & heine, 2005). we argue       that, for scrutinizing the cultural dimension of cognition,       taking an anthropological perspective is invaluable, not only       for the task itself, but for attenuating the home-field disadvantages       that are inescapably linked to cross-cultural research       (medin, bennis, & chandler, 2010).
counterfactual thinking, where one envisions alternative pos-       sible events and their outcomes, is hypothesized to be one of the primary ways in       which we reason about causal relation- ships (e.g., pearl, 2000; woodward, 2003).       recent compu- tational and experimental work suggests that both adults and       children may reason about causality in a manner consistent with probabilistic       graphical models – coherent, complex rep- resentations of causal structure       that allow distinctive kinds of inferences (e.g., gopnik et al., 2004; griffiths       & tenenbaum, 2009). in particular, the causal models approach supports and       distinguishes two types of inferences, predictions, on the one hand, and       interventions, including counterfactual inter- ventions, on the other. in       predictions, we take what we think is true now as a premise and then use the       model to calculate what else will be true. in counterfactuals, we take some value       of the model that we currently think is not true as a premise, and calculate what       would follow if it were.
the
sequential sampling models have been applied for describing the       cognitive processes underlying various psychological processes such as memory,       perception, or value-based decision making. they share the common assuming that       people accumulate information stochastically over time and once the accumulated       information passes a decision boundary a response is made. depending on the       cognitive domain the models differ in the specific nature of the accumulation       process. in particular, they differ in their assumption about what type of       information is processed, how the information is represented, and how the       boundary is defined.
many grammatical frameworks view words and rules as the basic       building blocks of language, with multiword sequences being treated as peripheral       exceptions in the form of idioms, etc.. the new millennium, however, has seen a       shift toward construing multiword sequences not as linguistic rarities but as       important building blocks for language acquisition and processing. based on a       growing bulk of evidence of sensitivity to multiword sequences in language       learning and use, multiword sequences have come to figure prominently in many       current approaches to language, including item-based learning, formulaic       language, usage-based language processing, and chunk-based learning. this       symposium brings together experts from these different approaches to language to       explore the idea that first and second language learners differ with respect to       their ability to use multiword building blocks to learn and process language, and       that this difference affects learning strategies and outcomes.
remembering frequently involves collaboration among two or more       individuals, often taking the form of a conversation.  in some conversations, one       person conveys new information to another, as when a daughter announces to her       mother that she is engaged.  in other conversations, two people talk to each       other about a shared past, as when a couple reminisce about the evening on which       they became engaged.   the later instance has the potential to shape both what       emerges in the discussion, as when one participant scaffolds the remembering of       the other.  it also has the potential to reshape how participants might       subsequently remember the material, with the possibility that the memories of the       participants will become more similar.  in other words, what people remember is,       in part, the result of how they jointly recount the past with others.  yet,       despite the critical contribution of joint conversational remembering to memory,       detailed study of this phenomenon is only beginning to be undertaken.  the       objective of this symposium is to bring together several strands of research that       explores conversational, or, more generally, communicative influences on memory.        the speakers offer a range of different approaches.  dr. stone explores how       public speeches can induce forgetting as well as reinforce memories across a       large population and thereby promote a mnemonic convergence through a single       social interaction.  dr. echterhoff considers the role of motivation in       moderating conversational influences.  dr. coman investigates whether these       conversational influences propagate across large networks of individuals and can       thereby promote a mnemonic convergence.  dr. edelson examines the neuroscience       underlying memory conformity.  and dr. michaelian engages the philosophical       underpinning of the concept of collective memory.  in a short summation, dr.       hirst places these papers in the larger context of social aspects of memory and       moderates further discussion.       
a widespread and powerful model of socially interactive behavior       is ‘synchrony’ (jirsa & kelso, 2004): numerous studies have thus       recently indicated how individuals through social interaction become increasingly       entrained on multiple levels from physiology to syntax: through interaction       people synchronize their heart rates, their subtle postural sways, their gestures       and gaze behaviors, align their lexicon and their syntax. however, emerging       scholarship is increasingly attending to many instances in which patterns of       complementary and asynchronous actions rather than synchronous ones seem to       predict high levels of interpersonal coordination and joint performance. while       some activities such as expertly timed rowing may afford interacting agents to       synchronize their individual behaviours to reach high levels of joint       performance, other types of joint activity – like playing a game of       baseball – rather afford complementary actions: i.e. tightly coupled,       reciprocal activity derived from different behaviours performed across an       extended temporal sequence.
narrative, a distinctly cognitive phenomenon, has long been of       interest to       the disciplines that comprise cognitive science.  the past decade has seen a       resurgence of work using computational methods to understand, manipulate,       generate, and leverage narratives. this symposium, which is held in association       with the fourth international workshop on computational models of narrative       (cmn'13), a satellite event of cogsci 2013, will focus on aspects of the       scientific and computational understanding of narrative that intersect with       cognitive science.  the speakers and moderators are drawn from diverse fields       including cognitive psychology, artificial intelligence, cognitive science,       computational linguistics, and the humanities, and they will focus on a variety       of topics including: narrative and its role in analogy, education, and       persuasion; challenges in the representation of syntax, discourse, and semantics       of narrative; psychological and neuropsychological aspects of       narrative; and the growing integration of computational models of narrative in       humanities research.
the dream of cognitive neuroscience has always been a seamless       integration of cognitive representations with neural machinery, but---despite       decades of work---fundamental gaps remain. part of the problem is that many       contemporary theories of cognition are formulated in terms of representations and       computations that are quite different from those used in computational       neuroscience. bridging this gap requires more than simply a translation between       theoretical concepts in the two fields; what is needed is a more radical updating       of neuroscience's theoretical vocabulary.
the ability to learn from others is integral to sustaining and       transmitting human culture. what are the cognitive processes that support       imitative and collaborative cultural learning? how does cultural learning       contribute to group dynamics, such as cohesion and conflict?  recent research has       focused on how children acquire instrumental skills through causal inference       (call, carpenter, & tomasello, 2005; whiten, mcguigan, marshall-pescini, &       hopper, 2009).  however, children also need to acquire the norms and conventions       of their culture, as well as an understanding of cooperative behavior, to become       full-fledged members of their community.  this acquisition begins early in       ontogeny and is likely reliant on a unique mix of causal reasoning and       affiliative goals, triggered by the nature of the action sequence itself and a       variety of social cues.  in this symposium, we consider the emerging experimental       literature on the development of imitation and collaboration with the goal of       applying this work to broader issues of group dynamics and the transmission of       culture.  henderson will consider the understanding of collaborative goals in       infancy.  kenward will consider the normative basis of young children’s       over-imitation.  watson-jones will examine affiliative motivations underlying       children’s imitation. whitehouse will consider how ritualized, normative       behavior and cognition impacts group dynamics of coordination and social       cohesion.
the hypothesis that human cognition may be well characterized as a       set of bayesian computations has been the topic of considerable debate over the       last two decades. recently, critics have argued that this hypothesis is either       unlikely to be true or otherwise too unconstrained to be particularly useful for       explaining cognition (e.g., bowers & davis, 2012), whereas proponents have       defended their position by stating that the bayesian perspective has been       misunderstood, is not necessarily in conflict with other perspectives on       cognition, and can still be explanatorily useful as a framework for cognitive       science even if under-constrained in many ways (e.g., griffiths, chater, norris,       & pouget, 2012). our position in this debate is that both sides of this debate       may be right as well as wrong.
we are living in a period of considerable global change. from       climate change to peak oil we are facing multiple challenging problems that need       to be managed carefully and wisely. cognitive science has much to say about how       people are likely to view those problems and how they will respond to them. this       symposium will shed some light on those cognitive processes and how they can       help---or indeed hinder---the problems we are facing.       
the question of whether perception can be penetrated by cognition       is in the limelight again. the reason this question keeps coming up is that there       is so much at stake: is it possible to have theory-neutral observation? is it       possible to study perception without recourse to expectations, context, and       beliefs? what are the boundaries between perception, memory, and inference (and       do they even exist)? are findings from neuroscience that paint a picture of       perception as an inherently bidirectional and interactive process relevant for       understanding the relationship between cognition and perception?
unlike a passive sponge floating in a sea of information, humans       are active information foragers -- informavores -- who gather and consume new       knowledge. from controlling the movement of our eyes to determining which sources       of news to consult, judging the quality of alternative sources of information is       a critical part of our behavior. the goal of this symposium is to bring together       researchers who are working to understand the cognitive processes underlying       active information foraging and how they interact with more general aspects of       cognition.
the processing of social information belongs to the most       complex cognitive capacities of humans, enabling us to live       together in social communities. the symposium will focus       on the everyday competence to form social impressions and       understand others. this capability includes 1. the       understanding of oneself on the basis of an explicit selfconstrual,       2. the understanding of others by processing their       mental and bodily characteristics and states 3. the       understanding of social encounters by adequately       interpreting actions, communicative signals and social roles.       human communication is essentially embedded in cultural       contexts and is shaped by it; at the same time it constitutes       the cultural background shared by the interactants. the main       goal of this symposium is to investigate the role of cognitive       and cultural factors influencing self-construal, person       perception and understanding of others. thus we deal with       the following leading questions: how do we understand       other human beings, what are the best theoretical       perspectives, what can we learn from cognitive psychology       and neurosciences and what is the role of culture in the       process of understanding oneself and others? in the recent       development of social cognition it has become clear that we       not only have to account for the observational stance       towards other people but that we also have to systematically       consider situations of online interaction with other human       beings (2nd person perspective). the main aim of the       symposium is to present the state of the art of some key       topics of social and cultural cognition from the perspectives       of philosophy of mind, cross-cultural psychology and       social-cognitive neuroscience as well as to outline some       paradigmatic lines for future research.
when cognitive processes occur alongside observable actions, it is       possible for characteristics of these processes to influence the ongoing       performance of those actions. this satisfies everyday intuitions. for example,       negotiators and poker players claim to be attuned to ‘tells,’ these       early behavioral indicators of eventual decisions. going beyond intuitions,       however, several researchers have exploited this fine-grained source of behavior       to highlight online cognitive processing. using even a simple measure such as       computer-mouse tracking can reveal a wide range of cognitive processing. four       participants in this symposium report on applications of the analysis of the       action dynamics of cognition across multiple scales: (i) basic decisions, (ii)       language processing, (iii) false responding, and (iv) social processes. the       similarities and differences in expression of these processes in action highlight       important continuities and discontinuities across cognitive and neural       processes.
in recent years, computational models have become an increasingly       important part both of cognitive science and cognitive neuroscience. in tandem       with these developments neuroscientific and cognitive investigations of musical       experience and behaviour have been gathering pace. in this context, music       cognition constitutes a rich and challenging area of cognitive science in which       the processing of complex, multi-dimensional temporal sequences can be studied       without interference of meaning or semantics (see pearce & rohrmeier, 2012, for a       review).  because of its complexity and well-defined problem-space,       computational modelling of music witnessed a rapid growth of successful       higher-order modelling approaches. this workshop investigates computational       modelling as a bridge between cognition and the brain, with a focus on       understanding the psychological mechanisms involved in perceiving and producing       music.
humans are uniquely good at inventing norms, thinking about norms,       complying with norms and defeating norms. it is small wonder, then, that norms       are a focus of much interest as well as debate across the cognitive sciences,       encompassing such diverse issues as rationality, morality and action. the aim of       the present symposium is to bring together a range of psychological and       philosophical contributions to this pertinent debate. contributors come from       diverse backgrounds, including epistemology, meta-ethics, moral judgment,       decision making, and reasoning. we will examine foundational issues in normative       thinking, such as: what is the relation between norms and descriptions? what are       the psychological mechanisms underlying normative thinking? how do epistemic and       moral norms guide action? what, if any, are the appropriate norms for knowledge,       rationality, and moral behaviour, and how can they be determined?
implicit learning, essentially the ability to acquire unconscious       (implicit) knowledge, is a fundamental aspect of human cognition. this symposium       focuses on the acquisition of two cognitive systems that are widely regarded as       prime examples of implicit learning “in the real world”, namely       language and music (see e.g. rebuschat et al., 2011; rohrmeier & rebuschat,       2012). this symposium brings together leading researchers from across the       cognitive sciences (psychology, linguistics, cognitive neuroscience, computer       science, and musicology) in order to discuss current trends in implicit learning       research, to identify the progress made in recent years, and to outline future       directions to take, both in terms of topics and novel methodologies.
conceptual learning is sometimes described as replacement of       incorrect knowledge by correct knowledge.  however, a number of recent studies       show that the storage of correct concepts in memory does not automatically erase       related incorrect concepts from memory. as a result, naïve and scientific       concepts in the same domain can coexist in a learner. the symposium aims at       discussing these findings and their implications for definitions, models and       empirical studies of conceptual learning and development.
when constructing a mind, what are the basic materials, structures       and blueprints a young child has to work with? are most of the structures already       in place, with children merely working to embellish them?  do children begin with       several buildings already in place (the physics building, the social building,       the number building, etc.), and only decorate a bit as they get older, perhaps       building bridges between them using language? such a view might describe a strong       innate core hypothesis (spelke et al., 1994). or does the child begin with more       of an empty plain, and an ability to construct whatever is necessary out of       whatever materials are at hand at the time? such a view might be more along the       lines of classic empiricism (quine, 1964).
traditionally, psycholinguistics and neuropsychology have been       informed by conspicuous pathologies such as aphasia, which revealed the       localization of some of the processes involved in language comprehension and       production, in particular of those related to lexical access and morphological       and syntactic processing. one of the main objectives of this symposium is to       explore whether psychiatric pathologies are informative of the processes involved       in meaning construction and comprehension, in the same way that aphasia research       has contributed to our knowledge of the neurobiology of other aspects of       language
classical theories of meaning in the field of linguistics and       psycholinguistics assume that meaning arises from the combination of symbols for       which a substring or other part-whole relation is defined. according to this       perspective, symbols are abstract, amodal (i.e., neither perceptual, nor motoric)       and only contingently related to entities in the external world.       for a long time, a convincing case for classical models has been the absence of       alternatives. however, more recently, several theories subsumed under the notions       of “embodied” or “grounded” theories have challenged the       fundamental assumptions of classical models (e.g., barsalou, 1999; glenberg,       2010; pecher & zwaan, 2005). from the point of view of embodied theories,       cognition is grounded in modal representations which simulate actual objects,       properties and situations. such a claim carries theoretical, empirical and       methodological repercussions that also change the way linguistic processes are       conceived of (ferretti et al., 2013; zwaan & radvansky, 1998). the goal of the       symposium is to explore which repercussions these issues have on the nature of       linguistic meaning and its neural and cognitive realization or       representation.
that there is a rapid expansion of online education is much       better understood than what its consequences will be. this       symposium considers that one key feature of “real-world”       education that takes place on the internet is that it provides a       high level of experimental control and automatic data       collection & analysis, which can support cognitive science       research that was previously only possible in laboratory       settings and small-scale educational environments. the       presenters discuss the unprecedented opportunities online       learning provides for conducting research in ecologically       valid contexts: linking existing laboratory experiments to       relevant online contexts, personalizing adaptive instruction,       embedding in vivo research studies of education, and using       the vast amount of high quality data available. the product of       such work is not only theories and empirical discoveries that       better characterize learning, but also the opportunity to       directly translate these into practical benefits to students       through concrete improvements to educational resources.
we describe an attempt to understand causal reasoning in       situations where a binary cause produces a change on a continuous magnitude       dimension. we consider established theories of binary probabilistic causal       inference – Δp and power pc – and adapt them to continuous       non-probabilistic outcomes. while Δp describes causal strength as the       difference of effect occurrence between the presence and absence of the cause,       power pc normalizes this difference with the effect base-rate to obtain a       proportional measure of causal power, relative to the maximum possible strength.       two experiments compared the applicability of each approach by creating scenarios       where binary probabilistic scenarios were directly mapped onto inference problems       involving continuous magnitude dimensions. results from counterfactual judgments       tentatively indicate that people reason about causal relations with continuous       outcomes by adopting a proportional approach when evaluation preventive causal       powers, and a difference approach in generative scenarios.
although people expect to improve by investing effort in solving a       problem, several studies have found negative time-confidence correlations in       problem-solving tasks. the present study employed the metacognitive approach to       illuminate why, despite lengthy thinking, people provide solutions with low       confidence. according to the proposed diminishing criterion model (dcm), as       people invest longer, their confidence in their solution increases in a       goal-driven manner, in accordance with the common belief. nevertheless, the       process ends up with a negative time-confidence correlation, because people find       lower confidence levels as satisfactory as they invest longer in a problem,       reflecting a compromise in their stopping criterion. the hypotheses derived from       the dcm were supported with two problem types. when a “don’t       know” response was allowed, the participants still provided low confidence       solutions after lengthy thinking, suggesting that they found these low confidence       solutions to be satisfactory. the study offers reconciliation between beliefs and       empirical findings.
when listening to music, we form implicit expectations about the       forthcoming temporal sequence. listeners acquire knowledge of music through       processes such as statistical learning, but how do different types of statistical       information affect listeners’ learning and memory? to investigate this, we       conducted a behavioral study in which participants repeatedly heard tone       sequences varying within a range of information-theoretic measures. expectedness       ratings of tones were collected during three listening sessions, and a       recognition memory test was given after each session. this enabled us to examine       how statistical information affects expectation and memory for tone sequences       over a period of increasing exposure. we found significant correlations between       listeners’ expectedness ratings and measures of information theory (it),       and although listeners demonstrated poor overall memory performance, the it       properties significantly impacted on musical memory. generally, simple sequences       yielded increasingly better memory performance. high-information sequences, for       which making accurate predictions is difficult, resulted in consistently poor       recognition memory.
theories of embodied cognition suggest that sensorimotor processes       are involved in language comprehension processes. recent studies suggested that       sentences referring to actions that involve a typical effector (e.g. “he       kicks the ball”) can systematically activate motor cortex areas that are       involved in performing such actions (hauk, johnsrude & pulvermüller, 2004).       in behavioral studies, there is mixed evidence regarding the effects of       effector-specific words on corresponding actions.  in the current study, we       investigated the effect of four word groups on subsequent motor responses       involving the hand or the foot. the four word groups were (a) action verbs (e.g.,       kick, grasp) (b) nouns containing the lexeme ‘hand’ or       ‘foot’ (e.g., handball, football) (c) nouns referring to objects that       are typically manipulated by hand or foot (e.g., cup, shoe), and (d) as control       items, nouns that have a spatial association with the upper or lower space (e.g.,       eagle, root) and which are known to activate locational information in paradigms       where no reading is required. we found strong effector-specific compatibility       effects revealing a facilitation effect in all noun-groups. surprisingly, this       effect was not present for the action-verbs. implications of these findings will       be discussed.
ratcliff, van zandt, and mckoon (1999, psych. rev.) claim that       connectionist models fail to simulate many aspects of how individuals select one       of two possible responses. here, these claims are re-evaluated via computational       and behavioral investigations of an extended version of the original numerosity       judgment task. the results of the experiment indicate that some of the empirical       effects that the models failed to capture do not generalize and were likely due       to idiosyncratic aspects of the original methodology. the simulations show that a       more biologically-plausible model captures the bulk of the new effects, including       some trial-by-trial adaptive effects that are outside the scope of models tested       against aggregate data, and emergent asymptotic stability that has previously       required an explicit leak parameter.
in this paper, we test between suppression and activation accounts       of metaphor processing by means of a novel metaphor interference paradigm using       mouse-tracking. the goal is to understand how context influences the activation       of salient and non-salient features of a concept during the on-line processing of       a metaphor. in two mouse-tracking experiments, we examine the activation and       availability of conceptual features that were either irrelevant or relevant for       understanding a metaphor across various contexts. our findings support the       conclusion that context works primarily by rapidly suppressing salient features       of a concept that are not relevant for the particular metaphorical       interpretation. what is more, it seems that even further contextual manipulation       does not facilitate the activation of non-salient metaphor relevant features.        
when a visual object is briefly flashed, it appears to lag behind       another moving object (flash-lag effect; fle). previous studies show that a       sudden change to the moving object at the time of the flash presentation can       eliminate the fle. we examined whether the fle is eliminated when a moving object       alternates in color as it moves. observers viewed a moving disc, the color of       which did not change at all, changed only once when another object flashed, or       alternated between two colors as it moved before the flash presentation. the       results showed that although the magnitude of the fle was reduced compared with       the no-change condition, the fle observed with the moving object that changed       color during motion was significantly stronger than the fle in the one-change       condition. the results are discussed in relation to the object updating account       of the fle.
virtual models are a common instructional tool used in chemistry       education to help students learn about the 3d structure of molecules. the present       study examined effects of two interface design features on participant       performance during a molecule orientation task. the features examined were 1)       colocation of the visual and haptic workspace and 2) stereoscopic viewing. the       results indicate that colocating the interface increased participant accuracy,       while providing stereo did not. neither factor affected response time. the       effects of colocation were also reflected in subjective ratings of task demand       measured by the nasa-tlx. spatial ability was predictive of task performance but       did not interact with interface effects. the findings are discussed in the       context of spatial cognition and interface design for manipulating virtual       objects.
we set forth to show that lexical connectivity plays a role in       understanding early word learning. by considering words that are learned in       temporal proximity to one another to be related, we are able to better predict       the words next learned by toddlers. we build conditional probability models based       on data from the growing vocabularies of 77 toddlers, followed longitudinally for       a year. this type of conditional probability model outperforms the current norms       based on baseline probabilities of learning given age alone. this is a first step       to capturing the interaction between a child’s productive vocabulary and       their learning environment in order to understand what words a child might learn       next. we also test different types of variants of this conditional probability       and find that not only is there information in words that are learned in       proximity to one another but that it matters how models integrate this       information. the application of this work may provide better cognitive models of       acquisition and perhaps allow us to detect children at risk for enduring language       difficulties earlier and more accurately.
we present a novel learning rule for learning transformations of       sophisticated neural representations in a biologically plausible manner. we show       that the rule can learn to transmit and bind semantic pointers. semantic pointers       have previously been used to build spaun, which is currently the world’s       largest functional brain model (eliasmith et al., 2012) and can perform several       complex cognitive tasks. the learning rule combines a previously proposed       supervised learning rule and a novel spiking form of the bcm unsupervised       learning rule. we show that spiking bcm increases sparsity of connection weights       at the cost of increased signal transmission error. we demonstrate that the       combined learning rule can learn transformations as well as the supervised rule       alone, and as well as the offline optimization used previously. we also       demonstrate that the combined learning rule is more robust to changes in       parameters and leads to better outcomes in higher dimensional spaces.
fairness and efficiency are important aspects that influence       cooperation in social dilemmas. during a repeated interaction, they have the       potential to serve as competing goals for the decision maker. the ability to       balance between fairness and efficiency depends, among other things, on available       information regarding mutual accountability for the outcomes in an interaction.       in this paper, we examine how information regarding mutual interdependencies       influences the interplay between fairness and efficiency in repeated chicken       game. we distinguish between three possible types of fair behavior: mutual       cooperation, alternating cooperation, and mutual destruction. our results show       that the first two types of fairness are positively correlated with the       availability of social information. in contrast, mutual destructive fairness is       not sensitive to the availability of information and is generally avoided. we       also find that without information regarding mutual interdependencies, unfairness       increases in parallel with efficiency. when social information is available,       however, increases in fairness is coupled with a decrease in efficiency, and the       best compromise between fairness and efficiency is reached when mutual       interdependencies are learned through repeated experiences. we highlight the       significance of our results for fair and efficient interaction in repeated social       interactions.
the rule versus rote distinction is one of the most debated issues       in recent psycholinguistics. dual route accounts hold that words can either be       stored whole in the mental lexicon or computationally derived by simple       combinatorial rules such as stem+affix. within this framework, response latencies       in lexical decision tasks have been applied to point out the difference between       rote memorization, on the one hand, and combinatorial rule manipulation, on the       other. however, this paper argues that there may be alternatives to this       distinction. it will be shown that german nouns, which can be distinctively       marked for number, case or both number and case, do elicit differing reaction       times. crucially, this effect can neither be explained by surface frequency       effects nor by internal morphological structure. rather, it seems to be triggered       by the degree of embedding into usage-based units.
infants demonstrate comprehension of early nouns (e.g.       “hand”) around six months, and comprehension of early non-nouns (e.g.       “eat”) around 10 months. in two experiments, we explore the reasons       for this lag. expt. 1 is a gaze-following study, the results of which suggest an       improvement in point-following around ten months, and reveal correlations between       pointing and both overall and non-noun vocabulary. expt. 2 is a set of corpus       analyses, the results of which suggest that word frequency does not explain the       difference between noun and non-noun age of acquisition, while suggesting that       the co-presence of words and their referents may play an important role. the       results of these experiments contribute to our understanding of word-learning       across word classes, and lend support to environmental and social factors as       having an impact on the trajectory of word learning in the first year of       life.
mental representations of environments are embodied in       cognitive maps. cognitive maps enclose spatial and distance       distortions, which appear due to transcription errors based on       processing of map information. participants processed       complex cartographical maps of varying amounts of visual       details like topography, boundaries and grid to examine their       effects on recall and orientation performance. the results       indicate that the presentation of boundaries, topographies and       a square grid significantly reduced distortion errors compared       to a blank map, whereas a presentation of more than one       visual element did not further reduce the distortions.
it is generally assumed that the character position targeted       within a       particular word is not under direct cognitive control, but is rather       determined by oculomotor processes sensitive only to word length and       distance. an alternative view is that readers target more distant       characters in words when they have parafoveally processed these words       more. these possibilities are difficult to distinguish because the       actual landing site within a word has large effects on subsequent word       processing measures. in two experiments, we decoupled the targeted       location from the actual landing site by shifting the text 3       characters during the saccade into a target word. results show that       subsequent word processing time given a particular landing site was       lower/higher when the eyes would have landed further forward/backward       in the word. this effect remains significant in some cases when       controlling for saccade launch site. these data provide evidence against       the oculomotor theory and support a cognitive account of saccade       targeting.
the ability to recognize faces is arguably one of the most       important and most practiced skills. the possible functions of the fusiform face       area (ffa), generally believed to be responsible for face recognition, also       feature these two characteristics. on the one hand, there are claims that the ffa       has evolved into a face specific module due to great importance of face       processing. on the other, the ffa is seen as a general visual expertise module       that distinguishes between individual examples within a single category. the       previous studies used experts and novices on stimuli such as cars, birds or       butterflies with ambiguous results. here this research stream is extended to the       game of chess, which does not share visible features with faces. the first study       shows that chess expertise modulates the ffa activation when complex multi-object       chess positions were presented. in contrast, isolated single chess objects did       not produce different activation patterns among experts and novices. the second       study confirmed that even a couple of isolated objects do not differently engage       the ffa among experts and novices. the two studies provide support for the       general expertise view of the ffa function, but also extend the scope of our       understanding about the function of the ffa. the ffa does not merely distinguish       between different exemplars. it also seems to engage into parsing complex       multi-object stimuli that contain numerous functional and spatial relations.
novices often lack metacognition and self-regulation skills that       are important for effective learning. betty's brain, an open-ended computer-based       learning environment helps students practice and develop metacognitive strategies       as they learn science topics. we extend previous work on sequence mining methods       to discover students' frequently-used behavior patterns from their activity       sequences. our results show that it is possible to interpret aspects of students'       learning strategies and their effectiveness by taking into ac-count the context       of their activities in the system.
the current study investigates whether mentalizing, or taking the       perspective of your interlocutor, plays an essential role throughout a       conversation or whether it is mostly used in reaction to misunderstandings. this       study is the first to use a brain-imaging method, meg, to answer this question.       in a first phase of the experiment, meg participants interacted "live" with a       confederate who set naming precedents for certain pictures. in a later phase,       these precedents were sometimes broken by a speaker who named the same picture in       a different way. this could be done by the same speaker, who set the precedent,       or by a different speaker. source analysis of meg data showed that in the 800 ms       before the naming, when the picture was already on the screen, episodic memory       and language areas were activated, but no mentalizing areas, suggesting that the       speaker's naming intentions were not anticipated by the listener on the basis of       shared experiences. mentalizing areas only became activated after the same       speaker had broken a precedent, which we interpret as a reaction to the violation       of conversational pragmatics.
a new method is demonstrated for identifying processing stages in       a task. since the 1860s cognitive scientists have used different methods to       identify processing stages, usually based on reaction time (rt) differences       between conditions. to overcome the limitations of rt-based methods we used       hidden markov models (hmms) to analyze eeg data. the hmms indicate for how many       stages there is evidence in the data, and how the durations of these stages vary       with experimental condition. this method was applied to an associative       recognition task in which associative strength and target/foil type were       manipulated. the hmm-eeg method identified six different processing stages for       targets and re-paired foils, whereas four similar stages were identified for new       foils. the duration of the third, fifth and sixth stage varied with associative       strength for targets and re-paired foils. we present an interpretation of the       identified stages, and conclude that the method can provide valuable insight in       human information processing.
meanings of basic expressions can be enriched by considering what       the speaker could have said, but chose not to, that is, the alternatives. we       report three experiments testing whether there is a single enrichment procedure       that stretches across diverse linguistic phenomena. participants were primed to       understand either the basic meaning or the enriched meaning of a sentence. we       found that the enrichment mechanism could be primed across some expressions but       not others, arguing against a universal enrichment mechanism. our results have       implications for understanding the processing of implied meaning and how       linguistic phenomenon should be grouped together.
across different domains the magnitude of a stimulus is positively       correlated with its perceived duration: bigger, brighter or louder stimuli are       usually perceived to last longer than smaller, dimmer or softer ones. according       to a theory of magnitude (atom), temporal and nontemporal magnitudes are linked       in the human mind by virtue of sharing a common metric. this claim has been       challenged by studies in the domains of brightness and loudness suggesting that       it is not the difference in magnitude between stimuli, but rather their degree of       change from background that modulates duration judgments. but do the same       relationships hold between perceived duration and all prothetic dimensions? we       tested the influence of stimulus magnitude and relative change on temporal       judgment in the domain of space. we found that, unlike brightness and loudness,       spatial length can influence duration judgments independently of the degree of       change from a common background, and that this effect is context dependent. thus,       an approach based exclusively on the degree of change between stimulus and       background is not sufficient to account for the effect of magnitude on temporal       judgments. our results suggest that space has a privileged link with temporal       representations compared to other prothetic domains, challenging the hypothesis       that space-time relationships are the product of a domain-general magnitude       system. 
accounts of category-based inductive reasoning can be       distinguished by the emphasis they place on associative retrieval processes       versus structural knowledge representation. using an open-ended category-based       induction task with a secondary task manipulation, we explored whether the       relative importance of these two processes in determining the reasoning output       depends upon the availability of mental resources. regressing indices of strength       of association and measures of structured relation against reasoners’       inferences showed that people’s inductions generated under cognitive load       were more strongly predicted by associative strength between base and conclusion       category. in contrast, inferences made under no load were best predicted by the       measure of the existence of structural relations between base and conclusion       category. this suggests that people make use of associative processes and recruit       structured knowledge to make inductive inferences, and that the relative       importance of these two forms of reasoning is determined by the availability of       mental resources
according to decades of research in affective neuroscience, the       left and right hemispheres are specialized for approach and avoidance motivation,       respectively. with the sword and shield hypothesis (ssh) we challenge this       conclusion; we propose that the lateralization of motivation depends on the       lateralization of motor control for the dominant and non-dominant hands (used       preferentially for approach and avoidance actions, respectively). the ssh       predicts that the laterality of approach motivation should vary continuously with       the laterality of circuits supporting approach-related actions. we measured mood       before and after 5 sessions of tdcs applied bilaterally to dlpfc in right- and       left-handers. results in right-handers show that positive emotions increased       after left-excitatory stimulation, but decreased after right-excitatory       stimulation.  in non-right-handers, however, the opposite pattern was found:       positive emotions decreased after left-excitatory stimulation, but increased       after right-excitatory stimulation. these results reveal continuous covariation       between the neural systems for action and emotion, supporting the ssh.
information structure describes how the information is packaged       within a discourse to optimize information transfer. we addressed the question if       and how a discourse context modulates the online processing of german       declaratives. native speakers of german read fictitious stories that depicted a       simple action scene of two characters while we recorded event-related brain       potentials (erps). two types of discourse contexts (topic vs. neutral) were       compared with regard to the processing of declarative canonical       subject-before-object (so) and non-canonical object-before-subject (os)       sentences. the preceding topic context only modulated the processing of os       sentences. this was indicated by a less pronounced positivity around 500 to 900       ms for the topic compared to the neutral context. as supported by previous       research we argue that this context-induced effect in the processing of       non-canonical sentences reflects reduced processing costs for the integration of       the discourse relevant topic information into the current discourse model.
in the two-envelope problem a reasoner is offered two envelopes,       one containing exactly twice the money in the other. after observing the amount       in one envelope it can be traded for the unseen contents of the other. until       recently it was argued that it did not matter whether the envelope was traded or       not, but abbott, davis & parrondo (2010) showed that gains could be made if       trading was a probabilistic function of amount observed. three experiments varied       where the observed and maximum amounts fell in a possible distribution and tested       whether this affected choices. trading was less likely for lower observed amount       than higher, but this effect differed depending on the stated distribution. this       suggests that participants’ trade decisions were affected by where       observations fit in the distribution, and thus their probabilities. the modeling       tools used here may be applicable to other reasoning phenomena.
evaluating whether information is generalizable, essential       knowledge about a novel category is a critical component of conceptual       development. in previous work (butler & markman, 2012) 4-year-old children were       able to use their understanding of whether information was explicitly       communicated for their benefit to guide such reasoning, while 3-year-olds were       not. in two experiments, we further investigate this finding. four-year-olds were       adept at navigating pedagogical interactions, judiciously identifying which       specific actions in an ongoing interaction were meant as communicative       demonstrations for their benefit, while 3-year-olds did not distinguish between       the manners of demonstration even in a simpler context. taken together, these       experiments illustrate that this powerful learning mechanism for facilitating       children’s conceptual development is under construction during the       preschool years.
this paper presents the results of a computational model of       generalized phonological rule learning (calamaro and jarosz, 2012), which is used       to model experimental studies on the learning of phonotactic patterns governed by       natural and unnatural classes. i focus on two papers with conflicting results on       the learnability of natural and unnatural rules. saffran and thiessen (2003) find       that a phonotactic pattern of positional voicing restrictions governed by a       natural class of segments is learned by infants, but a similar pattern governed       by an unnatural class is not learned. in contrast, chambers, onishi, and fisher       (2003) find that infants can learn a phonotactic pattern governed by an unnatural       class of segments. the computational model presented in this paper is able to       account for these seemingly conflicting results, explaining both the learnability       and unlearnability of rules governed by unnatural classes. 
the aim of this paper is to highlight the role of the social       factors among the different forces which influence natural selection. to do this,       we’ll start analyzing an example of highly complex society, like that of       the baboons, in order to show that the building-up of a society depends on       extremely flexible and continually negotiated social relationships, rather than       on features that are genetically determined. however, in our view, when we shift       from animal societies to the human ones, we have to recognize the central role of       language. in fact, even if the role of social influence appears to be relevant in       other animal species, in humans it was language that provided the way to make       this social influence much more important, to redefine the roles, to reverse the       genetic dominances even more, and to make human cooperation something unique.
the current paper examines spatial descriptions provided by older       adults in the context of a fetch task in a virtual house environment that mimics       an eldercare setting.  sixty-four older adults provided directions for how to       find a target or where to find a target to a robot or human (named brian) avatar.        there were systematic differences in the form and structure of the descriptions       based on the communicative task. specifically, how descriptions were longer,       contained more detail, and were dynamically structured as compared to where       descriptions.  however, where descriptions were found to be more effective in       conveying the target location, as assessed with a subsequent target selection       task.  implications for the development of robot algorithms for the comprehension       of naturalistic spatial language across these two communicative tasks are       discussed.
the process of generating a new hypothesis often begins with the       recognition that all of the hypotheses currently under consideration are wrong.       while this sort of falsification is straightforward when the observations are       incompatible with each of the hypotheses, an interesting situation arises when       the observations are implausible under the hypotheses but not incompatible with       them. we propose a formal account, inspired by statistical model checking, as an       explanation for how people reason about these probabilistic falsifications. we       contrast this account with approaches such as bayesian inference that account for       hypothesis comparison but do not explain how a reasoner might decide that the       hypothesis space needs to be expanded.
when english speakers successively pile-sort colors, their sorting       recapitulates an independently proposed hierarchy of color category evolution       during language change (boster, 1986). here we extend that finding to the       semantic domain of spatial relations. levinson et al. (2003) have proposed a       hierarchy of spatial category evolution, and we show that english speakers       successively pile-sort spatial scenes in a manner that recapitulates that       proposed evolutionary hierarchy. thus, in the spatial domain, as in color,       proposed universal patterns of language change based on cross-language       observations appear to reflect general cognitive forces that are available in the       minds of speakers of a single language.
we investigate children's online predictive processing as it       occurs naturally, in conversation. we showed 1--7 year-olds short videos of       improvised conversation between puppets, controlling for available linguistic       information through phonetic manipulation. even one- and two-year-old children       made accurate and spontaneous predictions about when a turn-switch would occur:       they gazed at the upcoming speaker before they heard a response begin. this       predictive skill relies on both lexical and prosodic information together, and is       not tied to either type of information alone. we suggest that children integrate       prosodic, lexical, and visual information to effectively predict upcoming       linguistic material in conversation.
we investigated gestural communication in early bilinguals. in       particular, we tested which aspects of gestures were “transferred”       from a language to another. though transfer in spoken languages has been studied       extensively, transfer in gesture is understudied. gesture transfer can provide       useful information on the cognitive architecture in bilingualism. in this study       our focus is on gesture rate and gesture space in italian/english bilinguals.       contrary to previous findings, we have no evidence of transfer. when bilinguals       switch language, their gesture parameters switch accordingly. the switch of       gesture (cultural) parameters such as rate and salience show that language and       gesture are tightly linked. this suggests that a language and the corresponding       gesture parameters might be selected in a high level processing stage at which       verbal and nonverbal aspects of communication are planned together. 
recent studies have shown that the involvement of semantic       information in visual lexical decision depends on the nature of nonword foils       with semantic effects increased as nonwords become more word-like (evans, lambon       ralph &woollams;, 2012). given that most models of lexical decision focus on       orthographic information (coltheart, rastle, perry, langdon & ziegler, 2001;       grainger & jacobs, 1996; seidenberg & mcclelland, 1989), the role of semantics       and its interactions with vision, orthography, and phonology has been overlooked.       we developed a recurrent connectionist model of single word reading including       visual, orthographic, phonological, and semantic processing. the model       differentiated words from nonwords by integrating measures of polarity across       four key processing layers. the contribution of semantics depended on the type of       nonword foils. the model was more reliant on semantic information when the       nonword foils were pseudowords and pseudohomophones rather than consonant       strings. the results support the view that semantic involvement in lexical       decision is graded by the difficulty of the decision task.
category information is used to predict unknown properties of       category members. previous research has found that when categorization is       uncertain, property predictions do not reflect integration of information across       categories as normative principles and bayesian models would suggest. rather,       people often base their predictions on only the most likely category and       disregard information from less likely ones. research in category-based induction       tends to elicit explicit, verbal responses which may not readily allow for       integration of information across categories. this paper explores whether       changing response mode can promote more normative use of category information in       induction. experiment 1 used an implicit measure of prediction: eye movements.       the results suggest that when making predictions implicitly people integrate       information across categories. the results of experiment 2 suggest that the       integration of information found in experiment 1 were not a result of explicit       strategies.
we present a spiking neuron brain model implemented in 318,870 lif       neurons organized with distinct cortical modules, a basal ganglia, and a       thalamus, that is capable of flexibly following memorized commands. neural       activity represents a structured set of rules, such as “if you see a 1,       then push button a, and if you see a 2, then push button b”. synaptic       connections between these neurons and the basal ganglia, thalamus, and other       areas cause the system to detect when rules should be applied and to then do so.       the model gives a reaction time       difference of 77 ms between the simple and two-choice reaction time tasks, and       requires 384 ms per item for sub-vocal counting, consistent with human       experimental results. this is the first biologically realistic spiking neuron       model capable of flexibly responding to complex structured instructions.
in this paper we propose a hidden markov model (hmm)-based method       to analyze eye movement data. we conducted a simple face recognition task and       recorded eye movements and performance of the participants. we used a variational       bayesian framework for gaussian mixture models to estimate the distribution of       fixation locations and modelled the fixation and transition data using hmms. we       showed that using hmms, we can describe individuals’ eye movement       strategies with both fixation locations and transition probabilities. by       clustering these hmms, we found that the strategies can be categorized into two       subgroups; one was more holistic and the other was more analytical. furthermore,       we found that correct and wrong recognitions were associated with distinctive eye       movement strategies. the difference between these strategies lied in their       transition probabilities.
cerebral lateralization is intertwined with virtually every       cognitive function that we think makes us human. yet a clear dichotomy has never       been explained: lateralized processing suggests independent, local development of       neural circuits, but the complementary nature of lateralized functions and       extremely strong functional coupling between homologous areas suggest robust       interhemispheric interactions. here, we review literature and present modeling       evidence that this dichotomy can be explained by the uniquely steep trajectory of       human post-natal brain growth. this drastic volumetric change cause most long       distance, interhemispheric connections to be more unreliable than shorter,       intrahemispheric connections, leading to lateralization. strong interhemispheric       collaboration is enabled by the later maturation and myelination of long-distance       callosal connections. we also review and reanalyze a well-cited modeling paper       (ringo, doty, demeter, & simard, 1994) thought to show a relationship between the       degree of hemispheric coordination and length of conduction delays, showing that       previous claims have a clear alternative explanation.
systematicity is a basic property of language and other culturally       transmitted behaviours. utilising a novel experimental task consisting of       initially independent sequence learning trials, we demonstrate that systematicity       can unfold gradually via the process of cultural transmission. 
inspired by a dynamic approach to recognition memory (cox &       shiffrin, 2012), we present results from a recognition memory experiment in which       the time at which diagnostic information arrives is unconsciously varied.        contrary to the predictions of most models, performance improves when diagnostic       information is available later, rather than earlier.  these results are accounted       for by a dynamic model of recognition, where the time at which information starts       to be accumulated for a recognition decision can vary independently of when       features are available to be sampled from the test display.  the same model is       shown to be able to reproduce the priming results of jacoby & whitehouse (1989),       originally attributed to a fluency heuristic.  the ability to account for such       seemingly disparate results with a single model illustrates the utility of a       dynamic approach to recognition.
previous research suggests that people often recall individual       items when sets are smaller than four and aggregate set features for sets larger       than four. one intriguing possibility is that the process of aggregating sets       creates summary representations that maintain the statistical properties of the       set itself. for sets of numbers, this process might implicitly create approximate       means. we report the results of two experiments investigating memory for number       sets and its relation to working memory and metacognitive monitoring. in both       experiments, participants were shown a series of data sets that varied in size       (4, 6, or 8 numbers) and variance (10% or 20% of the mean) and were then       presented with an actual value from the set and the set mean. in experiment 1,       participants were asked to select the actual value, and in experiment 2,       participants were asked to select the set mean. results indicated that the       proportion of correct selections and metacognitive confidence decreased with set       size. working memory was related to performance only when the set size was 6. the       findings suggest that participants often erroneously reported the set mean as       being a member of the set and that this effect increased for sets larger than       four. the findings suggest that the process of aggregating number sets results in       approximate means.
we parsimoniously model the effect of proactive interference and       memorization effort in learning stable graphical layouts. we model the visual       search cost, i.e. the number of distractors visually encoded while looking for a       target item, as a reasonable surrogate of onscreen proactive interference.       further, we show that a novel quantity that we term "effort factor" is an       acceptable estimate for comparing the memorization effort across different access       cost of onscreen information during the early stages of practice.
does a middle school mathematics curriculum that is redesigned       using principles based in cognitive research improve student outcomes?  to test       whether research can be effectively translated into practice, the connected       mathematics project 2 (cmp2) curriculum was revised according to four principles       1) mapping verbal-visual information, 2) interleaving worked examples, 3) spacing       learning over time and 4) using formative assessment. this study of 6th grade and       8th grade mathematics education addresses the research question, “do       students who are exposed to specific redesigned cmp2 curriculum modules       (treatment) exhibit greater improvements in mathematics performance in the       module-specific content area than their counterparts exposed to the regular cmp2       curriculum (control)?” preliminary analyses show statistically significant       effects of the redesigned cmp2 units in three of the four curricular units in       this study.
exploratory learning before instruction can benefit understanding,       but can also be challenging. individual differences in response to challenge,       such as achievement motivation, may therefore moderate the benefits of       exploratory learning. higher mastery orientation generally leads to increased       effort in response to challenge, whereas higher performance orientation leads to       withdrawal. children (2nd-4th grade; n=159) were given mathematical equivalence       problems to solve as either an exploratory learning activity (before instruction)       or as practice (after instruction). higher mastery orientation was associated       with improved learning from exploration. in contrast, performance orientation did       not lead to learning improvements—and sometimes even hurt learning. higher       mastery orientation was also associated with more sophisticated problem-solving       strategies during exploration. although exploratory activities have the potential       to advance strategy selection and subsequent learning, achievement motivation may       boost or hinder these benefits.   
we present data from three experiments addressing how much theory       of mind reasoning is involved in production and interpretation of ambiguous       referential expressions in an artificial language task, and how this interacts       with the cost and availability of alternative utterances. when an unambiguous       alternative is not available, listeners tend to draw simple quantity inferences       reminiscent of scalar implicatures (grice, 1975). when an unambiguous alternative       is available, fewer inferences are observed, but gradiently more as the cost of       unambiguous alternatives increase. we outline a novel game theoretic model of       pragmatic reasoning based on probabilistic back-and-forth reasoning about       interlocutors’ rational choices and beliefs. the model provides a good fit       to the data and raises interesting issues for future research.
we test the hypothesis that superficial knowledge interdependence       is more effective in fostering individual learning from collaboration than the       true knowledge interdependence often realized by jigsaw-type collaboration       arrangements. based on research on group information-processing, we argue for the       benefits of distributing only contextual information, but not core principles       between learners, establishing superficial knowledge interdependence. in a       computer-supported collaborative learning environment, 78 university students       learned about stochastic urn models. knowledge interdependence was established by       systematically distributing learning materials within student triads, so that       students either became experts for an urn model, establishing true knowledge       interdependence, or for one of the embedding cover stories, establishing       superficial knowledge interdependence. afterwards, all triads worked on the same       collaborative tasks, and were exposed to all models. results show successful       learning across conditions, but superior knowledge transfer in triads       collaborating under superficial knowledge interdependence. benefits were highest       for low prior knowledge learners.
non-integer rational numbers, such as fractions and decimals, pose       challenges for learners, both in conceptual understanding and in performing       mathematical operations. previous studies have focused on tasks involving access       and comparison of integrated magnitude representations, showing that adults have       less precise magnitude representations for fractions than decimals. here we show       the relative effectiveness of fractions over decimals in reasoning about       relations between quantities. we constructed analogical reasoning problems that       required mapping rational numbers (fractions or decimals) onto pictures depicting       either part-whole or ratio relations between two quantities. we also varied the       ontological nature of the depicted quantities, which could be discrete,       continuous, or continuous but parsed into discrete components. fractions were       more effective than decimals for reasoning about discrete and continuous-parsed       (i.e., discretized) quantities, whereas neither number type was particularly       effective in reasoning about continuous quantities. our findings show that, when       numbers serve as models of quantitative relations, the ease of relational mapping       depends on the analogical correspondence between the format of rational numbers       and the quantity it models. 
object segregation in a visual scene is a complex perceptual       process that relies on the integration of multiple cues. the task is       computationally challenging, and even the best performing models fall       significantly short of human performance. infants initially have a surprisingly       impoverished set of segregation cues and their ability to perform object       segregation in static images is severely limited. major questions that arise are       therefore how the rich set of useful cues is learned, and what initial capacities       make this learning possible. here we present a computational model that initially       incorporates only two basic capacities known to exist at an early age: the       grouping of image regions by common motion and the detection of motion       discontinuities. the model then learns significant aspects of object segregation       in static images in an entirely unsupervised manner by observing videos of       objects in motion. implications of the model to infant learning and to the future       development of object segregation models are discussed.
standard working memory (wm) updating tasks confound updating       requirements with generic wm functions. we introduce a method for isolating a       process unique to wm updating, namely the removal of no-longer relevant       information. in a modified version of an established updating paradigm,       to-be-updated items were cued before the new memoranda were presented. longer       cue-stimulus intervals—that is, longer removal time—led to faster       updating, showing that people can actively remove information from wm.       well-established effects of item repetition and similarity on updating rts were       diminished with longer removal time, arguably because representational overlap       between out-dated and new information becomes less influential when out-dated       information can be removed prior to new encoding. the benefit of removal time was       found only for partial updating, not for complete updating of entire memory sets.       we conclude that removal of out-dated information can be experimentally isolated,       and that removal is a unique, active wm updating process.
generating explanations and making comparisons have both been       shown to improve learning. while each process has been studied individually, the       relationship between explanation and comparison is not well understood. three       experiments evaluated the effectiveness of explanation and comparison prompts in       learning novel categories. in experiment 1, participants explained items’       category membership, performed pairwise comparisons between items (listed       similarities and differences), did both, or did a control task. the explanation       task increased the discovery of rules underlying category membership; however,       the comparison task decreased rule discovery. experiments 2 and 3 showed that (1)       comparing all four category exemplars was more effective than either       within-category or between-category pairwise comparisons, and that (2)       “explain” participants reported higher levels of both spontaneous       explanation and comparison than “compare” participants. this work       provides insights into when explanation and comparison are most effective, and       how these processes can work together to maximize learning.
several approaches to implementing symbol-like represen-       tations in neurally plausible models have been proposed.       these approaches include binding through synchrony (shas-       tri & ajjanagadde, 1993), mesh binding (van der velde &       de kamps, 2006), and conjunctive binding (smolensky, 1990;       plate, 2003). recent theoretical work has suggested that most       of these methods will not scale well – that is, they cannot en-       code structured representations that use any of the tens of thou-       sands of terms in the adult lexicon without making implausible       resource assumptions (stewart & eliasmith, 2011; eliasmith,       in press). here we present an approach that will scale appro-       priately, and which is based on neurally implementing a type       of vector symbolic architecture (vsa). specifically, we con-       struct a spiking neural network composed of about 2.5 million       neurons that employs a vsa to encode and decode the main       lexical relations in wordnet, a semantic network containing       over 100,000 concepts (fellbaum, 1998). we experimentally       demonstrate the capabilities of our model by measuring its per-       formance on three tasks which test its ability to accurately tra-       verse the wordnet hierarchy, as well as to decode sentences       employing any wordnet term while preserving the original       lexical structure. we argue that these results show that our       approach is uniquely well-suited to providing a biologically       plausible, human-scale account of the structured representa-       tions that underwrite cognition.
recent research has sought to examine how learners are able to       track the co-occurrence of words and objects across moments in time, a behavior       commonly termed cross-situational statistical learning. the current experiment       was designed to examine if learners can simultaneously determine word-referent       pairings while engaging in other cognitive processes that support language       learning, such as distinguishing phonologically overlapping words. participants       were presented with a cross-situational statistical learning task with pairs of       words in four categories: non-minimal pairs, near minimal pairs, vowel minimal       pairs, and consonant minimal pairs. the results revealed that participants were       able to simultaneously learn word-referent pairings while distinguishing all four       categories of word pairings. however, learners experienced the most difficulty       learning vowel minimal pairs. this work demonstrates that learners are able to       simultaneously engage in multiple cognitive processes that support language       learning. 
we asked college students to make judgments about realistic moral       situations presented as dilemmas (which asked for an either/or decision) vs.       problems (which did not ask for such a decision) as well as when the situation       explicitly included affectively salient language vs. non-affectively salient       language. we report two main findings. the first is that there are four different       types of cognitive strategy that subjects use in their responses: simple       reasoning, intuitive judging, cautious reasoning, and empathic reasoning. we give       operational definitions of these types in terms of our observed data. in       addition, the four types characterized strategies not only in the whole sample,       but also in all of the subsamples in our study. the second finding is that the       intuitive judging type comprised approximately 26% of our respondents, while       about 74% of our respondents employed one of the three styles of reasoning named       above. we think that these findings present an interesting challenge to models of       moral cognition which predict that there is either a single, or a single most       common, strategy – especially a strategy of relying upon one’s       intuitions – that people use to think about moral situations. 
languages around the world share a number of commonalities known       as language universals. we investigate whether the existence of some recurrent       patterns can be explained by the learner’s preference to balance the amount       of information provided by the cues to sentence meaning. in an artificial       language learning paradigm, we expose learners to two languages with optional       case-marking – one with fixed and one with flexible word order. we find       that learners of the flexible word order language, where word order is       uninformative of sentence meaning, use significantly more case-marking than the       learners of the fixed word order language, where case is a redundant cue. the       learning outcomes in our experiment parallel a variety of typological phenomena,       providing support for the hypothesis that communicative biases can shape language       structures.
language learners tend to regularize unpredictable variation and       some claim that is due to a language-specific regularization bias. we investigate       the role of task difficulty on regularization behavior in a non-linguistic       frequency learning task and show that adults regularize variable input when       tracking multiple frequencies concurrently, but reliably reproduce the variation       they have observed when tracking one frequency. these results suggest that       regularization behavior may be due to domain-general factors, such as memory       limitations.
the present study presents a novel paradigm for testing the       ability for adults to rapidly learn novel morphological categories in the wake of       irrelevant information: specifically number markings intermixed with irrelevant       gender cues. using an artificial language learning paradigm, participants were       exposed to picture-sound pairs in which pictures of animals varied by number       (singular, dual and plural), but with irrelevant gender information intermixed       with the exposure items (masculine, feminine and neuter). auditory stimuli were       presented in cvcvcv forms (e.g., [zovabu]) in which the first two syllables       denoted the animal (e.g., [zova] for snail) and the final syllable denoted       number. (e.g., [bu] for single). results revealed that participants were able to       learn which category the suffix endings referred to, based on a two-alternative       forced-choice generalization task. implications for the learning of complex       paradigms are discussed.
research in analogical reasoning suggests that higher-order       cognitive functions such as abstract reasoning, far transfer, and creativity are       founded on recognizing structural similarities among relational systems. here we       integrate theories of analogy with the computational framework of reinforcement       learning (rl). we propose a computational synergy between analogy and rl, in       which analogical comparison provides the rl learning algorithm with a measure of       relational similarity, and rl provides feedback signals that can drive analogical       learning. initial simulation results support the power of this approach.
the faces of other people are a critical information source for       young children. during early development, children undergo significant postural       and locomotor development, changing from lying and sitting infants to toddlers       who walk independently. we used a head-mounted camera in conjunction with a       face-detection system to explore the effects of these changes on children's       visual access to their caregivers' faces during an in-lab play session. in a       cross-sectional sample of 4 - 20 month old children, we found substantial changes       in face accessibility based on age and posture. these changes may translate into       changes in the accessibility of social information during language learning.
  the analysis of the internal structure of concepts reveals the         presence of a substantial amount of contextual information. even         though this interaction is easily recognizable, it is not clear how         contextual information is processed and included into concept         representations.  the aim of this paper is to shed light on this         question by analyzing the effect that an increasing amount of         context exerts on conceptual processing. we report a self-paced         reading experiment and a visual world experiment to test two         hypotheses about the integration of context information: the         incremental activation hypothesis suggests that the degree of         facilitation in concept processing increases with the amount of         context available; and the immediate activation hypothesis         states that once a sufficient amount of contextual support is         reached, no more facilitation occurs. our data are compatible with         the latter account.
we examined how the intrinsic orientation of spatial layouts and       the conversational partner’s viewpoint shape how people organize spatial       information in memory and subsequently describe it. in 24 pairs, directors first       studied an array with a symmetrical structure while either knowing their       matcher’s subsequent viewpoint or not. when describing the array to the       matcher, the array’s intrinsic orientation was aligned with the director,       the matcher, or neither partner. memory tests preceding descriptions revealed       that directors misaligned with the structure organized information according to a       priori knowledge, being more likely to use the structure as an organizing       orientation when knowing that matchers were aligned with it. the perspective of       directors’ descriptions was also influenced both by the partners’       alignment with the structure and their advance knowledge of that. altogether,       speakers are guided by converging social and representational cues to adapt       flexibly the organization of their memories and perspectives of their       descriptions. 
research on human reasoning is dominated by demonstrations of the       errors people make in various judgment and decision-making tasks. the area of       social cognition is not an exception: the list of apparent errors is long and       includes a number of contradictory phenomena. here we explore a prominent example       of the contradictory pairs of biases: false consensus and false uniqueness. we       show in an empirical study and with simulations that the consensus in the       literature about the stability of these effects may be premature, as their       occurrence depends on the format of questions used to measure them.
successful dialogue frequently requires that interlocutors       construct and align their conceptualizations of referents. this study presents       data from a referential communication experiment the manipulates contextual       factors such as the availability of feedback and role constancy in order to       investigate how conversational partners reconcile their perspectives in the face       of mutual uncertainty about what constitutes common ground. the results show that       speakers tend to incorporate information about the addressee’s perspective,       and that this information tends to come through direct feedback rather than       through indirect channels such as turn-taking.
when referring to an object using a description, speakers need to       select properties which jointly distinguish it from any potential distractors.       previous empirical and computational work addressing this content selection       process has highlighted the role of both (i) the discriminatory power of       properties of a referent, i.e. how many of the distractors in a domain each       property excludes; (ii) how inherently salient or preferred a property is. to       date, there has been no attempt to systematically investigate the trade-o       between these two potentially competing motivations. this paper investigates       experimentally the extent to which speakers take discriminatory power versus       preference into account during content selection for reference production. our       results suggest that discriminatory power in fact plays a relatively unimportant       role. we discuss the implications of this for computational models of reference       production.
scenes filled with moving objects are often hierarchically       organized: the motion of a migrating goose is nested within the flight pattern of       its flock, the motion of a car is nested within the traffic pattern of other cars       on the road, the motion of body parts are nested in the motion of the body.       humans perceive hierarchical structure even in stimuli with two or three moving       dots. an influential theory of hierarchical motion perception holds that the       visual system performs a "vector analysis" of moving objects, decomposing them       into common and relative motions. however, this theory does not specify how to       resolve ambiguity when a scene admits more than one vector analysis. we describe       a bayesian theory of vector analysis and show that it can account for classic       results from dot motion experiments. our theory takes a step towards       understanding how moving scenes are parsed into objects.
how are space and time related in the brain? this study contrasts       two proposals that make different predictions about the interaction between       spatial and temporal magnitudes. whereas atom implies that their relation is       symmetric, metaphor theory claims it is asymmetric. we investigated whether space       and time activate overlapping areas of the inferior parietal cortex (ipc) and       whether they do so symmetrically or asymmetrically. we measured       participants’ neural activity while they made temporal and spatial       judgments on identical visual stimuli. the behavioral results replicated earlier       observations of a space-time asymmetry: spatial information influenced temporal       judgments more than vice versa. the bold data indicated that space and time       activated overlapping ipc clusters and that, consistent with metaphor theory,       this activation was asymmetric: the shared region of ipc was activated more       during temporal than during spatial judgments. we consider three possible       interpretations of this neural asymmetry, based on 3 possible functions of       ipc.
complex and dynamic decision making environments are common       throughout life, but little is known about how normal aging influences       performance on these types of scenarios. to determine performance differences       associated with normal aging, we test older and younger adults in a dynamic       control task. the task involves the control of a single output variable via       multiple and uncertain input controls. a computational model is developed to       determine the behavioral characteristics associated with normal aging in a       dynamic control task. older adults exhibit a positivity effect, congruent with       previous research. model based analysis demonstrates a unique performance       signature profile associated with normal aging.
prior research on the development of category-based reasoning       indicates a protracted developmental course of this ability as well as a high       degree of individual variability. however, the sources of this individual       variability as well as the sources of developmental change remain unclear. the       present study aimed to examine these issues, with a focus on the role of       representational change and executive function development. across two time       points spaced approximately 7 months apart, children’s category-based       reasoning was assessed along with a battery of executive function and       representational change measures. results replicated prior work in that only a       small proportion of children exhibited spontaneous category-based reasoning at       time 1, and this proportion increased with development. in addition, both       executive function and representational change were found to predict the       development of category-based reasoning. 
construction tasks involve numerous demanding sub-tasks such as       creating a mental model of the goal object and integrating the object parts into       this model. for this purpose object parts need to be assigned a function within       the overall structure. in this paper we examine the linguistic represen- tation       of this process. participants were given 16 object parts to assemble without a       manual, and were asked to think aloud while doing so. depending on condition they       were not given any specific information, or told that the goal object was a       dollhouse, or shown a picture of the dollhouse. in a second study, participants       were asked to instruct a partner to assemble the dollhouse. results of our       linguistic analysis of think-aloud data and instructions reveal three strategies       of assigning function to objects, one of which occurred exclu- sively in       instructions. with less specific information about the goal object, functions       were more often assigned explicitly. in these cases function tended to relate to       the overall structure (e.g. ‘house’) rather than to structural parts       (e.g. ‘wall’).
the most popular way to improve consumers’ control over       their electricity cost is by providing frequent and detailed feedback with       “in-home displays” (ihd). in this study, we examined alternative ways       to train experimental participants to control and optimize their use of       electricity by “feedforward” training to map energy consuming       behaviors to costs. the participants were trained in one of four experimental       conditions, one feedback (“ihd”) and three feedforward conditions       before they had to control the electricity consumption in a simulated household.       results showed that one of the feedforward conditions produced somewhat higher       utility and as good or better satisfaction of a monthly budget than the feedback       training condition, despite never receiving any feedback about the monthly cost,       but the generalization to a new budget constraint proved to be slightly       poorer.
behavioural findings in several strategic games indicate that       people punish others if they think they are being treated ‘unfairly’       even at the cost of minimizing their own material payoff. we investigated the       primary driving force behind such altruistic cooperation. in experiment 1, we       replicated previous findings indicating that the key mechanism contributing to       the emergence of altruistic cooperation is fairness considerations. in experiment       2, we investigated the effect of the opportunity for reputation building and       future interaction on altruistic cooperation and found that these factors become       effective only when fairness considerations are removed.
information distortion is a cognitive bias in sequential       diagnostic reasoning. assumptions about the diagnostic validity of later evidence       are distorted in favor of the leading hypothesis. therefore the bias contributes       to a primacy effect. current parallel constraint satisfaction models account for       order effects and coherence shifts, but do not explain information distortion. as       an alternative a new, probabilistic constraint satisfaction model is proposed,       which considers uncertainty about diagnostic validity by defining probability       distributions over coherence relations. simulations based on the new model show       that by shifting distributions in favor of the leading hypothesis an increase in       coherence can be achieved. thus the model is able to explain information       distortion by assuming a need for coherence. it also accounts for a number of       other recent findings on clinical diagnostic reasoning. alternative models and       necessary future research are discussed.
the cognitive representation of a return path is a rather       unexplored topic including different issues, e.g., perception, mental imagery,       mental spatial processing, and language. we here investigated the return path       with landmarks located on different positions (optimal, suboptimal). participants       learned a total of 24 routes and had to produce the return paths (n=20). in a       second experiment the different positions plus map learning versus verbal       directions were investigated (n=20). both experiments reveal that the position of       a landmark at an intersection (structural salience) has an influence on       wayfinding performance. however, the results are somehow ambiguous. therefore, we       also present first approaches for predicting behavior (e.g., optimal route       descriptions) and for modeling the perceptual and cognitive processes involved in       finding the return path, including visibility, structural salience, mental       representation/ transformation, and language.
binocular rivalry displays and ambiguous figures such as the       necker cube elicit a perceptual reversal effect mediated by attentional and       perceptual processes. perceptual dominance times are highly variable between       individuals and may be partially influenced by genetic factors. this study       examined the role of putative genetic effects associated with familial       sinistrality, derived from a novel pedigree-based genetic model. in a continuous       necker viewing task, dominance times were significantly correlated (r-square =       .36) with a multifactorial estimate of genetic effects associated with non       right-handedness. no association with genetic estimates was found in an       intermittent viewing condition. these results suggest that genetic factors       associated with functional asymmetries may also affect noise-based perceptual       alternation, but not short term visual memory.
little is known about the how the decision is made to terminate       memory search, though there have been several recent attempts to uncover this       process. in one recent study, miller et al. (2012), re-analyzed data from a large       number of free-recall experiments and identified intrusions as a factor that       influenced search termination decisions. one potential problem with this       re-analysis is that all the data were drawn from experiments in which it was       impossible to determine if or when search was terminated. using data from       experiments in which search termination decisions were directly measured, we       confirmed miller at al.'s (2012) original findings but also demonstrated that       intrusions influence the time taken to generate the final retrieval and the time       between the final retrieval and search termination. the pattern of data is       consistent with a simple, sample-with-replacement model in which intrusions are       less active than items from the target list.
the conclusion that people are optimistic concerning personal risk       does not have a sound evidential basis. following harris and hahn’s (2011)       critique of unrealistic optimism research, we consider the evidence from a recent       series of high profile neuroscience papers. we demonstrate that the methods used       are fundamentally flawed. a simulation and an empirical comparison of autism       spectrum condition participants with typical adults confirm that we have learnt       nothing about optimism from these studies.
what psychological and linguistic processes allow one to go beyond       the literal meaning of a sentence and infer what was meant but not said       (“reading between the lines”)? theorists have differed as to whether       these phenomena are driven by complex, online inference processes or by       relatively rote rules. the present study uses erp to explore the cognitive and       neural mechanisms involved in scalar implicature (the inference that, e.g.,       “some” indicates “some but not all”), a test case that       has been subject to considerable behavioral research but limited       neuropsychological research. our results challenge both rote-processing and       rich-inference accounts. we provide the first erp results showing that scalar       implicature processing depends on context, challenging rote-processing theories       of implicature. however, we also fail to find evidence of a processing cost       associated with implicature processing, as predicted by many rich-inference       accounts. these results point to a novel conceptualization of pragmatic       processing in scalar implicature.
two studies examined how sampling of base rate information and       causal explanation of false positives facilitate intuitive probability judgments.        experiment 1a varied these two manipulations factorially.  each had an additive       effect on reducing base rate neglect and increasing choice of the normatively       correct solution.  experiment 1b showed that description of relevant       distributional information produced similar facilitation to sequential sampling.        these results indicate that causal and sampling approaches impact on different       components of probability judgment.
we present a novel way of accounting for similarity judgments.        our approach posits that similarity ratings stem from three main sources:       familiarity, priming, and inherent perceptual similarity.  we present a process       model of our approach in the cognitive architecture act-r, and match our model's       predictions to data collected from a human subject experiment which involved       simple perceptual stimuli.  familiarity accounts for rising ratings over time;       priming accounts for asymmetric effects that arise when the stimuli are shown       with different frequencies.  pure perceptual similarity also predicts trends in       the results.  overall, our model matched the data with r^2 of 0.99.
we present original evidence that abstract and concrete concepts       are organized and represented differently, based on statistical analyses of       thousands of concepts in publicly available datasets. first, we show that       abstract and concrete concepts have differing patterns of association with other       concepts. second, we test recent hypotheses that abstract concepts are organized       according to association, whereas concrete concepts are organized according to       (semantic) similarity. third, we present evidence suggesting that concrete       representations are more strongly feature-based than abstract representations. we       argue that degree of feature- based structure may fundamentally determine       concreteness, and discuss implications for cognitive and computational models of       meaning.       
making accurate judgments is an essential skill in everyday life.       however, little is known about the basic cognitive skills required for accurate       judgments. research on judgment and categorization processes suggests that people       rely on various strategies when making judgments. these strategies differ in the       cognitive abilities they require. specifically high working memory capacity may       benefit rule-based judgments, whereas good long-term memory may be crucial for       memory-based judgments. we investigated this hypothesis following an individual       differences approach. 177 participants performed two judgment tasks that were       either best solved by a rule-based or a memory-based strategy. additionally, we       measured working memory capacity and episodic memory with three tests. consistent       with our hypothesis structural equation modeling showed that working memory       capacity predicted judgment accuracy in the rule-based task whereas episodic       memory predicted judgment accuracy in the memory-based task. apparently,       different memory abilities are essential for successfully adopting different       judgment strategies.
this research demonstrates that preschoolers flexibly trust and       mistrust the same individuals, as preschoolers recognize that their intentions       may vary. in study 1 (n=101) 3- and 4-year-olds trusted speakers based on their       current, rather than previous, intentions to give in/correct information. thus       preschoolers infer the meanings behind different intentions and recognize that       intentions change within individuals over time. in study 2 (n=80) 3- to       5-year-olds trusted speakers who were currently sincere, but previously       intentionally inaccurate, rather than currently sincere, but previously ignorant,       showing that preschoolers infer current knowledge from prior intentions.       preschoolers also trusted speakers who were currently knowledgeable, although       previously ignorant, showing that they recognize knowledge is variable within       individuals. 
language is often regarded as a rich source of evidence about the       mind. however, a number of findings challenge this position, at least at the       level of words: where languages differ in their lexical distinctions, conceptual       differences are not always observed. we ask here how language might serve as a       window into the mind despite an apparently loose connection between words and       concepts. we propose that prominent conceptual distinctions, though not       necessarily captured by individual words, may be revealed by elements of meaning       shared by multiple words. testing this hypothesis in the domain of space, we show       that clusters of spatial terms, identified through dimensionality reduction       analyses of semantic similarity data, align with conceptual categories       spontaneously accessed during the perceptual discrimination of spatial relations.       these findings suggest that aspects of semantic structure beyond the level of       words may provide considerable insight into the conceptual system. implications       for research on linguistic relativity are discussed.
reasoning about others' preferences is an important aspect of       understanding the social world. although there is some evidence that young       children reason appropriately about others' discrepant preferences, there are       reasons to suspect this  ability remains fragile through the preschool years. in       particular, we argue that the way preferences are expressed may tap into humans'       lifelong tendency toward naïve realism, the belief that my way of seeing the       world is the normative, correct one. we present data demonstrating that tolerance       for unconventional opinions increases during the preschool years but remains       susceptible to influence by linguistic framing.
in the present study we investigated whether eye movements in       visual search are optimized to reduce time on task. subjects task was to find a       target object in a large field of objects that differed based on shape, color,       size and numeric label. the target specification was manipulated, directly       influencing the average number of fixations it took subjects to find the target       object. although a microstrategy that allowed for parallel saccade programming       and information processing was found to be more efficient in terms of time, a       serial microstrategy where saccade programming always follows information       processing was found to be the more prevalent microstrategy.
many moral psychologists have proposed that the difference between       people’s moral judgments about the trolley and footbridge dilemmas can be       explained by their differing emotional responses to the dilemmas. in two       experiments, we tested this explanation by presenting the dilemmas and measuring       participants’ reactions using a self-report emotion measure (panas-x). as       might be expected, participants experienced more intense emotions after reading       moral dilemmas when compared to a non-moral dilemma. however, participants’       emotional reactions to the trolley and footbridge dilemmas did not differ. our       findings call the oft cited emotion explanation into question.
children can learn new words in pedagogical contexts, but they may       also infer reference using a variety of other information sources. here we       investigate children’s sensitivity to the place- ment of novel labels       within discourse structure as a possible mechanism for word learning. in       experiment 1, children ages 2–6 years participated in word learning trials       featuring two novel items and one novel label. in critical trials, the labels       were embedded between two sentences about the same item, whereas in a control       condition, the label was introduced after two sentences about the item. children       of all ages were more likely to attribute the label to the toy whose descriptions       brack- eted the embedded label, and response strength increased with age.       children across all ages responded at chance in the control condition. in       experiment 2, adults showed the same patterns of responses as children in both       critical and control conditions. together, these results suggest that discourse       continuity is a reliable cue to reference for both children and adults.
in attempt to resolve the controversial issue of the influence of       the anxiety state on analogy-making this paper presents a replication of the       original tohill and holyoak study extending it with a new factor – the       complexity of the mapping. it turns out that the anxiety influence interacts with       the complexity of the mapping task. this has certain implications for the models       of analogy and for the further study of the role anxiety plays in       analogy-making.
although studies of categorization have been a staple of       psychological research for decades, there continues to be substantial       disagreement about how unique classes of objects are represented in the brain. we       present a neural architecture for categorizing visual stimuli based on the neural       engineering framework and the manipulation of semantic pointers. the model       accounts for how the visual system computes semantic representations from raw       images, and how those representations are then manipulated to produce category       judgments. all computations of the model are carried out in simulated spiking       neurons. we demonstrate that the model matches human performance on two seminal       behavioural studies of image-based concept acquisition: posner and keele (1968)       and regehr and brooks (1993).
quinian bootstrapping is susan carey's solution to fodor’s       paradox of concept learning. carey claims that contrary to fodor’s view,       not all learning amounts to hypothesis testing, and that there are ways in which       even primitive concepts can be learned. recently georges rey has argued that       carey’s attempt to refute radical concept nativism is unsuccessful. first       it cannot explain how the expressive power of mental representational systems       could increase due to learning. second, both fodorian circularity charges and       goodmanian problems of indeterminacy apply to carey’s examples of quinian       bootstrapping. i argue that carey’s examples of bootstrapping can be       amended to escape fodorian and goodmanian objections. i suggest some ways to       improve on our models of concept learning to this end. i also argue that skill       learning is the way for mental representational systems to increase their own       expressive power, that is, to enrich their conceptual repertoire beyond what       compositionality alone affords.
can our gestures help us think, and, if so, how? previous work       suggests that they can. here, students, alone in a room, studied descriptions of       environments for later tests of knowledge. the majority of participants       spontaneously gestured while reading the descriptions, and most of those also       gestured while answering true-false questions. they did not gesture       proportionately more time for environments with many landmarks than for       environments with few. their gestures laid out the environments, primarily using       points to places and lines for paths. descriptions and questions accompanied by       gestures were remembered more accurately. participants rarely looked at their       hands. gestures seem to promote learning by establishing embodied representations       of the environments.
retrieval that is based on common relational structure, such as an       underlying principle or pattern, is useful but typically rare. based on evidence       that comparison-derived schema abstraction can improve relational retrieval, we       asked whether the use of relational labels can also promote abstraction and       improve relational retrieval. using a cued-recall paradigm, we varied the       presence of relational labels at encoding and test. as compared to a no-label       baseline condition, relational retrieval improved when relational labels were       given at encoding and at test and also when relational labels were given only at       encoding. the findings demonstrate that one way to improve relational retrieval       is through the use of labels that name relational structure.
domain-general statistical learning (sl) is thought to support       language phenomena like verb bias and structural priming.  we explored this idea       by inducing these phenomena within a non-linguistic serial reaction time (srt)       task where participants learned an english-like artificial language using sl.  in       a series of two experiments we found error rates to be sensitive to verbs’       structural preferences and abstract structural priming.  the similarities between       the behaviour in this task and previous linguistic research suggests that this       method may be useful for studying the nature of sl in language learning and       processing.
social evaluations depend on our ability to interpret other       people’s behavior. in adults, these evaluations are influenced by our       perception of the competence and motivation of the agent: helping when it is       difficult to help is praiseworthy; not helping when it is easy to help is       reprehensible. here we look at young children’s capacity to make competence       attributions and its relation to their social evaluations. we find that as early       as 18-months, infants can use the time and effort associated with achieving a       goal-directed action to distinguish agents, and that infants prefer more       competent agents. when asked to choose between two agents who act as moral       bystanders and refuse to engage in a helpful action, we find a sustained       preference for the more competent agent until the age of three, when the       preference is reversed. we argue that the ability to calculate the cost and       benefits of goal-directed action originates in early childhood and plays a       fundamental role in moral reasoning.
the first two years of life are characterized by considerable       change in all domains – perception, cognition, action, and social       interactions.  here, we consider the statistical structure of visual input during       these two years. infants spanning the ages from 1 to 24 months wore body-mounted       video cameras for 6 hours at home as they engaged in their daily activities. our       data strongly suggest that the statistical structure of the learning environment       is dynamic and ordered. the available visual statistics are not stationary, but       rather they are gated by young children's developmental level. we find a rolling       wave of "see-saw" patterns over developmental time in two classes of important       social stimuli: first faces, then hands; and within hands, first       other-then-self-then-touching-then-holding. these ordered environments may help       learning systems “start small,” find the optimal path to the optimal       solution, and determine the architecture of the system that does the       learning.
syntactic constructions roughly correspond to sentence meanings.       previous research has shown that chinese children can associate an svo       construction with a causative event at age 2, but do not always map an sv       construction to a non-causative event even after reaching 5 years of age. the       latter results may be attributed to the fact that chinese allows       argument-dropping (jiang & haryu, 2010). this paper investigated chinese       adults’ syntax-semantics knowledge and found that even adults do not always       map an intransitive construction to a non-causative event, although they are       likely to use an intransitive construction to describe a non-causative event. the       results suggest that although chinese adults understand that causative and       non-causative events should typically be described using transitive and       intransitive constructions, respectively, the use of this knowledge in inferring       novel verb meanings seems to be regulated by the actual usage of sv sentences in       chinese.
redundancy reduction, or sparsity, appears to be an important       information-theoretic principle for encoding natural sensory data. while sparse       codes have been the subject of much recent research, they have primarily been       evaluated using readily available datasets of natural images and sounds. in       comparison, relatively little work has investigated the use of sparse codes for       representing information about human movements and poses. this paper proposes a       basic architecture for evaluating the impact of sparsity when coding human poses,       and tests the performance of several coding methods within this framework for the       task of mapping from a kinematic (joint angle) modality to a dynamic (joint       torque) one. we show that sparse codes are indeed useful for effective mappings       between modalities and examine in detail the sources of error for each stage in       the model.
we present a task-based model of human gaze allocation in a       driving environment. when engaged in natural tasks, gaze is predominantly       directed towards task relevant objects. in particular in a multi-task scenario       such as driving, human drivers must access multiple perceptual cues that can be       used for effective control. our model uses visual task modules that require       multiple independent sources of information for control, analogous to human       foveation on different task-relevant objects. building on the framework described       by sprague and ballard (2003), we use a modular structure to feed information to       a set of pid controllers that drive a simulated car and introduce a barrier model       for gaze selection. the softmax barrier model uses performance thresholds to       represent task importance across modules and allows noise to be added to any       module to represent task uncertainty. results from the model compare favorably       with human gaze data gathered from subjects driving in a virtual environment.
in line with usage-based accounts, recent psycholinguistic studies       have confirmed that frequency of occurrence impacts processing latencies for       multiword strings (e.g., arnon & snider, 2010). however, these studies have not       been concerned with the meaning of the multiword chunks in question, which is       central to accounts of formulaic language rooted in cognitive linguistics (e.g.,       wray, 2002). here, we address this issue by comparing processing latencies for       three types of multiword chunks: idiomatic expressions, meaningful compositional       phrases, and less meaningful fragments. all three chunk types were matched for       whole- and sub-string frequency. our results show that frequency facilitates       processing for all three chunk types, but to a lesser extent than their       “meaningfulness” (as assessed in a separate norming study),       indicating that the meanings of multiword expressions may have implications for       models of language processing which extend beyond those of frequency of       occurrence. 
many studies have examined the distinction between feature-and       relation-based categories (gentner, 2005; genter & kurtz, 2005; jung & hummel,       2009; tomlinson & love, 2011). those findings suggest that featural and relationl       categories have fundamentally different learning algorithms, where relational       categories rely on explicit representations and thus require working memory and       attention, as opposed to featural categories which may be learned more       implicitly. in this study, we investigated further the distinction between       feature-and relation-based category learning using a dual task methodology. our       results revealed an interaction: featural category learning was more impaired by       a visuospatial dual task than by a verbal dual task, whereas relational category       learning was more impaired by the verbal dual task. our results suggest that in       contrast to featural category learning, which may involve mainly non-verbal       mechanisms, relational category learning appears to place greater demands on more       explicit and attention-demanding verbal or verbally-related learning       mechanisms.
many people have had the experience of knowing what song will play       next on an album (even one heard only a few times). conversely, many people fail       to recognize an acquaintance encountered in an unfamiliar context. associations       can likely form simply because items appear nearby in time, and not only due to       semantic similarity. using surprise recognition testing, we examine the automatic       storage of associations between successively encountered words on a list of       incidentally studied words. many modern memory models assume storage of such       associations, but with little evidence as yet (e.g., cox & shiffrin, 2012; rem-ii       mueller & shiffrin, 2006). we find evidence for sequential associations, which       are further improved by shared semantics or study context. we also find improved       accuracy and response time for old words preceded by old words, and for new words       preceded by new words—regardless of the previous response.
previous research has found that people can use word-object       co-occurrences from ambiguous situations to learn word meanings (e.g., yu &       smith, 2007). however, most studies of cross-situational learning present an       equal number of words and objects, which may simplify the problem by, for       example, encouraging learners to use assumptions such as each word going with one       object. this paper presents several conditions in which the number of words and       objects do not match: either additional objects appear at random, or objects       appear sometimes without their intended words. these manipulations do generally       hurt learning in comparison to balanced conditions, but people still learn a       significant proportion of word-object pairings. the results are explored in terms       of statistics of the training trials—including contextual diversity and       context familiarity—and with the uncertainty- and familiarity-biased       associative model. parametric differences between conditions hint at hidden       cognitive constructs.
this paper examines the impact of thinking-aloud (ta) instructions       as well as of individuals' prior domain knowledge on information processing and       source evaluation during web search on a health-related topic. with regard to ta       instructions, prompted instructions that entailed evaluation prompts (as used in       some previous web search studies) were compared to neutral instructions (in line       with the standards defined by ericsson & simon, 1993) and to a silent condition.       to measure participants' (n = 44) information processing and source evaluation we       used a rich multi-method approach including eye-tracking methodologies, log file       data, and verbal protocols. results indicate that prompted ta instructions as       compared to neutral instructions significantly increased participants' verbal       reflections on information quality and on structural aspects of web pages, given       that participants possessed at least a moderate level of prior domain knowledge.       in addition, prompted instructions resulted in less linear viewing sequences on       the search engine results pages than the silent condition. finally, the higher       participants' prior domain knowledge the more intensely they scrutinized the       search results presented by the search engine and the smaller were their average       pupil sizes, which indicated lower cognitive load. the significance of the       results is considered in light of methodological as well as educational       implications.
previous work has identified a distributed, network of neural       systems involved in appraising the value of rewards, such as when winning $100.       we hypothesized that involvement of intraparietal sulcus (ips) in this network is       specialized for processing numeric rather than monetary value. to test our       hypothesis, we manipulated numeric magnitude and units to construct a range of       economic rewards (e.g., +$1, +100¢) in response to simple decisions.       consistent with our hypothesis, bold activity in ips was related to changes in       numeric magnitude, independent of monetary value, whereas activity in ofc was       associated with monetary value, independent of numeric magnitude. finally, by       using representation similarity analysis, we found that the information       represented in ips and ofc was more consistent with the patterns expected if       representations of numeric magnitudes or monetary values, respectively, were in a       compressive scale. together, these findings show the importance of numerical       cognition for understanding how the brain processes monetary rewards.
what makes something funny? humor theorists posit that       incongruity---perceiving a situation from different viewpoints and finding the       resulting interpretations to be incompatible---contributes to sensations of       mirth. in this paper, we use a computational model of sentence comprehension to       formalize incongruity and test its relationship to humor in puns. by combining a       noisy channel model of language comprehension and standard information theoretic       measures, we derive two dimensions of incongruity---ambiguity of meaning and       distinctiveness of viewpoints---and use them to predict humans' judgments of       funniness. results showed that both ambiguity and distinctiveness are significant       predictors of humor. additionally, our model automatically identifies specific       features of a pun that make it amusing. we thus show how a probabilistic model of       sentence comprehension can help explain essential features of the complex       phenomenon of linguistic humor.
mimicry and imitation are crucial mechanisms of social learning       and rapport.  further, mimicry informs essential social judgments formed not only       by the interacting party but also by third-party observers.  how sophisticated       are observer’s inferences from mimicry?  we examined this in the context of       observers’ use of mimicry to judge trustworthiness.  participants observed       a dyadic interaction in which a target mimicked or did not mimic a model.  prior       to observation, the model’s honesty was earlier defamed, or praised, in       front of some, but not other, targets. observers always knew the model’s       reputation. observers also knew which targets were aware of the model’s       reputation.  results suggest that observers’ use of mimicry in trust       judgments is very sophisticated it reflects not just the presence of mimicry, but       also the model’s moral reputation and, critically, knowledge of the       target’s awareness of the model’s reputation.  this sophistication       leads observers to rate targets as trustworthy when they mimic untrustworthy       models, but only when the observers know that the model reputation is unknown to       the target.
how individuals think about opposing or paradoxical categories       influences their social relationships. we found that chinese managers were more       likely than us managers to categorize attempts to outperform others as an       instance of both competition and cooperation. further, the chinese managers were       more likely than the us managers to perceive a given working relationship as       being both cooperative and competitive. the two findings were linked:       culturally-guided beliefs about whether the cooperation-competition paradox       should be integrated or kept separate influenced how individuals understood their       social relationships. more broadly, the implication is that category membership       and relations between categories are guided by cultural influences distinct from       the particulars of the categories themselves that normally enter into cognitive       science research on categories. in addition, those categorization choices are       consequential for the network of social relationships individuals form.
we present a highly performant, minimally supervised system for       the challenging task of unconstrained conceptual property extraction (e.g.,       "banana is fruit", "spoon used for eating"). our technique employs lightly       supervised support vector machines to acquire promising features from our corpora       (wikipedia and ukwac) and uses those features to anchor the search for plausible       unconstrained relations in our corpus. we introduce a novel backing-off method to       find the most likely relation for each concept/feature pair and produce a number       of metrics which act as potential indicators of true relations, training our       system using a stochastic search algorithm to find the optimal reweighting of       these metrics. we also introduce a human semantic-similarity dataset; our output       shows a strong correlation with human similarity judgements. both our gold       standard comparison and direct human evaluation results improve on those of       previous approaches, with our human judgements evaluation showing a significant       20 percentage point performance increase.
are observed links between musicality and non-native speech sound       processing due to superior sensory processing of temporal, pitch, and spectral       information, which benefits both musical and linguistic processing? native       english speakers discriminated norwegian tonal contrasts, non-linguistic       pure-tone analogues, norwegian vowels, and short tones differing in temporal,       pitch and spectral characteristics. musicality was measured using gordon’s       (1989) advanced measures of musical audiation (amma). after controlling for       effects of sex, non-verbal iq and previous language learning experience, the link       between amma scores and tonal contour discrimination was partially mediated by       pitch acuity. in addition, tonal contrast, pitch contour and vowel discrimination       were predicted by temporal and spectral acuity. no independent effects of musical       training were found. thus, links between musicality and non-native speech sound       processing appear to be mainly due to superior temporal, pitch or spectral       acuity, which, in turn, may play somewhat different roles in processing different       speech sounds.
during the school semester, students face an onslaught of new       material. students work hard to achieve initial mastery of the material, but soon       their skill degrades or they forget. although students and educators both       appreciate that review can help stabilize learning, time constraints result in a       trade off between acquiring new knowledge and preserving old knowledge. to use       time efficiently, when should review take place? experimental studies have shown       benefits to long-term retention with spaced study, but little practical advice is       available to students and educators about the optimal spacing of study. the       dearth of advice is due to the challenge of conducting experimental studies of       learning in educational settings where material is introduced in blocks over the       time frame of a semester. in this paper, we turn to two established models of       memory---act-r and mcm---to conduct simulation studies exploring the impact of       study schedule on long-term retention. based on the premise of fixed time each       week to review, converging evidence from the two models suggests that an optimal       review schedule obtains significant benefits over haphazard (suboptimal) review       schedules. further, we identify two scheduling heuristics that obtain near       optimal review performance: (1) review the material from u-weeks back, and (2)       review material whose predicted memory strength is closest to theta. the former       has implications for classroom instruction and the latter for the design of       electronic tutors.
why do languages have the categories they do? it has been argued       that spatial terms in the world’s languages reflect categories that support       highly informative communication, and that this accounts for the spatial       categories found across languages.  however, this proposal has been tested       against only nine languages, and in a limited fashion.  here, we consider two new       languages: máíhɨki, an under-documented language of peruvian       amazonia, and english.  we analyze spatial data from these two new languages and       the original nine, using thorough and theoretically targeted computational tests.       the results support the hypothesis that spatial terms across dissimilar languages       enable near-optimally informative communication, over an influential competing       hypothesis.
affect is important in motivated performance situations such as       negotiation. longstanding theories of emotion suggest that facial expressions       provide enough information to perceive another person’s internal affective       state. alternatively, the contextual emotion hypothesis posits that situational       factors bias the perception of emotion in others’ facial displays. this       hypothesis predicts that individuals will have different perceptions of the same       facial expression depending upon the context in which the expression is       displayed. in this study, cardiovascular indexes of motivational states (i.e.,       challenge vs. threat) were recorded while players engaged in a multi-issue       negotiation where the opposing negotiator (confederate) displayed emotional       facial expressions (angry vs. happy); the confederate’s negotiation       strategy (cooperative vs. competitive) was factorially crossed with his facial       expression. during the game, participants’ eye fixations and cardiovascular       responses, indexing task engagement and challenge/threat motivation, were       recorded. results indicated that participants playing confederates with       incongruent facial expressions (e.g., cooperative strategy, angry face) exhibited       a greater threat response, which arises due to increased uncertainty. eye       fixations also suggest that participants look at the face more in order to       acquire information to reconcile their uncertainty in the incongruent condition.       taken together, these results suggest that context matters in the perception of       emotion.
we consider the problem of language evolution in a population       setting, focusing on the case of continuous parameter learning. while theories of       phonetic change tend to emphasize the types of transmission errors that could       give rise to a shift in pronunciation norms, it is challenging to develop a model       that allows for both stability as well as change.  we model the acquisition of       vowel-to-vowel coarticulation in both single- and multiple-teacher settings,       considering progressively more restrictive prior learning biases. we demonstrate       that both stability and change are possible at the population level, but only       under fairly strong assumptions about the nature of learning and production       biases.
we examined whether a bilingual advantage can be found in older       bilinguals that share the same cultural background with monolinguals. sixteen       gaelic-english bilinguals over the age of 60 years were compared with three       monolingual control groups in performance on the simon task, as well as in       general intelligence and socio-economic status. some of the monolinguals were       bidialectal allowing us to also test whether switching between dialects can incur       similar cognitive benefits as bilingualism. results showed no group differences       in overall reaction times as well as in the simon effect suggesting that       individuals that share a cultural background may not exhibit differences in       inhibitory control even if they routinely use another dialect or another       language. this opens up the possibility that other factors associated with       bilingualism, like immigrant status, may be responsible for the bilingual       advantage found in some but not in other studies.
both response latency and phonetic variation reflect competition       among alternatives during the speech production process. a review of the       literature finds an apparent contradiction in the latency results. in some tasks       where latency is measured, similarity between targets and competitors results in       slower reaction times. in other tasks, similar competitors appear to facilitate       production times relative to non-similar competitors (though a lack of any       competition at all results in the shortest response latencies). with respect to       phonetic realization, experiments suggest that high levels of competition induced       by sufficiently similar competitors result in hyperarticulation of target       utterances. we present a bayesian model of speech production that formalizes the       selection and planning of spoken forms as noisy-channel communication among       different levels of processing. the model resolves the apparent contradiction       found in the latency results, and establishes a novel connection between those       results and observed patterns of hyperarticulation.
can linguistic structures influence how people perceive and       remember causal events? using a change-detection method, we presented       participants with direct causal scenes paired with either transitive (he       stretched the toy) or periphrastic sentences (he made the toy stretch.)       participants then viewed movies with changes to the manner of action (stretching       the toy with palms up vs. down), the result (stretching it a shorter vs. longer       distance), or no change. participants judged whether the two movies were       identical. reading periphrastic sentences made people more likely to notice a       change in manner than a change in result. reading transitive sentences had the       reverse effect – participants were more likely to notice changes in result.       this work provides an important advance in our understanding of how rich       conceptual representations map into the grammatical structures of language. we       discuss how this novel method can provide insight into the nonlinguistic       representations recruited by particular sentence structures.
computational accounts have traditionally focused on mapping       between structured representations as fundamental to analogical processing.       however, a recent connectionist model has been used to argue that structured       representations may not be necessary to solve verbal analogies. green and       colleagues (2010) have shown that brain areas associated with analogical mapping       become more engaged as semantic distance increases between verbal analogy source       and targets. herein, we had participants verify verbal analogies characterized       for semantic distance while we monitored their brain waves using eeg. our results       suggest that the semantic distance between the source and target of a verbal       analogy does influence early semantic processing as reflected in the n400       event-related potential. however, successfully differentiating valid and invalid       verbal analogies engages areas of prefrontal cortex widely associated with       inhibitory processing and the integration of abstract relations in working       memory. thus, it appears that traditional semantic priming alone is likely       insufficient to explain the full extent of analogical processing.
the temporal co-occurrence of a novel word and a visual referent       undoubtedly facilitates establishing the meaning of a word. it is less       understood, however, how precisely learners can keep track of the frequencies of       these co-occurrences across situations. observational learning may rely on one or       few highly informative exposures (propose-but-verify) or it may be driven by the       collection of evidence in a more gradual and parallel manner (multiple-hypotheses       tracking). we evaluated both hypotheses within two experiments and found that       learners were able to keep track of more than one hypothesis for a novel word.       however, this memory was strongly dependent on each learner’s individual       learning path (i.e., which meanings they had considered before) and influ-enced       by the order of presentation of potential referents. we argue for an account of a       multiple-proposal memory rather than a multiple co-occurrence memory.
can our decisions be guided by unconscious or implicit influ-       ences? according to the somatic marker hypothesis, emotion- based signals guide       our decisions in uncertain environments outside awareness. however, evidence for       this claim can be questioned on the grounds of inadequate assessments of       conscious knowledge. post-decision wagering, in which participants make wagers on       the correctness of their decisions, has been recently proposed as an objective       and sensitive measure of conscious content. in the experiments reported here, we       employed variations of a classic decision-making paradigm, the iowa gambling       task, in combination with wagering in order to investigate the role played by       unconscious influences. we also examined biases that affect wagering strategies       such as the definition of the optimal strategy and loss aversion. our results       demonstrate the inadequacy of post-decision wagering as a direct measure of       conscious knowledge and also question the claim that implicit processes influence       decision-making.
this study investigates to what extent visual saliency cues in       realistic visual scenes cause speakers to include a redundant color attribute in       their definite descriptions of objects, and in particular how such cues guide       speakers in determining which objects in the scene are relevant distractors, and       which not. first, regarding bottom-up cues, the results revealed that the       presence of clutter positively affected the redundant use of color, but that the       distance between a target and a distractor did not have an effect in this       respect. second, an effect of top-down saliency (i.e., whether a target’s       type was mentioned in the instructions) was only partially borne out by the data.       we argue that these findings are problematic for algorithms that aim to generate       psychologically realistic object descriptions, since these generally select       properties that help to distinguish a target from all distractors that are       present in a scene.
in naturally occurring speech and gesture, meaning occurs       organized and distributed across the modalities in different ways. the underlying       cognitive processes are largely unexplored. we propose a model based on       activation spreading within dynamically shaped multimodal memories, in which       coordination arises from the interplay of visuo-spatial and linguistically shaped       representations under given communicative and cognitive resources. an       implementation of this model is presented and first simulation results are       reported.
time is talked about in terms of space more frequently than the       opposite is true. past experimental evidence suggests that this asymmetry runs       deep, with results suggesting that temporal concepts and percepts find structure       in spatial representations but not vice versa. however, these studies frequently       involve verbal and/or visual stimuli.  because vision makes a privileged       contribution to spatial processing it is unclear whether these results speak to a       deep asymmetry between time and space, or a modality specific one. the present       study was motivated by this ambiguity and a complementary correspondence between       audition and temporal processing.  in an auditory perceptual task, duration and       spatial displacement judgments were shown to be mutually contagious.  irrelevant       temporal information influenced spatial judgments and vice versa with a larger       effect of time on space. the results suggest that the perceptual asymmetry       between domains does not generalize across modalities and that time is not       fundamentally more abstract than space.
two experiments in the visual world paradigm investigated       competition in sentence processing from dynamic event-related information about       location. in experiment 1, listeners viewed visual arrays with container objects       like a bowl, jar, pan, and jug, while they heard sentences like “the boy       will pour the sweetcorn from the bowl into the jar, and he will pour the gravy       from the pan into the jug. but first/and then, he will taste the       sweetcorn.” while “but first” contexts referred to the       “source” location of the discourse-final noun (e.g.,       “sweetcorn”), “and then” contexts referred to its       “goal” location. in experiment 2, listeners always heard “and       then” contexts. we found that listeners rapidly fixated context-relevant       locations. crucially, they also fixated locations that were context-irrelevant,       but related to the discourse-final noun, suggesting object competition, or       consistent with abstract location information implied by “but first”       (source) or “and then” (goal), suggesting location competition.
accounts of mechanistic explanation require that complex cognitive       phenomena can be decomposed into simpler subtasks. we provide a theory of       explanation that rationalizes this requirement, and then we use a simple genetic       algorithm exercise to demonstrate that evolution can produce designs that violate       this functional modularity requirement. 
we present an eye-tracking experiment investigating the time       course with which listeners derive pragmatic inferences from contextual       information. we used as a test case the construction “it looks like an       x” pronounced either with (a) a nuclear pitch accent on the final noun, or       (b) a contrastive l+h* pitch       accent and a rising boundary tone, a contour that can support a complex       contrastive inference (e.g., it looks like a zebra...(but it is not)). the       contrastive intonational contour elicited higher proportions of fixations to       non-prototypical target pictures (e.g., a zebra-like animal) during the earliest       moments of processing the target noun. further, when the display only contained a       single related pair of pictures, effects of the contrastive accent on       “looks” emerged prior to the target noun, indicating that efficient       referential resolution is supported by rapidly generated inferences based on       visual and prosodic context.
we investigate pre-schoolers’ ability in drawing pragmatic       inferences based on prosodic information. previous work has found that young       children are generally oblivious to intonational meaning of utterances. in       particular, the ability to comprehend contrastive prosody develops late during       language acquisition (after the age of 6). in three experiments, we show that       preschoolers can engage in prosody-based pragmatic inferences if the context       provides supports for them. furthermore, we find that preschoolers’       interpretation of prosody involves complex counter-factual reasoning (‘what       the speaker would have said if she had intended another meaning’). the       picture emerging from our studies contrasts with previous work: through rich       contextual inferences, four-year olds are able to bootstrap their interpretation       of prosodic information, and achieve adult like performance in intonation       interpretation.
recent studies hypothesize that language production is governed by       the principle of efficient information transmission: speakers tend to omit       elements whose information content is contextually predictable while providing       more linguistic signal to convey otherwise less predictable information. however,       previous findings in support of this hypothesis are also compatible with       alternative accounts based on production difficulty. to distinguish between these       competing accounts, we conducted       experiments on speaker’s preference in optional casemarking in japanese.       the results suggest that japanese speakers are more likely to omit the object       case-marker when an associated noun has semantic properties that are prototypical       to a grammatical object. moreover, case-marker omission was       facilitated when other elements in a sentence made the grammatical function       assignment more predictable. the results were obtained with all the factors       related to production difficulty held constant, and thus support the models of       communicatively efficient language production.
research investigating top-down attentional capture has       demonstrated a tight coupling of working memory content with attention and eye       movements. by capitalizing on this relationship, we have developed a novel       methodology called the memory activation capture (mac) procedure for measuring       the dynamics of working memory content supporting complex cognitive tasks (e.g.,       decision making, problem solving). by observing which items are preferentially       fixated in task irrelevant arrays containing task relevant information, we gain a       measure of working memory content as the task evolves through time. the efficacy       of the mac procedure is demonstrated in a hypothesis generation task. results       suggest a two-stage process following hypothesis retrieval whereby it undergoes a       brief period of heightened activation before entering a lower activation state       while being maintained for output. the present effects are of additional general       interest as they represent the first demonstrations of top-down attentional       capture driven by participant-established wm content retrieved from long-term       memory.
the detection and categorization of animate motions is a crucial       task underlying social interaction and perceptual decision-making. neural       representations of perceived animate objects are built in the primate cortical       region sts which is a region of convergent input from intermediate level form and       motion representations. populations of sts cells exist which are selectively       responsive to specific animated motion sequences. it is still unclear how and to       which extent form and motion information contribute to the generation of such       representations and what kind of mechanisms are involved in the learning       processes. we demonstrate how the proposed model automatically selects       significant motion patterns as well as meaningful static form prototypes.       sequence selective representations are learned in sts by fusing static form and       motion input from the segregated bottom-up driving input streams. cells in sts,       in turn, feed activities recurrently to their input sites along top-down signal       pathways, enabling predictions about future input.
young children tend to map novel words to novel objects even in       the presence of familiar competitors, a finding that has been dubbed the       “disambiguation” effect. theoretical accounts of this effect have       debated whether it is due to initial constraints on children’s lexicons       (e.g. a principle of mutual exclusivity) or situation-specific pragmatic       inferences. we suggest that both could be true. we present a hierarchical       bayesian model that implements both situation-level and hierarchical inference,       and show that both can in principle contribute to disambiguation inferences with       different levels of strength depending on differ- ences in the situation and       language experience of the learner. we additionally present data testing a novel       prediction of this probabilistic view of disambiguation.
to learn the meaning of a new word, children must solve two       distinct problems: identify the referent under ambiguity and determine how to       generalize that word’s meaning to new objects. traditionally, these two       problems have been addressed separately in the literature, despite their tight       relationship with one another. we present a hierarchical bayesian model that       jointly infers both the referent of a word in ambiguous con- texts and the       concept associated with a word. as a first step in testing this model, we provide       evidence that our model fits human data in a simple cross-situational concept       learning task.
secondary-level students encounter many difficulties in learning       complex systems with hierarchical levels. scaffolding is very critical in       teaching complex systems. we have two complementary research questions on       scaffolding: 1. how can we chunk and sequence the learning activities in teaching       complex systems? 2. how can we help students make connections across system       levels? a simulation-based environment teaching a chemical system was used as the       research instrument, and the study was conducted at a middle school setting. the       results showed that the sequencing method following the “from concrete to       abstract” principle produced better recall and comprehension of the system       concepts (knowledge integration), while the sequencing method aligned with the       casual structure of the system facilitated the construction of a better causal       model for transfer. the results also demonstrated that explicit level-bridging       scaffolding had positive effects on both knowledge integration and learning the       deep causal structure.  
in order to better understand how humans acquire knowledge, one of       the essential goals in cognitive science is to build a cognitive model of human       learning. however, manual construction of such cognitive models is time       consuming, and requires domain expertise. further, manually-constructed models       may still miss distinctions in learning which are important for instruction in       education. our prior work proposed an approach that finds cognitive models using       a state-of-the-art learning agent, simstudent, and we demonstrated that, for       algebra learning, the agent can find a better cognitive model than human experts.       to ensure the generality of that proposed approach, we further apply it to three       domains: algebra, stoichiometry, and fraction addition. to evaluate the quality       of the cognitive models discovered, we measured how well the cognitive models fit       to student learning curve data. simstudent discovers cognitive models that       predicts human student behavior better than the human-generated models.
in learned helplessness experiments, subjects first experience a       lack of control       in one situation, and then show learning deficits when performing or learning       another task in another situation. generalization, thus, is at the core of the       learned helplessness phenomenon. substantial experimental and theoretical effort       has been invested into establishing that a state- and       task-independent belief about controllability is necessary. however, to what       extent generalization is also sufficient to explain the transfer has not been       examined. here, we show qualitatively and quantitatively that bayesian learning       of action-outcome contingencies at three levels of abstraction is sufficient to       account for the key features of learned helplessness, including escape deficits       and impairment of appetitive learning after inescapable shocks.
people have generally been considered poor at probabilistic       reasoning, producing subjective probability estimates that far from accord to       normative rules. features of the typical probabilistic reasoning task, however,       make strong conclusions difficult. the present study, therefore, combines       research on probabilistic reasoning with research on category learning where       participants learn base rates and likelihoods in a category-learning task. later       they produce estimates of posterior probability based on the learnt       probabilities. the results show that our participants can produce subjective       probability estimates that are well calibrated against the normative bayesian       probability and are sensitive to base rates. further, they have accurate       knowledge of both base rate and means of the categories encountered during       learning. this indicates that under some conditions people might be better at       probabilistic reasoning than what could be expected from previous research.
expertise is easy to identify in retrospect. it is the most ex-       pert player who wins the meet and the most proficient team that wins the       playoffs. however, sometimes during play we see a masterful move that clearly       separates one player from the competition. our goal, in this work, is to identify       the masterful moves or elements of expertise that predict the con- tinuum of       performance in the game of tetris. as a first step we have collected data from a       wide variety of tetris tourna- ment players and used it to derive metrics of       global, local, and immediate interactions. here we present statistical models of       these data and report the initial success of these models at predicting level of       expertise.
recent evidence has suggested that the relationship between a        test of fluid intelligence, raven's progressive matrices, and working memory       capacity (wmc) may be invariant across difficulty levels of the raven's items. we       show that this invariance can only be observed if the overall correlation between       raven's and wmc is low. we demonstrate that by using a composite measure of wmc,       which yields a higher correlation between wmc and raven's than reported in       previous studies, that there was a significant positive relationship between       raven's item difficulty and the extent of the itemwise correlation with wmc. this       result puts strong constraints on theories of reasoning and challenges some       existing views.
time concepts are named differently across the world's languages.       in english, the names for days of the week and months of the year are       opaque—to people learning and using english, there's no obvious reason why       friday or september have the names they do. but in other languages, like chinese,       time concepts have numerically transparent names—the days of the week and       months of the year are named using sequential numbers. we investigated whether       having opaque versus mathematically transparent time concepts affects how people       reason about time. results show that chinese speakers are more likely to       spontaneously employ arithmetic when doing temporal calculations, which in turn       improves the speed and accuracy of some time calculations. english speakers       appear to use other strategies, such as sequential recitation.
spatial ability tests like mental rotation and paper-folding       provide strong predictions of an individual’s achievement in science and       engineering. what cognitive skills are involved in them? we use a computational       model to analyze these tasks, asking how much information must be processed to       perform them. the models demonstrate that in some cases stimuli can be vastly       simplified, resulting in consistent performance regardless of stimulus       complexity. the ability to produce a scaled-down representation of a complex       stimulus may be a key skill underlying high spatial ability.
past research has uncovered evidence of social influences on a       wide variety of behaviors.  everything from our choice of clothing to smoking       appears to be shaped by the people we know.  however, little is known about the       mechanisms that underlie these influences. here, we report a series of       agent-based simulations demonstrating that information diffuses across social       networks in much the same way that behavior diffuses.  these findings lead us to       conclude that many previously observed social influences on behavior likely rely       on a substrate of information transmission and representation.
during collaboration, people communicate using verbal and       non-verbal cues, including gaze cues. social factors can affect gaze allocation,       however most research on gaze cueing has not considered these factors. the       presence of social roles was manipulated in a collaborative task whilst eye       movements were measured. in pairs, participants worked together to make a cake.       half of the pairs were given roles (“chef” or “gatherer”)       and the other half were not. across all participants we found, contrary to the       results of static image experiments, that participants spent very little time       looking at each other, challenging the generalisability of the conclusions from       lab-based paradigms. when given spoken instructions, listeners in the roles       condition looked at the speaker significantly more than listeners in the no roles       condition. we conclude that our tendency to seek the gaze cues of collaborators       is affected either by our social perceptions of the collaborator or their       perceived reliability.
the paper presents two studies that investigated how individuals       reason from disjunctive statements that use numerical estimations. in the       experiments two types of such statements were used. in the first type both       constituents of a disjunction could be a logically correct answer. that is, if       “the average life time of a fruit fly is either 9 or 27 days”, any of       those numbers is logically possible. in the second type that truth of one       constituent excluded the truth of the other, e.g. “the average time of       holidays in the eu is either higher than 9 days or else higher than 27       days”. a simple repetition of any of those figures is an illusory inference       as it renders both constituents true. the results of experiment 1 proved that       although the participants showed a tendency to repeat one of the disjuncts as       their answer, this tendency was smaller when the content of the statements       referred to politics and social life in comparison with the general knowledge       questions. the results of experiment 2 showed that individuals reveal the       tendency to repeat opinions coming from speakers who are more likeable, even if       such opinions are incorrect illusory inferences. the results of both studies show       that illusory inferences appear also in the domain of numerical cognition but       they may be reduced by pragmatic factors such as the content of the message and       the knowledge about its source.
the aim of this paper is to briefly illustrate how the theoretical       framework of cognitive niches can prove useful to frame not       only the cultural development of human beings, but the naturalization       of morality as well.
in this article we demonstrate how algorithmic probability theory       is applied to situations that involve uncertainty. when people are unsure of       their model of reality, then the outcome they observe will cause them to update       their beliefs. we argue that classical probability cannot be applied in such       cases, and that subjective probability must instead be used. in experiment 1 we       show that, when judging the probability of lottery number sequences, people apply       subjective rather than classical probability. in experiment 2 we examine the       conjunction fallacy and demonstrate that the materials used by tversky and       kahneman (1983) involve model uncertainty. we then provide a formal mathematical       proof that, for every uncertain model, there exists a conjunction of outcomes       which is more subjectively probable than either of its constituents in isolation.       
a social simon effect exists when two individuals perform a       go/no-go task in the presence of each other, but not when they perform the same       task alone. such effects are argued to indicate that individuals co-represent       task goals and the to-be-performed actions of a co-actor. the present study       investigates an alternative hypothesis—that these effects are due to       dynamical entrainment processes that couple the behavior of socially situated       actors. participants performed a standard go/no-go simon task in joint and       individual conditions. the dynamic structure of response times (rts) was examined       using nonlinear methods. consistent with our hypothesis, the analyses revealed       that the structure of rts in the joint condition indicate interpersonal coupling       constraining participant behavior and were more correlated across a range of       time-scales compared to the rts of pseudo-pair controls. the findings imply that       dynamic processes might underlie social stimulus-response compatibility effects       and shape joint cognitive processes in general.
how are we able to reason about abstract concepts that lie       resolutely beyond the reach of perception? one strategy is to ground       understanding in space. numbers, for instance, are known to interact with       egocentric space during rapid numerical judgments. a range of experimental       results have demonstrated that, among literate western people, this “mental       number-line” goes from left to right, with smaller numbers associated with       left space, and larger numbers with right space. but what is the nature of this       “space”? previous work has conflated multiple possible egocentric       frames of reference—head-based, eye-based, action-based—leaving it       unclear which space is interacting with number. in the present paper, two studies       investigated whether a single centrally-located button, stationary in hand- and       eye-based coordinates, can nevertheless exhibit different spatial properties in       virtue of task-specific activity. in a go/no-go paradigm, participants judged the       magnitude (exp. 1) and parity (exp. 2) of single-digit numbers. crucially, they       responded only with the index or middle finger of a single hand. while judging       magnitude (exp. 1), participants were faster to respond to smaller numbers with       the more leftward finger, and larger numbers with the more rightward finger,       regardless of the hand being used. this effect disappeared when judging parity       (exp. 2), replaced by finger-specific associations on the left hand only. in sum,       in a task-sensitive way, participants associated numbers with egocentric       space—but a behavioral space defined relative to embodied interaction       rather than head- or eye-based reference frames. we discuss implications for       number representation and the nature of “space” in embodied       activity.
technology has become integrated into many facets of our lives.       due to the rapid onset of this integration, many current k-12 teachers do not       have the skills required to supply the sudden demand for technical training. this       deficit, in turn, has created a demand for professional development programs that       allow working teachers to learn computer science so that they might become       qualified to teach this increasingly important field. subgoal labeled worked       examples have been found to improve the performance of learners in highly       procedural domains. the present study tested subgoal labeled worked examples in       an online learning program for teachers. teachers who received the subgoal labels       solved novel problems more accurately than teachers who received the same worked       examples without the subgoal labels. these findings have implications for the use       of subgoal labels in professional development, other types of lifelong learning,       and online learning.
we explored people’s reactions to expert categorizers who       expressed difficulty in making a categorization decision. specifically, we       compared people’s impressions of expert health professionals who either       expressed certainty, uncertainty, or ambivalence about a categorization decision       in the form of a diagnosis. we found that ambivalence resulted in the most       negative impressions of these experts, including lower ratings of competence and       decisiveness (experiment 1). impressions of ambivalence did not improve when the       complexity of the decision was explicitly manipulated (experiment 2).       implications for categorization are discussed. 
in the literature on verbal human-computer interaction there       is general consent that humans’ preconceptualisations of the       machine’s capabilities lead to conceptual and syntactic simplifications       of the language used. we present a wizard of oz /       confederate study where humans communicate with either a       system or an expert in a localization task in a complex building,       in a setting which encourages them to give as much information       as possible. we analyzed the syntactic complexity       of object descriptions. although we did find differences concerning       the complexity of object descriptions on the clausal       level, there were no significant structural differences on the       subclausal level.
the question how agent and patient roles are assigned to causal       participants has largely been neglected in the psychological literature on force       dynamics. based on the linguistic theory of dowty (1991), we propose that agency       is a prototype concept. we adapted dowty’s theory to account for scenarios       showing physical interactions. in the standard michotte launching scenario the       ball entering the scene is usually assigned the agent role, whereas the ball that       is being launched is viewed as the patient. we showed in two experiments that       agency intuitions were moderated by manipulations of the context prior to the       launching event. altering features such as relative movement, sequence of       visibility, and self-propelled motion tended to increase agency attributions to       the patient relative to the standard scenario. we suspect that shifts in       figure-ground perceptions, and intuitions about characteristics of interventions       may be the overarching reason for the efficacy of the tested criteria.
causal reasoning is a critical part of everyday cognition. we ask       how people reason about causes when faced with inconsistent sources of knowledge.       causal models arise from multiple sources of information regarding their       constituent parameters. knowledge sources may be inconsistent both within       parameters (when one source says a variable should appear often and another says       it should appear rarely), and between parameters (when dependencies among       parameters result in an internally inconsistent causal model). we provide a       normative model for resolving both these sources of conflict. an experiment found       that our model of belief integration predicted the qualitative pattern of adults       causal inferences under uncertainty.
in this paper we examine the idea of a "naïve physics" in       humans solving physics problems. this invokes the idea that people have a theory       of motion in their heads that is non- newtonian, and hence leads to systematic       errors on these problems. we are able to show that, by selecting our problems       carefully, it is possible to obtain answers that are consistent with this       naïve physics and inconsistent with it; suggesting that it is not used to       solve these problems but sometimes offered as post-hoc justification for the       answers given. we offer evidence that the answers given owe more to past       experience than any theory, and that a theory that postulates extrapolation on       the basis of associative memory can give a good account of our results.
in sequential diagnostic reasoning, the goal is to infer the       probability of a cause event from sequentially observed effects. typically,       studies investigating such tasks provide subjects with precise quantitative       information regarding the strength of the relations between causes and effects.       by contrast, we examined people’s performance when this information is       communicated through qualitative, rather vague verbal terms (e.g., “x       occasionally causes symptom a”). we conducted an experiment in which we       compared subjects’ judgments with a bayesian model whose predictions were       derived using numeric equivalents of various verbal terms from an unrelated study       with different subjects. we found a remarkably close correspondence between       subjects’ diagnostic judgments based on verbal information and the       model’s predictions, as well as compared to a matched control condition in       which information was presented numerically. additionally, we observed       interindividual differences regarding the temporal weighting of evidence.
humans can perform several different tasks on the same set of       stimuli in rapid alternation.  each task, signaled by a distinct task cue, may       require the classification of stimuli using a different stimulus attribute.       however, such "task switching" performance comes at a cost, as expressed by       weaker performance when switching rather than repeating tasks. this cost is often       claimed to be the consequence of a mental reorientation away from the previous       task and towards the new task, requiring executive control of behavior.       alternatively, task switching could simply be based on the retrieval of different       cue-stimulus-response associations. in this experiment, pigeons learned       go-left/go-right discriminations between grating patterns according to either       their spatial frequency or their orientation, depending on the color of the       pattern (the task cue). when humans solved the same tasks on the basis of       verbalizable rules, they responded more slowly and made more errors on trials       where they had to switch between tasks than when repeating the same task. pigeons       did not show this "switch cost"; but like humans, their performance was       significantly worse when the response (left or right) to a given stimulus varied       between tasks than when it stayed the same (the “congruency effect”).       larger effects of both switch costs and congruency were observed in humans       learning the tasks by trial and error. we discuss the potential driving factors       behind these very different patterns of performance for both humans and       pigeons.
this study examined the relationship between human body movements       and emotion based on laban movement analysis (lma). ten participants participated       in the experiment in which they stayed at a small resting room while hearing       pleasant or unpleasant sounds. after the stay at the room, the participants rated       their subjective emotional states. participants' body movement were also recorded       with four video cameras. the movement analysis based on lma reveled  significant       differences in movement features between experimental conditions. in addition,       significant correlations between movement features and subjective mood ratings       were observed. these results suggest a strong relationship between human body       movements and emotion.       
i argue that linear correlations between log word frequency,and       lexical measures, cannot be taken as evidence for a "principle of minimum       effort". the principle of maximum entropy  indicates that such relations are in       fact the ones most probable to be found. for such claims, one needs to compare       the correlations with adequate baselines reflecting what would be expected in a       purely random system. i then introduce a way of computing such baselines, and use       it to show that the correlations found in a corpus are actually weaker than what       one would expect to find by chance. therefore, if an argument were to be made       based on them, it would paradoxically be that language is worse for communication       than what one would expect to find in a random system. more appropriately       however, what these results reflect is that such correlations are not the best       places to look for linguistic optimality.
we show that social roles alter creativity assessments.       specifically, the two main roles in the innovation process – generator       roles for producing new ideas and implementer roles for selecting ideas to pursue       – invoke different lay theories about what is creative. study 1 showed that       implementers rated a low novelty version of an idea as more creative than a high       novelty version, but generators did the opposite. study 2 showed that generators       rated a low usefulness idea as more creative than a high usefulness idea, but       implementers did the opposite. thus, complementary roles prompted competing       perspectives.  these findings underscore a new challenge for the social       distribution of knowledge-intensive work.
the two-system hypothesis states that there are two kinds of       reasoning systems, the first of which is evolutionarily old, heuristically (or       associatively) based, automatic, fast, and is a collection of independent       systems. the second is evolutionarily new, perhaps peculiar to humans, is       rule-based, controlled, slow, and is a single token system. advocates of the       two-system hypothesis generally support their claim by an inference to the best       explanation: two systems are needed to explain experimental data from the       reasoning, heuristics, and biases literature. the best evidence for this claim       comes from simultaneous contradictory belief (henceforth scb) (sloman 1996,       2002). i argue that sloman has not provided us with cases of scb. in each of his       examples there is no evidence that the beliefs are held simultaneously. i then       offer the outline for an experimental setup that would offer compelling evidence       for the existence of scb and thereby support the two-system hypothesis.
we demonstrate that an ideal observer model bounded by known       limitations of the human visual system can explain empirical evidence concerning       two effects of distractor ratios on visual search—effects that have       previously been explained with salience-based models. the model makes optimal       state estimations based on bayesian estimates of stimuli localization and optimal       control decisions of where to fixate in order to maximize task performance.       analysis of the model’s behavior under different task strategies and       different constraints on the visual system reveal which aspects of the model are       responsible for the effects: the distractor-ratio effects on number of fixations       is a signature of optimal state estimation in the face of noisy spatial       information, and the saccadic-bias effect is a signature of both optimal control       and estimation under these same bounds.
the aim of this paper is to argue that action-guiding vision is       not cognitively impenetrable and arguments that suggest otherwise rely on an       unjustified identification between action-guiding vision and dorsal vision       – a functional and an anatomical way of describing the mind. the       examination of these arguments show the importance of making a distinction       between the functional and the anatomical level when addressing the problem of       cognitive penetrability.
making inference in everyday life often requires people to make       inferences about low frequency events. in the most extreme case, some types of       object or event may have never been previously observed. an experiment is       presented in which participants needed to infer the existence and number of       unobserved event types, based solely on the frequency distribution of a set of       observed events. results indicate people's inferences are sensitive to the shape       of the distribution over the observed events, even when the number of observed       events and event types is held constant, and that people are able to infer       abstract rules that describe entire classes of event distributions. human       inferences are shown to be similar to those made by a hierarchical bayesian       model.
beliefs frequently undergo revisions, especially when new pieces       of information are true but inconsistent with current beliefs. in previous       studies, we showed that spatial belief revision is often guided by the functional       asymmetry between the reference object and the located objects of the spatial       relation. here we first draw a connection between spatial belief revision and       grounded cognition. in two experiments, we explored whether imagined physical       properties of objects influence which object is relocated and which remains at       its initial position. participants mentally revised beliefs about the arrangement       of objects which could be envisaged as small and large (experiment 1) or easy to       move and difficult to move (experiment 2). the results show that (1) small       objects are more often relocated than larger objects and (2) easy to move objects       are faster relocated than difficult to move objects. the findings are in line       with the idea of grounded cognition.
certain difficulties of a word learning situation can promote       long-term learning, and thus are referred to as "desirable difﬁculties".       we use a computational modelling approach to examine the possible explanatory       factors of the observed patterns in a cross-situational word learning experiment.       our results suggest that the within-trial ambiguity and the presentation duration       of each trial in addition to other distributional characteristics of the input       (experimental stimuli) may explain these results. our ﬁndings also       emphasize the role of computational modelling in understanding empirical       results.
first, we argue for the metaphysical claim that emotions are       individuated as patterns of characteristic features. our second claim concerns       the epistemology of emotion recognition: we demonstrate that emotion recognition       is a process pattern recognition that relies on the same type of pattern       recognition typical for object recognition. the analogy allows us to defend a       variant of a direct perception account of emotion recognition. we distinguish two       forms of directly perceiving emotions: 1. perceiving an emotion (almost) without       any top-down-processes, 2. perceiving an emotion involving some significant       top-down-processes (including expectations and background knowledge), and in       addition 3. an inference-based evaluation of an emotion.
we present an execution model for manipulation of working memory       content during intellectual symbolic working memory tasks, which allows random       access of wm content through a schema-operated sensory-motor spatial working       memory. the core concept of this framework is binding symbolic items to spatial       locations which are accessible via selective mechanisms of attention in space. an       operational schema implements basic wm management operations such as insertion,       deletion and fetching through sequences of shifts in spatial attention towards       registry locations. we apply the model to a serial recall task (both forward and       backward orders). we show that the model provides a better fit to human data in       backward recall compared to forward recall, which conforms with the evidence for       leveraging spatial strategies for backward recall and  phonological strategies       for forward recall in normal subjects. we discuss additional possible       implications of our model and its assumption of spatial organization of wm       content and access through shifts of attention.
auditory overshadowing occurs when the presence of an auditory       stimulus interferes with visual processing. the current study tested whether this       occurs due to a privileged attentional status of auditory input or due to the       dynamic characteristics of auditory input. to address these questions,       preschoolers completed one of four discrimination tasks.  in the sound, motion,       and item baseline conditions, children discriminated these single information       types by judging whether paired stimuli were the same or different. in the       combined condition, children discriminated changing sounds, motions, or items in       the face of competing input in the other two dimensions. although       children’s discrimination of all information types attenuated in the       combined condition relative to baseline, motion and item discrimination       attenuated more than auditory discrimination. this provides evidence that early       in development auditory information receives privileged processing in the face of       competing input. 
while previous research has shown that working memory capacity       (wmc) predicts sentence processing ability, the understanding of the relationship       is limited as almost all studies have used the reading span task as their sole       measure of wmc.  the current study examined how the effects of garden-path       sentences and filler-gap dependencies (as indexed by the p600) related to four       measures of working memory (reading span, operation span, anti-saccade and       n-back). p600 effects for garden-path sentences correlated positively with       operation span score while effects for object relatives correlated negatively       with n-back accuracy.  these results indicate that, though both sentence types       are associated with increased working memory demands, the resolution of temporary       syntactic ambiguity and filler-gap dependencies recruit distinct working memory       mechanisms.
questionnaires to assess goal orientation are widely used.        however, recent research indicates some shortcomings.  most significantly,       questionnaire data are unable to capture developments and changes in       students´ goal orientation during the learning process.  therefore, it seems       appropriate to supplement questionnaire data with online measures that directly       tackle students’ behavior.  we analyzed data of 57 students who       participated in a study with the cognitive tutor geometry.  specifically, we       analyzed relationships between questionnaire data on goal orientation, the use of       hints and a glossary while working with the tutor as potential online indicators       for goal orientation, and learning outcomes.  results of our analyses show that       our potential online indicators systematically differ from questionnaire data of       goal orientation, yet have high predictive power for learning outcomes.        therefore, online indicators may be used to supplement questionnaire data of goal       orientation and/or to further optimize adaptation in intelligent tutoring       systems. 
semantic interference in word retrieval has been observed for both       well-learned and ad hoc inter-item relations. we tested whether such semantic       interference extends to the blocked cyclic naming of racially homogeneous vs.       heterogeneous faces. no information except arbitrarily assigned names was       provided for novel faces. yet we observed interference in naming individuals in       homogeneous groups. moreover, consistent with other findings in the social       domain, interference occurred for other-race but not for own-race faces. because       this interference effect does not require a rich knowledge base about       individuals, it is consistent with the view that interference arises in       adjustments to the strength of conceptual-lexical links rather than in knowledge       structures themselves. evidence of modulation by target race further suggests       that interference effects may provide an effective tool for exploration of social       categorization processes.
decision making is a dynamic process. alternatives compete over       time, and this competition plays out in sensorimotor processes. this is true not       just for perceptual decisions or simple categorisation tasks, but also for moral       decisions, which are the outcome of a complex interplay of intuition, emotion and       reasoning. in this experiment, we first establish a descriptive and causal link       between gaze and moral judgement. we then use eye movements to track the time       course of participants’ moral decisions and show that by interrupting their       decision process based on their gaze position, we are able to influence what they       decide. we interpret this as evidence for a dynamical systems view of decision       making and argue that our results provide new insights into how judgements are       reached and constructed in our embodied minds.
in interpersonal interaction, the terms synchrony or alignment       refer to the way in which communication channels like speech or body movement       become intertwined over time, both across interlocutors and within a single       individual. a recent trend in alignment research has targeted multimodal       alignment, exploring how various communication channels affect one another over       time (e.g., louwerse et al., 2012). while existing research has made significant       progress in mapping multimodal alignment during task-based or positively valenced       interactions, little is known about the dynamics of multimodal alignment during       conflict. we visualize multimodal alignment during naturalistic affiliative and       argumentative interactions as networks based on analyses of body movement and       speech. broadly, we find that conversational contexts strongly impact the ways in       which interlocutors’ movement and speech systems self-organize       interpersonally and intrapersonally.
in everyday communication, people not only use speech but also       hand gestures to convey information. one intriguing question in gesture research       has been why gestures take the specific form they do. previous research has       identified the speaker-gesturer’s communicative intent as one factor       shaping the form of iconic gestures. here we investigate whether communicative       intent also shapes the form of pointing gestures. in an experimental setting,       twenty-four participants produced pointing gestures identifying a referent for an       addressee. the communicative intent of the speaker-gesturer was manipulated by       varying the informativeness of the pointing gesture. a second independent       variable was the presence or absence of concurrent speech. as a function of their       communicative intent and irrespective of the presence of speech, participants       varied the durations of the stroke and the post-stroke hold-phase of their       gesture. these findings add to our understanding of how the communicative context       influences the form that a gesture takes. 
previous studies show that reading sentences about actions leads       to specific motor activity associated with actually performing those actions. we       investigate how sign language input may modulate motor activation, using british       sign language (bsl) materials, some of which explicitly encode direction of       motion, vs. written english, where motion is only implied. we find no evidence of       action simulation in bsl comprehension, but replicate effects of action       simulation in comprehension of written english. the results suggest that the       perception of motor articulation in the language input interferes with mental       simulation involving the motor system.
eye gaze and behavioral mimicry are important foundations of       social interaction. inspired by recent studies on eye-gaze me- diated spontaneous       behavioral mimicry of gestures, we studied the effect of eye gaze direction on       vocal mimicry. participants were instructed to repeat digits spoken by a virtual       agent with a direct or averted eye gaze. as a measure of imitation, the vocal       pitch was recorded and analyzed in order to determine if and to what extent vocal       mimicry was modulated by eye gaze. the results showed that eye gaze direction       affects vocal mimicry as measured by pitch slope. that is, when partici- pants       were exposed to an agent that gazed at them directly, they accommodated their       intonation more to that of the agent, than when they were exposed to an agent       that averted its gaze. these results suggest that in social interaction with a       virtual agent, humans mimic vocal intonation and that the degree of mimicry       depends on the eye-gaze direction of the agent. the implications for studies of       social interaction are discussed.
in a series of experiments conducted with dutch native speakers,       we explored systematic size/power sound-symbolic associations in novel and       existing words. in experiment 1 (n = 64),   participants associated       vowel-intrinsic fundamental frequency with size/power, disregarding the modality       of stimuli presentation (spoken, written), but depending on the lexical status of       the stimulus (more strongly for novel then for existing words). in experiment 2       (n = 56), we explored the idea that the order of vowels in a word affects       sound-symbolic associations, as pitch contours emerge from a sequence of       vowel-intrinsic fundamental frequencies. participants perceived stimuli with       'rising' combinations of front-back vowels as less powerful than stimuli with       ‘falling’ combinations. this finding indicates that even in non-tonal       languages, sound symbolism is not bound to a single segment (phoneme). we       compared the effect to the perception of tones in a tonal language, which we       explored in experiment 3 with mandarin native speakers (n = 96) judging the       perception of power in monosyllabic novel brand names with four different tones       (rising, falling, level and fall-rise). in experiment 4 (n = 146), we examined       the effect of vowel-intrinsic intensity, which has previously remained un-noted.       the results showed that like fundamental frequency, also intrinsic intensity       influences size/power-symbolic associations. 
philosophers traditionally held that knowledge is justified true       belief. gettier (1963) challenged this view with thought experiments in which       someone has a justified and true belief, but an element of luck is involved that       disqualifies the belief from counting as knowledge. we examined laypeople’s       concept of knowledge using a semantic integration paradigm modeled after that of       gentner (1981). participants read stories in which a character       ‘thought’ something was true. on a subsequent recall task, readers       sometimes falsely recalled the verb ‘thought’ as ‘knew,’       implicitly indicating that the reader had attributed knowledge to the character.       false recall of ‘knew’ occurred more frequently when the story       described a justified true belief than an unjustified belief. justified true       belief triggered these recall errors even in a so-called “gettier       case”. the present findings suggest that semantic integration provides an       empirical paradigm suitable for investigating lay notions about knowledge. 
recent work on causal learning has investigated the possible role       of generic priors in guiding human judgments of causal strength. one proposal has       been that people have a preference for causes that are sparse and       strong—i.e., few in number and individually strong (lu et al., 2008).       evidence for the use of sparse-and-strong priors has been obtained using a       maximally simple causal set-up (a single candidate cause plus unobserved       background causes). here we examine the possible impact of generic priors in more       complex, multi- causal set-ups. sparse-and-strong priors predict that competition       can be observed between candidate causes even if they occur independently (i.e.,       the estimated strength of cause a will be lower if the strength of uncorrelated       cause b is high rather than low). experiment 1 revealed such a cue competition       effect in judgments of causal strength. experiment 2 showed that, as predicted by       a bayesian learning model with sparse-and-strong priors, the impact of the prior       diminishes as sample size increases. these findings support the importance of a       preference for parsimony as a constraint on causal learning.
when two persons participate in a discussion, they not only       exchange the concepts and ideas they are discussing, they also express attitudes,       feelings and commitments regarding their partner: they express interpersonal       stances. endowed with backchannel model, several virtual agents are able to react       to       their partners’ behaviour through their non-verbal behaviour. in this       paper, we go beyond this approach, proposing and testing a model that enables       agents to express a dyadic stance, marker of effective communication: agents will       naturally co-construct a shared dyadic stance if and only if their interpersonal       stance is reciprocally positive. we focus on smile, which conveys interpersonal       stance and is a particularly efficient signal for co-regulation of communication.       with this model, a virtual agent, only capable to control its own individual       parameters, can, in fact, modulate and control the dyadic stance       appearing when it interacts with its partner. the evaluation of the model through       a user perceptive study has enabled us to validate that the dyadic stance is       significantly perceived as more positive (mutual understanding, attention,       agreement, interest, pleasantness) when reinforcement of smile is reciprocal.       
we report a study of naming and lexical decision with 132 adult       greek speakers responding to 150 words and matched pseudowords with decorrelated       frequency, length, neighborhood, syllable and bigram frequency, and transparency.       this approach allowed us to individuate and accurately estimate the effects of       each variable, and to assess their linearity and additivity. significant effects       of frequency, length, and syllable frequency were revealed, as well as several       interactions. the results are informative for cognitive modeling of visual word       recognition in more transparent orthographies.
political scientists are increasingly turning to game-theoretic       models to understand and predict the behavior of national leaders in wartime       scenarios, where two sides have the options of seeking resolution at either the       bargaining table or on the battlefield. while the theoretical analyses of these       models is suggestive of their ability to capture these scenarios, it is not clear       to what degree human behavior conforms to such equilibrium-based expectations. we       present the results of a study that placed people within two of these game       models, playing against an intelligent agent. we consider several testable       hypotheses drawn from the theoretical analyses and evaluate the degree to which       the observed human decision-making conforms to those hypotheses. 
although reasoning skills have been investigated in a number of       different domains, very little is known about how children and adults use them in       chemistry. here, participants from 4 years to adults saw various mixtures       presented using a standard property induction paradigm. the category and       appearance of everyday materials were varied to assess the extent that       participants use these features to inform their judgments about what happens when       these materials are mixed with water. in general, the results followed similar       patterns seen when this paradigm has been applied to other domains, with both       category and appearance informing inductive generalizations. the findings       contrast with interview-based measures of children’s understanding of       chemistry and offer an important addition to the field.
empathy with other persons’ emotions has been suggested to       root in a simulation process involving brain regions that play a crucial role in       the production of one’s own emotions. the current erp study combines this       approach with an embodied-simulative view of semantics. this view implies that       those very brain regions should also be involved in the semantic memory and       linguistic comprehension of intentional and proprioceptive emotion words. the       relation between cognitive empathy measured by the met test and the size of the       n400 effect occurring when semantic emotions words violate semantic expectations       is investigated.
across a range of psychometric tests, reaction times slow as adult       age increases. these changes have been widely taken to show that       cognitive-processing capacities decline across the lifespan. contrary to this, we       suggest that slower responses are not a sign of processing deficits, but instead       reflect a growing search problem, which escalates as learning increases the       amount of information in memory. a series of computational simulations show how       age-related slowing emerges naturally in learning models, as a result of the       statistical properties of human experience and the increased       information-processing load that a lifetime of learning inevitably brings. once       the cost of processing this extra information is controlled for, findings taken       to indicate declines in cognitive capacity support little more than the       unsurprising idea that choosing between or recalling items becomes more difficult       as their numbers increase. we review the implications of this for scientific and       cultural understanding of aging.
music is a pervasive phenomenon in human culture, and musical       rhythm is virtually present in all musical traditions. research on the evolution       and cognitive underpinnings of rhythm can benefit from a number of approaches. we       outline key concepts and definitions, allowing fine-grained analysis of rhythmic       cognition in experimental studies. we advocate comparative animal research as a       useful approach to answer questions about human music cognition and review       experimental evidence from different species. finally, we suggest future       directions for research on the cognitive basis of rhythm. apart from research in       semi-natural setups, possibly allowed by "drum set for chimpanzees" prototypes       presented here for the first time, mathematical modeling and systematic use of       circular statistics may allow promising advances.
the present study tested the transfer effects of a short training       intervention on principled-based self-explanations. the intervention used fables       and mathematics as "exemplifying" domains for training such self-explanations.       the effects were tested in a transfer learning environment about attribution       theory. in this experiment, 58 high-school students were randomly assigned to the       self-explanation training condition or a control condition (i.e., mnemonic       strategies). the learning outcomes from the transfer environment did not       significantly differ between groups. however, those students who reported to have       applied the strategies from the training intervention actually showed superior       learning outcomes. the self-explanation training intervention "convinced" just       part of the learners to engage in principle-based self-explanations. there seems       to be two options to achieve more reliable effects in the future: the use of       clearer prompts to employ the learned strategies in the transfer environment or a       more extended training intervention to have stronger effects on spontaneous       strategy application.
learning a particular categorization leads to corresponding       changes in the similarity structure of the categorized stimuli. the purpose of       the current study was to examine whether different category structures may lead       to greater or less similarity change. we created six category structures and       examined changes in similarity as a result of categorization in       between-participant conditions. the best-supported hypothesis was that the ease       of learning a categorization affects change in similarity, with the most change       following learning of difficult category structures. there was also support for       the hypothesis that similarity change is more likely to occur when the category       boundary was not aligned with the physical dimension of variation. finally, we       discuss some methodological challenges in addressing this important research       topic. 
several scholars, e.g. sellars (1956), meltzoff & gopnik (1993),       have construed the attribution of experiences as being governed by a       folk-psychological theory in which experiences function as theoretical entities.       however, so far this claim has not been convincingly supported by an account of       how people infer the existence of experiences. in this paper i argue that the       mechanisms that lead to the stipulation of experiences are fundamentally       inferential and are applied in both self-attribution and third-person attribution       of experiences. the two most common sources for going through such inferential       processes are (i) disagreements between two people in how the world is presented       to them, (ii) being aware of or suspecting differences between how the world is       presented to a person and extraneous information the person has about the world.       from situations like these, i show that ‘experience’ is a       theoretically-acquired concept which refers to entities that play an explanatory       role in virtue of fulfilling two conditions: a person entertains the concept       experience if that person makes an appearance-reality distinction (c1) and       considers the appearance to be subjective (c2). 
longitudinal data of conventionalization in emerging languages,       combined with computational models explaining such data, are lacking in the       literature on language emergence. in the present study we report on the emergence       of gestural communication systems (“homesigns”) invented by deaf       individuals in nicaragua. analysis of longitudinal data from several families       shows gradual convergence toward a gestural system with the essential       characteristics of a shared lexicon. we propose a general computational framework       to formalize the linguistic and social interactions among the individual signers       such that a shared lexicon may arise. more specifically, a reinforcement learning       process that adjusts the individual’s probability of gesture use in       response to others’ actual gesture use provides a suitable account of the       observed gestural convergence. implications for language emergence are discussed.       
the relationship between individual cognition and cultural       phenomena at the society level can be transformed by cultural transmission       (kirby, dowman, & griffiths, 2007). top-down models of this process have       typically assumed that individuals only adopt a single linguistic trait. recent       extensions include ‘bilingual’ agents, able to adopt multiple       linguistic traits (burkett & griffiths, 2010). however, bilingualism is more than       variation within an individual: it involves the conditional use of variation with       different interlocutors. that is, bilingualism is a property of a population that       emerges from use. a bottom-up simulation is presented where learners are       sensitive to the identity of other speakers. the simulation reveals that dynamic       social structures are a key factor for the evolution of bilingualism in a       population, a feature that was abstracted away in the top-down models. top-down       and bottom-up approaches may lead to different answers, but can work together to       reveal and explore important features of the cultural transmission process.
statistical word learning involves forming and aggregating       associations between words and objects that co-occur across contexts (e.g.,       vouloumanos & werker, 2009; smith & yu, 2008; yu & smith, 2007). however, the       mechanisms that support such learning are currently under debate, including the       extent to which learners carry forward multiple ambiguous associations (e.g.,       trueswell et al., 2013). the current study presented adults with a set of       statistical word learning tasks designed to measure the statistical computations       learners employ to build label-object mappings and to probe what information from       past contexts is available to further process and integrate with new information.       results reveal that learners use the co-occurrence of label-object pairings to       make inferences both about objects and labels currently present and those       presented on previous trials. further, the strength of learners’ memory for       past contexts moderated their inferences, suggesting a role for a rich       information structure in cross-situational word learning.
despite a long history of debate on how the speech production and       perception systems are linked and a vast number of experimental studies       indicating an intimate link between perception and production, formal proposals       of this link have been conspicuously lacking. we provide a computationally       explicit, dynamical model of the process of phonological planning. in this model,       the properties of a perceived utterance automatically serve as input to the       ongoing planning of an intended utterance. using tools from non-linear dynamics,       we formalize how incoming inputs from perception influence the ongoing choice of       phonological parameters to be used in production. our model provides an account       of response time modulations reported in independent experimental work, and makes       additional concrete predictions that can be tested experimentally. our model       provides a foundation for better understanding the cognition of speech       perception, speech production, and the interaction between the two.
research on numerical cognition suggests a strong link between       mental representations of space and quantity. the snarc effect (spatial-numerical       association of response codes effect) is characterized by the association of       small quantities with left space and large quantities with right space. while the       majority of research on the spatial representation of number has been on number       words or arabic numerals, this study investigates quantity representations that       are involved in the processing of grammatical number. we found that german words       that were inflected for singular had a relative left hand advantage, and       conversely, plurals had a relative right-hand advantage. however, this pattern       was only found in relatively late responses. moreover, it appeared to interfere       with the opposite pattern caused by the marc effect (markedness association of       response codes effect) leading to a relative right-hand advantage for singulars.       this interference appeared to depend mainly on response latency with marc effects       being more pronounced in early responses and snarc-like effects being more       pronounced in late responses. this work sheds light on the interaction of       different stimulus-to-response mappings operating on the same stimulus dimension       – grammatical number. moreover, it suggests that spatial numerical       associations go beyond explicit numerical information, as in number words or       arabic numerals. 
this paper demonstrates a new quantitative approach to identify       what is behind universally sensed sound symbolism and sound symbolism detected       only by speakers of a particular language. we presented 70 locomotion videos to       japanese and english speakers and asked them to create a word that would       sound-symbolically match each action, then to rate the action on five semantic       dimensions. multivariate analyses revealed that certain sound-meaning links       (e.g., voicing and speed) were more consistent than others within and across       languages. language-specific sound symbolism was also found for some       sound-meaning links (e.g., the affricate manner of articulation was associated       with light motions in japanese, but with heavy motions in english). this implies       that cross-linguistically shared and language-specific parts of sound symbolism       are intricately intertwined within each language. this research underscores the       importance of a bottom-up approach which can exploratorily investigate the       complex sound-symbolic systems as a whole.
conceptual metaphor congruency effects have been interpreted as       evidence for the notion that the representation of abstract conceptual dimensions       (e.g., power, evaluation) rests on more concrete dimensions (e.g., space,       brightness). however, an alternative account based on the notion of polarity       correspondence has recently received empirical support from studies about the       mapping between affective evaluation and morality on vertical space. we tested       the polarity correspondence account in the domain of number, which shows       well-known congruency effects with lateral left-right space (the snarc effect).       response polarity was manipulated by varying keyboard eccentricity in both parity       (odd-even) and quantity (larger-smaller than 5) tasks. response eccentricity did       not modulate the snarc effect. in a final experiment, the orthogonal simon effect       was modulated by the manipulation of response eccentricity. we conclude that       polarity correspondence does not provide an adequate explanation of conceptual       congruency effects in the domain of number. 
we investigated the time course of sentence formulation in       tagalog, a verb-initial language in which the verb obligatorily agrees with one       of its arguments. eye-tracked participants described pictures of transitive       events. fixations to the two characters in the events were compared across       sentences differing in agreement marking and post-verbal word order. fixation       patterns show evidence for two temporally dissociated phases in tagalog sentence       production. the first, driven by verb agreement, involves early linking of       concepts to syntactic functions; the second, driven by word order, involves       incremental lexical encoding of these concepts. these results suggest that even       the earliest stages of sentence formulation may be guided by a language's       grammatical structure.
psychological experiments have revealed remarkable regularities in       the developmental time course of cognition. infants generally acquire broad       categorical distinctions (i.e., plant/animal) before finer ones (i.e.,       bird/fish), and periods of little change are often punctuated by stage-like       transitions. this pattern of progressive differentiation has also been seen in       neural network models as they learn from exposure to training data.  our work       explains why the networks exhibit these phenomena. we find solutions to the       dynamics of error-correcting learning in linear three layer neural networks.       these solutions link the statistics of the training set and the dynamics of       learning in the network, and characterize formally how learning leads to the       emergence of structured representations for arbitrary training environments. we       then consider training a neural network on data generated by a hierarchically       structured probabilistic generative process. our results reveal that, for a broad       class of such structures, the learning dynamics must exhibit progressive,       coarse-to-fine differentiation with stage-like transitions punctuating longer       dormant periods.
fitting multi-parameter models to the behavior of individual       participants is a popular approach in cognitive science to measuring individual       differences. this approach assumes that the model parameters capture       psychologically meaningful and stable characteristics of a person. if so, the       estimated parameters should show, to some extent, stability across time.       recently, it has been proposed that hierarchical procedures might provide more       reliable parameter estimates than non-hierarchical procedures. here, we examine       the benefits of hierarchical parameter estimation for assessing parameter       stability using bayesian techniques. using the transfer-of-attention-exchange       model (tax; birnbaum & chavez, 1997), a highly successful account of risky       decision making, we compare parameter stability based on hierarchically versus       non-hierarchically estimated parameters. surprisingly, we find that parameter       stability for tax is not improved by using a hierarchical bayesian as compared to       a non-hierarchical bayesian approach. further analyses suggest that this is       because the shrinkage induced by hierarchical estimation overcorrects for extreme       yet reliable parameter values. we suggest that the benefits of hierarchical       techniques may be limited to particular conditions, such as sparse data on the       individual level or very homogenous samples.
linguistic experience attenuates adult listeners’ attention       to acoustic differences that are not phonemic in the listener’s language.       in the present study we found that acoustic information is available to listeners       after acoustic cues have been processed to identify phonemic categories.       moreover, we also found that listeners maintained an awareness of these       differences by comparing the identification function to typicality ratings and       confidence reports.
monetary intertemporal tradeoffs are a restricted, yet       underexplored, domain.  in this extended abstract, we provide an integrative       analysis of monetary tradeoffs involving single dated outcomes, unmixed       sequences, virtues (schedules of investment), and vices (schedules of debt).       results include debt aversion, aversion to vices (which adds to debt aversion)       and relative vices, and attraction to virtues and relative virtues. the results       motivate a comparative mental accounting model, which includes direct comparisons       between the outcomes delivered by the options at consecutive delays. the model       accommodates not only the results reported in this extended abstract, but also       other puzzling phenomena in choices involving sequences.
comparison of the ability of different computational cognitive       models to simulate empirical data should ideally take into account the complexity       of the compared models. although several comparison methods are available that       are meant to achieve this, little information on the differential strengths and       weaknesses of these methods is available. in this contribution we present the       results of a systematic comparison of 5 model comparison methods. employing model       recovery simulations, the methods are examined with respect to their ability to       identify the model that actually generated the data across 3 pairs of models and       a number of comparison situations. the simulations reveal several interesting       aspects of the considered methods such as, for instance, the fact that in certain       situations methods perform worse than model comparison neglecting model       complexity. based on the identified method characteristics, we derive a       preliminary recommendation on when to use which of the 5 methods.
humans exhibit certain systematic context-dependent preference       reversals when choosing among options that vary along multiple attribute       dimensions. for instance, the attraction, similarity, and compromise effects each       involves a change in relative preference between two options when a third option       is introduced. previously, such effects have been attributed to irrationality or       sub-optimality in decision-making, or to specific architectural or dynamical       constraints on cognition. we use a bayesian model of multi-attribute choice to       demonstrate that these effects naturally arise from three basic assumptions: (1)       humans assess options relative to “fair market value” as inferred       from prior experience and available options; (2) attributes are imperfectly       substitutable, and scarce attributes are relatively more valuable; (3)       uncertainty about market conditions and option values contributes to       stochasticity in choice behavior. this work provides both a novel normative       explanation for contextual modulation of choice behavior, and a means to predict       choice as a function of past experiences and novel contexts.
in novel situations, learning is biased towards information that       has a degree of prior predictive utility. in human learning, this is termed the       learned predictiveness effect and has proved critical in theorising about the       role of attention in learning. two experiments are reported in which the relative       contribution of controlled and automatic processes to learned predictiveness are       investigated. experiment 1 showed that while learned predictiveness is       susceptible to instructional manipulation, this effect is partial. experiment 2       manipulated predictive utility and instruction orthogonally in order to test the       potential involvement of automatic processes. it was found that even when cues       were explicitly instructed as causal, learning was biased in favour of previously       predictive over previously non-predictive cues. interestingly, this was reversed       for cues instructed as irrelevant. this suggests that learned predictiveness       benefits attentional control, whereby information is both easier to attend and       ignore.
words divide the world into labeled categories. languages vary in       the categories they label, sometimes to the point of making cross-cutting       divisions of the same space. previous work suggests two opposing hypotheses about       how communication contributes to category emergence: 1) these spaces lack an       objective shared similarity structure, and communication dynamically creates one       of a number of optimally shareable category structures; 2) the category       structures resulting from communication are not necessarily optimal, but diverge       from a shared similarity space in language-specific ways. we had participants       categorize images drawn from a continuous space in two conditions: a)       non-communicative, by similarity, b) communicative, dynamically creating       categories when playing a partnered communication game. the memory demands of       communication lead to reliance on salient images and early conventions, resulting       in non-optimal category structures compared to non-communicative participants.       this supports the hypothesis that communication leads to categories that diverge       non-optimally from a shared similarity space.
the aim of the current studies was to explore encoding time       differences in objects and relations and to investigate whether these differences       lead to differences in allocation of attention to object similarity. using a       match-to-sample paradigm with 5- to 6-year-olds and adults, we found that (1)       objects were encoded faster than relations for both adults and children, and that       (2) children, but not adults, preferentially allocated attention to object       similarity. ultimately, these questions are aimed at identifying the factors       responsible for the development of adult-like analogical reasoning. we suggest       that changes in selective attention over development may account for the pattern       of results seen across these two studies.
screen media, such as television and videos, are a common part of       young children’s lives. yet infants and toddlers have been shown to learn       less effectively from screens than from interactions with another person. using a       quasi-experimental design we explored how social factors of screen media       co-viewing impact children’s learning outcomes. we observed parents       co-viewing a novel word training video with their children, then tested children       for immediate and delayed word learning. we then investigated the links between       parental speech during co-viewing and children’s subsequent word learning.       parental speech that encouraged children to produce the novel words predicted       better retention of word learning, whereas speech that focused more on the video       itself rather than the content was negatively associated with learning.
the other-race effect (ore) refers to the phenomenon that       recognition memory for other-race faces is worse than for own-race faces. we       investigated whether white germans exhibited an ore towards turkish or arabic       faces using a multinomial processing tree model (mpt), the two-high threshold       model of recognition memory with three response categories (old, skip, and new).       using an mpt enabled us to adequately disentangle memory and response processes       using the fisher information approximation, a minimum description length based       measure of model complexity. results showed that participants exhibited an ore on       the memory parameters but not on the parameters representing response       processes.
externalist theories in natural language semantics have become the       orthodoxy since kripke is widely thought to have refuted descriptive theories       involving internal cognitive representation of meaning. this shift may be seen in       developments in philosophy of language of the 1970s – the direct reference       “revolution against frege” (wettstein 2004). almog (2005) writes of       the “uprising against frege’s doctrines” that “spread       like fire” based on the work of kripke, donnellan, putnam and kaplan.       however, i consider fodor’s (2004) heretical thought that something has       gone “awfully wrong” in this philosophical consensus, perhaps       confirming chomsky’s (1992) view that the whole field of philosophical       semantics is “utterly wrongheaded” and “crazy” by virtue       of its non-naturalist assumptions and “methodological dualism.” i       suggest that the externalist orthodoxy is a kind of cognitive illusion seen       elsewhere in philosophy and cognitive science.
in order to interact with the world, people must be able to       predict how it will unfold in the future, and these predictions must be updated       regularly in light of new information. here we study how the mind updates these       predictions over time. participants were asked to make ongoing predictions about       the destination of a simulated ball moving on a 2d bumper table. we modeled these       decisions by assuming people simulate the world forward under uncertainty. this       model fit participants’ behavior well overall, suggesting that people       continuously update their physical simulations to inform their decisions. in some       specific scenarios participants’ behavior is not fit well by the simulation       based model in a manner suggesting that in certain cases people may be using       qualitative, rather than simulation-based, physical reasoning.
language exhibits structure: a species-unique system for       expressing complex meanings using complex forms. we present a review of modelling       and experimental literature on the evolution of structure which suggests that       structure is a cultural adaptation in response to pressure for expressivity       (arising during communication) and compressibility (arising during learning), and       test this hypothesis using a new bayesian iterated learning model. we conclude       that linguistic structure can and should be explained as a consequence of       cultural evolution in response to these two pressures. 
we present a model of the wisconsin card sorting test, a classical       neuropsychological test frequently used to assess deficits in executive       functioning. the model is grounded in a cognitive architecture based on the       supervisory system theory of norman and shallice (1986) and evaluated against       data from control subjects and several groups of neurological patients as       reported by stuss et al. (2000). the model is able to account for control       performance across a range of dependent measures. when damaged in theoretically       motivated ways it is also able to capture the behaviour of the different patient       groups. specifically, the model supports the association by shallice et al.       (2008) of the function of task-setting to left lateral prefrontal cortex, of the       function of attentiveness to inferior medial prefrontal cortex, and of the       function of monitoring to right lateral prefrontal cortex. the implication of       these results for the supervisory system architecture and the localisation of       function within prefrontal cortex are discussed.
a recent paper by lev-ari and keysar (2010) reported that the       processing fluency associated with non-native speech causes non-native speakers       to sound less credible. the authors found that the same trivia statements were       rated as less truthful when spoken by a non-native speaker of english. the       present paper reports the results of three studies that attempted to replicate       the findings of lev-ari and keysar (2010) by focusing on processing fluency       manipulations other than accent. although we used virtually the same methodology       as lev-ari and keysar (2010), we failed to replicate the key finding that       foreign-accented speech is less credible than native-accented speech. the       implications of this finding is discussed.
one question in word production is how the presence of a       semantically related word affects the naming process. it has been suggested that       semantic effects in picture-word interference tasks are a net result of both       inhibitory and facilitatory processes that take place at different processing       levels. finkbeiner and caramazza (2006) argued that masking distractor words       removes the inhibitory component, leaving only lexical facilitation. we       investigated this claim by comparing different types of semantic relationship       – categorical relatedness, associative relatedness, and a combination of       both – in picture-word interference with masked and visible distractors. we       observed inhibitory effects in all conditions. in the visible condition, semantic       category coordinates exerted the strongest inhibition, while in the masked       condition, associatively related distractors interfered most. these findings are       not easily reconciled with previous findings on polarity shifts of semantic       effects with masked distractors. we discuss how all present findings could be       explained within the same framework. 
how are concepts represented in the human mind?  vector space       representations based on the instantaneous firing rates of neurons have been used       with great success.  however, there is growing evidence, both empirical and       computational, that relevant information is encoded in spatiotemporal patterns of       spikes called polychronous neuronal groups (pngs).  in this paper, we consider       the philosophical implications of png representations with regard to their       temporal extension, grounding, compositionality, and similarity.  we suggest that       the temporally extended nature of pngs implies that conceptual-level dynamics may       only be coherent at coarse time scales.  we introduce the notion of png trigger       sets as a way to ground the meaning of png representations, and we discuss       potential approachs to compositionality.  finally, we identify the open problem       of how to define an appropriate similarity metric for png-based mental       representations.
we analyse data from a very large (n=854064) sample of players of       an online game involving rapid perception, decision-making and motor responding.       this data set allows us to connect full details of training history with measures       of performance, for participants who are engaged for a sustained amount of time       in effortful practice. we show that lawful relations exist between practice       amount and subsequent performance, and between practice spacing and subsequent       performance. this confirms results long established in the literature on skill       acquisition. additionally, we show that higher initial variation in performance       is linked to subsequent higher performance, a result we link to the       exploration-exploitation trade-off from the computational framework of       reinforcement learning. we discuss the benefits and opportunities of behavioural       datasets with very large sample sizes and suggest that this approach could be       particularly fecund for studies of skill acquisition.
instruction often employs visual representations to support deep       understanding. however, students’ prior misconceptions may override the       meaning in these scaffolds. we investigate fraction bars, a common representation       intended to promote sense-making. our prior work found that students often did       not use the fraction bars effectively. this difficulty factors assessment       compares four scaffold types: pictures only, two forms of pictures with numbers,       and numbers only, to assess which interpretation steps were difficult.  on       equivalence items, students performed equally well with all scaffolds that       included pictures, but worse with the numbers-only scaffold, indicating that       fraction bars improved scores for equivalence. however, including numbers with       the pictures decreased performance for fraction addition. although students       demonstrated competence with fraction bars in fraction equivalence, they did not       transfer this knowledge to addition. these results suggest caution in designing       and teaching representations for sense-making.
in the area of computational processing of natural language texts,       advances toward simpler yet more accurate models of meaning are desirable. as       syntax is a major component of semantic analysis, we explore how a long-term  and       institutional bias towards the verb as the main determiner of syntactic (and       semantic) structure may underserve some kinds of information. we introduce an       analysis paradigm that restores the noun to some importance in syntactic       analysis. a noun-driven syntax representation has been developed and evaluated,       and ; implications of its use in further processing and in better modeling of       natural language meaning areis investigated.
the cognitive reflection test (crt) was devised to measure the       inhibition of heuristic responses to favour analytic ones. toplak, west and       stanovich (2011) demonstrated that the crt was a powerful predictor of heuristics       and biases task performance - proposing it as a metric of the cognitive       miserliness central to dual process theories of thinking. this thesis was       examined using reasoning response-times, normative responses from two reasoning       tasks and working memory capacity (wmc)  to predict individual differences in       performance on the crt. these data offered limited support for the view of       miserliness as the primary factor in the crt. the strongest predictor of crt in       both experiments was wmc. it is argued that while cognitive miserliness has been       implicated in crt performance, participants must also possess the requisite wmc       and mindware to successfully complete it. therefore, the psychological and       psychometric properties of the crt require continued study.
in current theories of word reading the structure and operations       of the phonological buffer are quite underspecified. we investigated this issue       by running a reading aloud experiment in italian. we adopted a priming paradigm,       with three-syllabic words as primes and targets and we jointly manipulated two       effects ascribed to the stage of phonological and phonetic encoding, that is       stress priming and syllable frequency. target words varying for the frequency of       their initial syllable were preceded by words congruent or incongruent for the       stress pattern.  the results showed an interaction between syllable frequency and       stress prime, with the stress congruency effect larger for the targets with       low-frequency first  syllable. this result suggests that, in reading aloud,       stress assignment and syllable computation have a tight time dynamics in the       phonological output buffer, and that the process at the level of       phonology-to-phonetic interface operates interactively.
two prominent approaches to describing how people make decisions       between risky options are algebraic models and heuristics. the two approaches are       based on fundamentally different algorithms and are thus usually treated as       antithetical, suggesting that they may be incommensurable. using cumulative       prospect theory (cpt; tversky & kahneman, 1992) as an illustrative case of an       algebraic model, we demonstrate how algebraic models and heuristics can mutually       inform each other. specifically, we highlight that cpt describes decisions in       terms of psychophysical characteristics, such as diminishing sensitivity to       probabilities, and we show that this holds even when the underlying process is       heuristic in nature. our results suggest that algebraic models and heuristics       might offer complementary rather than rival modeling frameworks and highlight the       potential role of heuristic principles in information processing for prominent       descriptive constructs in risky choice.
the present study examines the decisions made by reasoners when       they are asked to revise their beliefs in the face of new, counterfactual       information. participants indicated the scope (the degree of set inclusion) of       semantic generalizations about real categories in a pretest. in subsequent       experiments, these scope values were used to predict the willingness of       participants to retain statements in their existing knowledge sets. when those       sets were logically compatible with a modus tollens (mt) structure, participants       were more likely to retain the general statements, but not when the sets were       logically compatible with a modus ponens (mp) structure. however, the mp       retention rates increased when locatives were added to the generalizations. these       findings are inconsistent with several prevailing proposals of belief revision       but do support the concept of belief revision as following possible worlds       logic.
by 8 months of age, infants use statistical regularities and       perceptual cues to orient attention (e.g. kirkham et al., 2007; wu & kirkham,       2010). however, it is unclear whether infants are sensitive to the reliability of       individual attentional cues. in this eye-tracking study, 8-month-olds were       familiarized with a reliable face, which always looked to a box where an       animation appeared, and an unreliable face, which looked only 25% of the time to       the box containing the animation. at test, when the animations did not appear,       infants searched longer in the corner cued by the reliable face, but did not       search longer in the corner cued by the unreliable face. these results suggest       that even young infants can track the the reliability of potential informants and       use this information to distribute attention in support of early learning.
we study structural properties of a turn-based game called the       marble drop game, which is an experimental paradigm designed to investigate       higher-order social reasoning. we show that the cognitive complexity of game       trials, measured with respect to reaction time, can be predicted by looking at       the structural properties of the game instances.  in order to do this, we define       complexity measures of finite dynamic two-player games based on the number of       alternations between the game players and on the pay-off structure. our       predictions of reaction times and reasoning strategies, based on the theoretical       analysis of complexity of marble drop game instances, are compared to subjects'       actual reaction times. this research illustrates how formal methods of logic and       computer science can be used to identify the inherent complexity of cognitive       tasks. such analyses can be located between marr's computational and algorithmic       levels. 
we present a neural network model of the storage of episode       representations in working memory (wm). our key idea is that episodes are encoded       in wm as prepared sensorimotor routines: i.e. as prepared sequences of       attentional and motor operations. our network reproduces several experimental       findings about the representation of prepared sequences in prefrontal cortex.       interpreted as a model of wm episode representations, it has useful applications       in an account of long-term memory for episodes and in accounts of sentence       processing.
there have been few studies on a cognitive model for algorithm       understanding in a human-computer cooperative situation. in the present study, we       conducted an experiment with participants to investigate the cognitive process of       higher level abstraction (algorithm understanding) performed in a human-computer       collaboration task. the most recently used (mru) algorithm, known to be one of       the simplest adaptive algorithms, and probabilistic mru algorithm were used to       test the human capability to understand an algorithm. the experimental results       showed that inductive reasoning in which participants observed the history of       computer action, and they updated a statistical model while restricting their       focus on a certain history with deteministic bias and markov bias played key role       to correctly understand the mru algorithm. the results also showed that deductive       reasoning was used to understand algorithms when participants rely on prior       knowledge, and that there was a case in which the algorithm, even known to be the       simplest one, was never understood.
this study investigated the degrees of consistencies in driving       behavior when operating a real system (real car), a virtual system (high fidelity       driving simulator), and a laboratory system (computer driving game). the same       tendency of behavioral consistencies was confirmed among the three systems: i.e.,       the steering operation demonstrated the highest behavioral consistencies,       followed by the acceleration and braking operations, respectively. the       individuality of driving behavior emerged more in the braking and acceleration       operations than in the steering operation. the same tendency for behavioral       consistencies of braking, acceleration, and steering operations was confirmed in       each of the three systems.
while processing spoken language, people look towards relevant       objects, and the time course of their gaze(s) can inform us about online language       processing (tanenhaus et al, 1995). here, we investigate lexical recognition in       british sign language (bsl) using a visual world paradigm, the first such study       using a signed language.  comprehension of spoken words and signs could be driven       by temporal constraints regardless of modality (“first in, first       processed”), or by perceptual salience which differs for speech       (auditorialy perceived) and sign (visually perceived). deaf bsl signers looked       more often to semantically related distracter pictures than to unrelated       pictures, replicating studies using acoustically-presented speech. for       phonologically related pictures, gaze increased only for those sharing visually       salient phonological features (i.e., location and movement features). results are       discussed in the context of language processing in different modalities. overall,       we conclude that lexical processing for both speech and sign is likely driven by       perceptual salience and that potential differences in processing emerge from       differences between visual and auditory systems.
where do emergent features come from? this has long been an       intriging puzzle. the concept of pet fish illustrates the       difficulty. most people expect pet fish to live in bowls, even       though this is not something either pets or fish normally do. the       inference that pet fish have the feature of living in bowls cannot       be explained purely in terms of the constituents themselves. the       feature seems to emerge. the present paper aims to explain this       effect using notions of classificatory composition. adjoined concept       references are taken to construct classifications rather than       combinations; a pet fish is taken to be a fish classified as a pet       rather than a combination of a pet a fish. it is also shown that,       where concepts have a compositional representation, feature       emergence can be accounted for in terms of compositional       accommodation.       
before children acquire the precise definitions of time words,       like minute and hour, how do they interpret them? and how are such proto-meanings       acquired in development? here we present three experiments, and assess       children’s early understanding of seven time words: second, minute, hour,       day, week, month, and year. our findings indicate that children first learn time       words as a lexical class, then learn their ordinal relations, but initially have       little to no knowledge of their relative durations. this understanding emerges       late in development – many years after children first start using time       words in speech – and in many children does not emerge until they have       acquired formal definitions for the words.    
research under the paradigm of the label feedback hypothesis has       proposed a causal role for verbal labels in the online learning and processing of       categories. labeled categories are learned faster, and are subsequently more       robust. the present study extends this research paradigm by considering the       relationship between verbal labels and flexible categorization. flexibility is a       key trait of human cognition, and flexible categorization is important in a       number of tasks. participants learned to categorize ‘friendly’ and       ‘unfriendly’ aliens either with or without names, followed by a       transfer task. while selective attention to a particular dimension slowed       relearning, no effect of label was found for either category learning or       relearning with one exception; labels facilitated flexibility when selective       attention was not involved in the transfer. the inability to replicate effects of       verbal labels in category learning using similar methodologies raises interesting       theoretical issues, questioning the extent to which this relationship       applies.
previous work suggests that inductive and deductive reasoning may       be accomplished by different processes. here, we examine whether different       phenomena of inductive reasoning, previously explained in the same way, may rely       on different types of processes. in experiment 1 we show that trials which       examine sensitivity to sample size in inductive reasoning have greater effects on       secondary task performance than do trials examining sensitivity to the diversity       of the sample. in experiment 2 we show that in a surprise recognition memory       test, participants have significantly better memory for the content of diversity       trials than for sample size trials. both findings are consistent with the       suggestion that some phenomena of inductive reasoning may be rule-based, whereas       others may depend on feature-level processing.
the present study investigates two key aspects of analogical       retrieval: (1) whether activities different from problem solving automatically       elicit a search for analogical sources, and (2) whether strategic search can       overcome the superficial bias observed in classical experiments. in experiment 1,       participants generated persuasive arguments for a target analog under three       experimental conditions: without indication to use analogies, with instruction to       use analogies, and with indication to search for sources within four predefined       domains. responses from the first condition showed that argumentation rarely       triggers spontaneous analogical retrievals. results from the remaining conditions       demonstrated that the superficial bias can be strategically reversed when       participants are suggested to focus on specific domains. experiment 2 replicated       this last result with the simple instruction to search within domains different       from that of the target (i.e., without being provided with a list of specific       domains). the theoretical and educational implications of these findings are       discussed.
current dynamic models of decision-making assume that a unitary       system is responsible for forming preferences. however, extensive research has       shown that decision-making and behavior result from the interaction of two       separate systems of reasoning - one that is fast, automatic, and experiential and       one that is slow, deliberative and rational. this paper develops the first       dynamic dual-process model of decision-making that can account for choice,       response times, and prices. the model is applied to several phenomena from the       risky decision-making literature including enhancements in preference by small       losses, preference reversals due to response mode, and the influence of price and       affect on preference.
holistic processing and left-side bias are both behavioral markers       of expert face recognition. in contrast, chinese character recognition expertise       involves left-side bias but reduced holistic processing (hsiao & cottrell, 2009).       here we examine whether the reduction in holistic processing associated with       expert chinese character recognition can be better explained by writing rather       than reading experience. compared with non-chinese readers (novices), chinese       readers who had limited writing experience (limited-writers) showed increased       holistic processing, whereas chinese readers who could also write characters       fluently (writers) showed reduced holistic processing. this result suggests that       writing/sensorimotor experience can modulate holistic processing effects, and       that the reduced holistic processing observed in expert chinese readers may       depend on writing rather than reading experience. by contrast, both writers and       limited-writers showed a similar level of left-side bias in processing symmetric       chinese characters, left-side bias may therefore be a consistent expertise marker       for object recognition uninfluenced by motor experience. 
early in acquisition children overgeneralize verbs to       ungrammatical structures.  the retreat from overgeneralization is linked to the       acquisition of verb classes, the semantics of which constrain the structures in       which a verb can appear (e.g., pinker 1989; ambridge, pine & rowland, 2012). how       children learn these classes remains unclear.  some argue that distributional       regularities in linguistic input provide sufficient evidence for verb classes to       emerge and become linked to particular structures.  a corpus analysis of the       english locative construction (e.g., the woman sprayed water onto the wall/the       wall with water) demonstrated that children have similar verb classes to adults.       a correspondence analysis revealed that distributional regularities in the input       could support these verb classes.  finally, a connectionist simulation was able       to model early overgeneralization and retreat through distributional learning of       verb classes.  these results support a distributional learning account of verb       semantics.
in solving a variety of problems people interact with their       external environment, often using artefacts to supplement and augment their       problem solving skills. the role of interactivity in problem solving was       investigated using a river-crossing problem. all participants performed the task       twice, once in a high interactivity condition and once in a low interactivity       condition. moves to completion were higher in the high interactivity condition       but latency per move was much shorter with high than with low interactivity.       moves in the world were easier to implement than to simulate mentally and acted       as epistemic actions to facilitate thinking. in addition, when participants       experienced the low interactivity version of the task second, their performance       reflected little learning. however, when the high interactivity version was       completed second, latency to solution and latency per move were substantially       reduced. these results underscore the importance of investigating problem solving       behaviour from a distributed cognition perspective.
individuals make decisions under uncertainty every day based on       incomplete information concerning the potential outcome of the choice or chance       levels. the choices individuals make often deviate from the rational or       mathematically objective solution. accordingly, the dynamics of human       decision-making are difficult to capture using conventional, linear mathematical       models. here, we present data from a two-choice task with variable risk between       sure loss and risky loss to illustrate how a simple nonlinear dynamical system       can be employed to capture the dynamics of human decision-making under       uncertainty (i.e., multi-stability, bifurcations). we test the feasibility of       this model quantitatively and demonstrate how the model can account for up to 86%       of the observed choice behavior. the implications of using dynamical models for       explaining the nonlinear complexities of human decision-making are discussed, as       well as the degree to which nonlinear dynamical systems theory might offer an       alternative framework for understanding human decision-making processes.
behavioral mimicry is the nonconscious copying of an interaction       partner’s behavior and is affected by social dynamics. whereas it has been       studied extensively in adults, little is known about the development of mimicry.       the aims of this study were twofold, first to identify whether young children       demonstrate mimicry and, second, to investigate whether young children’s       mimicry displays sensitivity to social dynamics. using a video-based paradigm,       40-month-old children observed six types of behaviors (i.e. yawning, laughing,       frowning, cheek-scratching, mouth-rubbing and head-wiggling) performed by a model       which they had previously seen either helping or hindering another model. results       indicate that children carried out five of the six behaviors more often while       watching the behavior videos than during baseline. however, no differences were       found between the two social manipulations. we conclude that young children       demonstrate mimicry like that reported in adults and discuss the possible causes       of the absence of a social effect.
how do people coordinate actions with others? we tested the       hypothesis that pairs of participants strategically reduce the variability of       their action performance to achieve synchronicity in the absence of visual       feedback about each other’s actions. consistent with this prediction,       participants moved faster and less variably in a condition where they could not       see their task partner’s movements compared to a condition in which visual       information was available. the accuracy of the resulting coordination was the       same in both conditions. these findings are interpreted as evidence for general       strategic adaptation in the service of real-time action coordination when only       minimal perceptual information is available. 
based on the unique traits of biological motion perception, the       existence of a “life detector”, a special sensitivity to perceiving       motion patterns typical for animals, seems to be plausible (johnson, 2006).       showing motion displays upside-down or with changes in global structure is known       to disturb processing in different ways, but not much is known yet about how       inversion affects attention and incidental processing. to examine the perception       of upright and inverted point-light walkers regarding incidental processing, we       used a flanker paradigm (eriksen & eriksen, 1974) adapted for biological motion       (thornton & vuong, 2004), and extended it to include inverted and scrambled       figures. results show that inverted walkers do not evoke incidental processing       and they allow high accuracy in performance only when attentional capacities are       not diminished. an asymmetrical interaction between upright and inverted figures       is found which alludes to qualitatively different pathways of processing.
from the moment they make up their mind, people are reluctant to       change it. we tested the hypothesis that people disposing of more cognitive       resources—through circadian variations or socially distributed       thinking—would engage in deliberative thinking and would consequently be       less likely to exhibit belief perseverance. perseverance was measured by the       change in judgments related to a suspect in a criminal case, following the       presentation of an offender profile that was at odds with the suspect’s       description. individuals tested at a compatible circadian time exhibited less       perseverance in the face of contradictory evidence compared to individuals tested       at an incongruent time. individuals deliberating on their own also tended to show       more belief perseverance compared to those who worked in groups. there was,       however, no interaction effect between circadian timing and condition of       deliberation on belief change. the implications for our understanding of the       mechanisms that underpin belief perseverance are discussed.
it is now generally accepted that words’ emotional content       plays a role in lexical processing, but the literature offers incompatible       findings concerning what this role may be. here we use a large sample of lexical       decision data (british lexicon project, keuleers et al., 2012) and we carry out a       series of analyses differing in the way emotional variables are treated. a       variety of statistical approaches yielded common conclusions: when confounding       variables are taken into account, emotional words, whether positive or negative,       are processed faster than neutral words. this effect is categorical rather than       graded; is not modulated by emotional arousal; and is not limited to words       explicitly referring to emotions. we discuss this in terms of internally       grounding words’ meanings in emotional experience, akin to the manner in       which concepts may be grounded in perception and action.
many decisions under risk and uncertainty are made under physical       or emotional stress. recent research suggests that stress influences decisions       between risky options, but that the direction of the influence depends on the       characteristics of the gambles. for instance, stress increases risk taking for       loss gambles, but decreases risk taking for gain gambles. in the current project       we investigate: (1) whether the riskiness of gambles influences the direction of       the stress effect and (2) whether changes in risk taking can be linked to changes       in attention. participants who gave relatively more attention to gains than to       losses, as indicated by eye- tracking data, were more risk seeking than       participants who gave less attention to gains. stress did not influence       participants’ attention. however, stressed participants became more risk       seeking when considering gambles with relatively low risk, but less risk seeking       for gambles with relatively high risk.
in category-based induction tasks, it is a robust finding that       positive observations raise the judged likelihood of a conclusion and negative       observations lower judged likelihood. we present evidence that negative       observations can raise the judged likelihood. in particular, we asked       participants to judge the likelihood of a conclusion after introducing them to       different sets of premises either containing one positive observation or the same       positive observation and a negative observation. we found that when the negative       observation is dissimilar to the positive observation, willingness to accept a       conclusion is raised. moreover, results from a simultaneous hypothesis generation       task suggest that the rise in judged conclusion likelihood is due to a peculiar       shift in the hypothesis space of the reasoner, in that the hypothesis with the       largest extension, yet still consistent with all premises gains disproportionate       popularity when introducing dissimilar negative observations.
three experiments test the hypothesis that engaging in explanation       prompts children to favor inductively rich properties when generalizing to novel       cases.  in experiment 1, preschoolers prompted to explain during a causal       learning task were more likely to override a tendency to generalize according to       perceptual similarity and instead extend an internal feature to an object that       shared a causal property.  in experiment 2, we replicated this effect of       explanation in a case of label extension. experiment 3 demonstrated that       explanation improves memory for internal features and labels, but impairs memory       for superficial features.  we conclude that explaining can influence learning by       prompting children to favor inductively rich properties over surface       similarity.
children make inductive inferences about the causal properties of       individual objects from a very young age.  when can they infer higher-order       relational properties - a task that has proven difficult for non-human primates?        in two experiments, we examined 18-24-month-old infants’ relational       inferences using a causal version of a relational match-to-sample task.  results       suggest that by 21-24 months of age, infants are able to infer a relational       causal principle from just a few observations and use this inference to guide       their own subsequent actions and bring about a novel causal outcome.  findings       are considered in light of recent discussion about the nature of relational and       causal reasoning, and their evolutionary origins.
several computational models explaining fixation durations in       scene viewing (nuthmann, smith, engbert, & henderson, 2010) and in reading       (engbert, nuthmann, richter, & kliegl, 2005; reichle, pollatsek, fisher, &       rayner, 1998) assume that saccade programming is completed in two stages: an       initial, labile stage that is subject to cancellation and an subsequent,       non-labile stage in which the program can no longer be cancelled. this       distinction is motivated by findings from double-step experiments that used much       simpler situations than scene viewing or reading. here, we adopt a classic       double-step paradigm to a scene-viewing context. in a static condition targets       are presented to the left or right of a central fixation cross along a horizontal       axis while in a scene condition targets are presented in a gaze contingent manner       along a trajectory defined by the location of recent fixations. we found evidence       in support of the claims that saccade cancellation occurs within a naturalistic       scene-viewing context and that saccade cancellation can account for increases in       observed fixation duration distributions. the duration of the non-labile stage       was estimated to be longer in the scene condition compared to the static       condition. 
recent findings show that human inferences and decisions       interfere in ways analogous to incompatible quantum       observables, and conceptual judgments are inseparable in       ways similar to entangled quantum states. this discovery has       led a group of physicists and psychologists to form a new       field called “quantum cognition,” which uses mathematical       principles of quantum theory to explain human cognitive       behavior. the power of this new theoretical approach is       illustrated here by testing an a priori and precise prediction       derived from quantum theory regarding question order effects       commonly observed in survey research. the test of quantum       theory was statistically satisfied across a set of 26 national       surveys on presidential job approval and country satisfaction       in past 10 years. these results suggest that quantum theory,       initially invented to explain order effects on measurements in       physics, provides a powerful prediction for measurement       order effects in social and behavioral sciences too.
idioms and common multi-word expressions are often argued to be       stored as chunks of words or fixed configurations in the mind, and to therefore       be accessed faster and interpreted more easily than fully compositional word       combinations. experimental research has furthermore shown that a specific       “recognition point” can be identified in such expressions, at which       enough information is present to access the meaning of the whole expression and       predict the remaining words of the collocation.        in this paper, we suggest measures for automatically identifying those multi-word       expressions where the first part is particularly predictive of the rest, and       evaluate our measures against human association data collected in a cloze test.       
frederick’s (2005) cognitive reflection test (crt) is a       3-item task shown to predict susceptibility to decision-making biases better than       intelligence measures. it is described as measuring ‘cognitive       reflection’ - a metacognitive trait capturing the degree to which people       prefer to reflect on answers rather than giving intuitive responses. herein, we       ask how much of the crt’s success can be explained by assuming it is a test       of numerical (rather than general) intelligence. our results show crt is closely       related to numerical ability and that its predictive power is limited to biases       with a numerical basis. although it may also capture some aspect of a rational       cognition decision style, it is unrelated to a metacognitive, error-checking and       inhibition measure. we conclude that the predictive power of the crt can,       largely, be explained via numerical ability without the need to posit a separate       ‘cognitive reflection’ trait.
social learning has been shown to be an evolutionarily adaptive       strategy, but can be implemented via many different cognitive mechanisms.       sensitivity to statistical dependency in the behavior of other people is a factor       that discriminates between possible mechanisms: blind imitation or simple rule       based strategies may be unaffected by dependency, while more sophisticated social       learning strategies should take it into account. we use a bayesian model to       determine how rational agents should incorporate the effects of statistical       dependency when learning from other people, conducting two experiments that       examine whether human learners behave similarly. we find that people are       sensitive to two different patterns of dependency, supporting the use of a       sophisticated strategy for social learning.
making a choice between alternatives can influence our subsequent       evaluation of the selected option (e.g. sharot, velasquez & dolan, 2010). thus,       in resolving psychological uncertainty, the act of making a judgment itself       appears to have a constructive role in subsequent related decisions. this study       focuses on emotional ambivalence and the development of affective evaluations       over two stages, such that (just) making an intermediate evaluation in the first       stage is shown to influence the overall affective evaluation in the second stage.       models based on classical probability theory, which assume that an intermediate       evaluation simply reads off an existing internal state, cannot accommodate this       result in a natural way.  an explanation is offered with a quantum probability       model, which, under specific circumstances, requires the measurement of an       internal state to have a constructive role. the predictions of the quantum       probability model were supported by the empirical results.
learning to represent hierarchical structure and its       nonadjacent dependencies (nds) is thought to be       difficult. i present three simulations of nd learning       using a simple recurrent network (srn). in simulation       1, i show that the model can learn distance-invariant       representations of nonadjacent dependencies. in       simulation 2, i show that purely localist srns can       learn abstract rule-like relationships. in simulation 3, i       show that srns exhibit facilitated learning when there       are correlated perceptual and semantic cues to the       structure (just as people do). together, these       simulations show that (contrary to previous claims)       srns are capable of learning abstract and rule-like       nonadjacent dependencies, and show critical       perceptual- and semantics-syntax interactions during       learning. the studies refute the claim that neural       networks and other associative models are       fundamentally incapable of representing hierarchical       structure, and show how recurrent networks can       provide insight about principles underlying human       learning and the representation of hierarchical structure.
recent studies showing learners can induce phrase structure from       distributional patterns (thompson & newport, 2007; saffran, 2001) suggest that       phrase structure need not be innate. here, we ask if this learning ability is       restricted to language.  specifically, we ask if phrase structure can be induced       from non-linguistic visual arrays and further, whether learning is assisted by       abstract category information. in an artificial visual grammar paradigm where       co-occurrence relationships exist between categories of objects rather than       individual items, participants preferred phrase-relevant pairs over       frequency-matched non-phrase pairs. additionally, participants generalized       phrasal relationships to novel pairs, but only in the cued condition. taken       together these results show that learners can acquire phrase structure in a       non-linguistic system, and that cues improve learning.
a previous study (hwang et al., 2011) found evidence for semantic       guidance of visual attention during the inspection of real-world scenes, i.e., an       influence of semantic relationships among scene objects on overt shifts of       attention. in particular, the results revealed an observer bias toward gaze       transitions between semantically similar objects. however, these results are not       necessarily indicative of semantic processing of individual objects but may be       confounded by knowledge of the scene gist, which does not require object       recognition (torralba et al., 2006), or by known spatial dependency among objects       (oliva & torralba, 2007). to examine the mechanisms underlying semantic guidance,       in the present study, subjects were asked to view a series of displays with the       scene gist removed and spatial dependency varied. our results confirm the       previous finding of semantic guidance and show that it is not entirely due to       either the effect of scene gist or the spatial dependency among objects. even       without scene gist or spatial dependency, subjects still retrieved semantic       information to guide their attention. this strategy may facilitate scene       understanding and object memorization.
most predictions can be partitioned into two components: the       predicted outcome, and the chance that one considers the outcome will happen. we       studied how people evaluate predictions with binary outcomes. these predictions       can be conveyed in two equivalent ways: one predicting an outcome with some       probability, and the other predicting the other outcome with the probability of       the complement of the first outcome. although these two ways of stating the       predictions are mathematically interchangeable, we hypothesized that people would       judge the congruently stated prediction, one that has the same qualitative       component as the actual outcome, as more accurate. we tested this hypothesis in       four experiments. results suggested that this effect is consistent across a       number of domains; depends on the frame in which the prediction is stated; is       robust regardless of whether the ratings were elicited in positive or negative       terms; holds for both rating and choice tasks.
aesthetics and the arts have garnered more attention within       cognitive science in recent years. despite this increasing interest, "scientists       of art" often focus on one of two areas: the formal properties of artworks       themselves, or the mental processes involved in perceiving these works in an       isolated, one-on-one encounter. in this paper, i review some representative       examples of such work before suggesting some alternative ways that cognitive       science might approach aesthetics and the arts -- ways that would complement the       isolationist approaches that have predominated to this point. in doing so, i draw       on the observations and arguments of various philosophers of art, highlighting       some of the socially and culturally situated factors that are important in       shaping the development of our taste and sensibilities.
advances in developmental research has made it clear       that word learning has a long beginning. recent work       has demonstrated that infants learn words at 6 months       of age—that is, before the traditional “first word” milestone       in productive language—which is a full year before       the usual “naming explosion” in productive vocabulary.       before infants talk, walk, or even point, how can the       earliest stage of word learning take place at all? we       used recent technology that allowed us to zoom in on the       point of view of infants and also the traditional roomview       observations to document how infants’ visual input       is dynamically synchronized with their own participation,       as well as from social input in the context of parent-child       word learning play. the parents’ task was to play with       the child with a set of toys as they taught the toys to       them. to specifically document the child’s dominant       view and their participation, we coded the size of the       toy object on which the child was focused and who was       manipulating the toy at the moment. the results reveal       systematic and dynamic links between infants’ view and       their level of participation.
although word learning unfolds over days, weeks, and months,       individual naming events are over in a matter of seconds. to benefit from a       naming event, children must at least hear the label and see the referent. we       tested 1-, 2- , 3-, and 4-year old children in a naturalistic word learning task       with two conditions: one that taxed both speech processing and rapid       gaze-following, and one in which a social cue-to-reference was available for an       extended time. the development of word-learning in the extended condition       paralleled the development of speech processing, but learning in the brief       condition lagged       behind. however, learning from both the brief and extended cues was predicted by       individual differences in speech processing and cue-following together. thus,       even through the 4th year, real-time processing of social and linguistic       information are a critical bottleneck for word learning.
how people achieve long-term goals in an imperfectly known       environment, via repeated tries and noisy outcomes, is an important problem in       cognitive science. there are two interrelated questions: how humans represent       information, both what has been learned and what can still be learned, and how       they choose actions, in particular how they negotiate the tension between       exploration and exploitation. in this work, we examine human behavioral data in a       multi-armed bandit setting, in which the subject choose one of four       “arms” to pull on each trial and receives a binary outcome       (win/lose). we implement both the bayes optimal policy, which maximizes the       expected cumulative reward in this ﬁnite horizon bandit environment, as       well as a variety of heuristic policies that vary in their complexity of       information representation and decision policy. we ﬁnd that the knowledge       gradient algorithm, which combines exact bayesian learning with a decision policy       that maximizes a combination of immediate reward gain and long-term knowledge       gain, captures subjects’ trial-by-trial choice best among all the models       considered; it also provides the best approximation to the computationally       intense optimal policy among all the heuristic policies.
this paper introduces a cognitive tutor designed for second       language grammar instruction. the tutor adopted corbett and anderson’s       (1995) bayesian knowledge tracing model and provided adaptive training on the       english article system. we followed the competition model (macwhinney, 1997) and       understood the article system as a galaxy of cues determining article usage on       the basis of form-function mapping. cues are in competition during language       acquisition; hence cue contrast is predicted to be an effective instructional       method. seventy-eight students were randomly assigned to four article training       conditions (to learn 33 cues) and a control condition (to write essays). we found       that article-training groups significantly outperformed the control group in an       immediate posttest and a delayed posttest. specifically, our result also       suggested that there was a significant interaction between cue contrast and cue       type (definite vs. indefinite). cue contrast promoted more learning on the       indefinite cues (more difficult for learners). knowledge tracing did not       demonstrate such an interactional effect with cue types. instead, it boosted the       instructional effect promoted by cue contrast.
stroop interference is often explained by an automaticity account,       according to which it arises due to more extensive practice in reading than in       color naming. here we investigated the effect on interference of isolated       practice in color naming (of incongruent and neutral stimuli) and in word reading       (of color names) in adults and children in grades 4–5. in both groups       interference was reduced after practicing color naming of incongruent stimuli.       for children, interference was also reduced after practice in word reading of       color names. in neither group was interference diminished after practice in color       naming of neutral stimuli. these findings are consistent with a negative       relationship between reading ability and interference and challenge the       automaticity account.
 a series of papers have appeared investigating the ability of         various species to learn context-free languages. from a         computational point of view, the experiments in this tradition         suffer from a number of problems concerning the stimuli used in the         training phase of the experiments, the controls presented in the         test phase of the experiments, and the motivation for and the         conclusions drawn from the experiments. this paper discusses in some         detail the problems with the existing work in this domain before         presenting a new design for this type of experiments that avoids the         problems identified in existing studies. finally, the paper presents         results from a small study demonstrating the benefits of the new         design.
vertical and horizontal head movements (universally associated       with nodding and shaking, respectively) have frequently been demonstrated to       affect cognitive processes. two experiments were conducted to test the hypothesis       that overt head movements can influence memory for valenced images. in the first       experiment, participants were instructed to perform either vertical or horizontal       head movements while viewing a slideshow of 76 randomized positive and negative       images, which they later had to recognize from a set containing 50% of the same       target images and 50% distractor images. no interaction between head movement       type and image valence was obtained. in the second experiment, participants were       told to remember as many images as possible from a slideshow of 60 randomized       valenced images, which they were later asked to freely recall. a significant       interaction was obtained, with a higher rate of recall for positive images when       vertical head movements (vhm) were performed and a higher rate of recall for       negative images when horizontal head movements (hhm) were performed.
the debate between hierarchical versus sequential structure in       language acquisition has recently flared up again (cf. frank, bod & christiansen       2012; pesetsky 2013). roughly, the nativist view on language endorses that human       language acquisition is guided by innate rules that operate on hierarchical       structures. the empiricist view assumes that language acquisition is the product       of abstractions from empirical input but leaves it as an open question whether       sequential or hierarchical structure is needed. some empirical models use       sequential structure (e.g. reali & christiansen 2005) while other models are       based on hierarchical structure (bod 2009; bod & smets 2012). 
the crux of the whorfian thesis is that our thought and behavior       are influenced in deep ways by the language we use. in recent years we have seen       a wave of rigorous and creative investigations of this thesis (boroditsky, 2010;       wolff & holmes, 2011 for reviews). yet, many researchers remain highly skeptical       of findings purporting to support whorfian claims  (gleitman & papafragou, 2005),       and much confusion remains about how to integrate these find-ings into existing       theories of cognition. a major barrier to understanding the degree to which       various aspects of human cognition may be affected by speaking different       languages is understanding the relationship between language—any       language—and the rest of cognition. to remove this barrier we need to       address a fundamental question: to what degree is normal human cognition actually       language-augmented cognition? i will argue that a surprising variety of behavior       previously assumed to be “nonverbal” shows signs of being influenced       by linguistic factors and i will outline a theory of language-augmented thought       that offers a mechanistic account of where we might expect to find effects of       language on “nonverbal” cognition (lupyan, 2012a, 2012b, for       reviews).
in the 1970s and 80s cognitive science and cognitive linguistics       and computational psycholinguistics emerged as the boxes around our disciplines       started to become straight-jackets, and research out of one discipline would       start to make waves in others. the toy systems of artificial intelligence were       reaching limits, and introspection by programmers and engineers was reinventing       square wheels without any biological plausibility and in ignorance of relevant       work across the cognitive sciences, while conversely, work in other fields often       lacked the understanding of computability and complexity necessary to ensure that       models were realistic and computationally plausible.        this is the starting point for the research program i have been undertaking for       the last 35 years, seeking to build intelligent computer systems and       computational cognitive models. the idea has been to try to build an intelligent       system modelled on the way a baby learns about the world, culture, society and       language. conversely, the idea has been to explore theories from psychology,       linguistics and neuroscience through the medium of computational models.
we present results from a new paradigm: mass participation games.       in our experiments, hundreds of people can play a computer game simultaneously       using audience response handsets. we can collect responses from a lecture hall       full of people with the precision of a laboratory cubicle. we have studied two       games: continuous, action games where participants cooperate to achieve a goal;       and decision- making paradigms in which participants make repeated choices to       maximise their own or the group’s rewards. we address a range of       theoretical questions with experimental manipulations and computer modelling. do       participants play as if they were alone, or as a group? if so, do they represent       the group as a single entity, or a collection of other agents? what are the       dynamics of these behaviours, with learning across many trials? lastly, what does       it feel like to act in concert, or in competition, with a room full of       people?
grounded (embodied) theories of cognition propose that memory,       including knowledge and meaning, is grounded in sensorimotor and mental state       processes. the main proposed mechanism for how memory is grounded is mental       simulation. simulation occurs when neural activity in modal association cortex       triggers time-locked, recurrent and feedback activity across multiple lower-level       modal processing areas from which the memory was initially constructed. through       this distributed multi-regional activity, seeing an object or reading its name       (e.g., “dog”) re-enacts associated features that were stored during       earlier learning experiences (e.g. its shape, color, motion, actions with it),       thereby constructing cognition, memory, and meaning. this paper reviews       convergent evidence from cognitive neuroscience of mental imagery, object       cognition, and memory that supports a multi-state interactive (musi) account of       automatic and strategic mental simulation mechanisms that can ground memory,       including the meaning, of objects in modal processing of visual features.
probabilistic models of cognition have enjoyed recent success in       explaining how people make inductive inferences. yet, the difficult computations       over structured representations that are often required by these models seem       incompatible with the continuous and distributed nature of human minds. to       reconcile this issue, and to understand the implications of constraints on       probabilistic models, we take the approach of formalizing the mechanisms by which       cognitive and neural processes could approximate bayesian inference.       specifically, we show that an associative memory system using sparse, distributed       representations can be reinterpreted as an importance sampler, a monte carlo       method of approximating bayesian inference. this capacity is illustrated through       two case studies: a simple letter reconstruction task, and the classic problem of       property induction.  broadly, our work demonstrates that probabilistic models can       be implemented in a practical, distributed manner, and helps bridge the gap       between algorithmic- and computational-level models of cognition.
the purpose of this study was to examine the process of embodied       cognition in distance estimation. according to recent cognitive science studies,       our intelligent behavior that ranges from perception to inference is not       accomplished in only a closed mental process, but is affected by body and action.       however, previous studies do not clarify whether these effects were derived from       physical load or subjective heaviness. in order to examine the question, two       experiments were conducted using the “size-weight illusion’’.       performance on the distance estimation task was not affected by subjective       heaviness but by physical load.
this study attempts to advance corpus-based exploration of sound       iconicity, i.e. the existence of a non-arbitrary relationship between forms and       meanings in language. we examine a number of phonesthemes, phonetic groupings       proposed to be meaningful in the literature, with the aim of developing ways to       validate their existence and their semantic content. our first experiment is a       replication of otis and sagi (2008), who showed that sets of words containing       phonesthemes are more semantically related to each other than sets of random       words. we augment their results using the british national corpus and the       semantic vectors package for building a distributional semantic model. our second       experiment shows how the semantic content of at least some phonesthemes can be       identified automatically using wordnet, thereby further reducing the room for       intuitive judgments in this controversial field.
spatial skills have been associated with learning in stem areas       and some research has shown that playing video games could facilitate the       development of spatial skills.  this study examines whether playing a game that       uses a realistic physics engine and places spatial demands on the players could       facilitate learning a subsequent physics lesson.  fifty-eight participants viewed       a brief lesson on newton’s laws of motion after either playing the puzzle       game tetris or the first-person perspective puzzle game portal, which       incorporates aspects of physics such as momentum.  the groups did not differ on       subsequent tests of learning outcomes involving physics, but the portal group       scored significantly higher on a perspective taking test (d = 0.57). this study       shows that playing a commercial game that incorporates newtonian physics does not       prepare students to learn physics but does improve an important spatial cognition       skill related to physics.
while social psychology has identified characteristics of       intergroup dynamics, few studies have looked into the perceptions  of robot group       dynamics.  in this experiment, we  separate robots into majority and  minority        groups based solely on their behavior in a simple dance routine.  we attempt to       understand how people's perceptions of robots within those groups change based on       group size and features of  behavior.  participants viewed the robot dances and       rated one robot from each group on a variety of characteristics. we find that       being from the minority versus majority group  has a significant impact on       perceptions of a robot's creativity, interestingness, anti-sociality, dancing       ability, and how much of a team player it  is.  at the same time, individual       behaviors (leading the dance, following the dance, or performing an entirely       unique dance) have no statistical effect on participants' ratings of robot       characteristics.  from these results, we conclude that group size has a larger       effect than behavior on  subjective evaluations of robots in majority and       minority groups.  
bar graphs and line graphs are commonly used ways of graphical       communication. due to the difference in their perceptual visuo-spatial       properties, they facilitate comprehension of different events. bar graphs are       commonly used in the domain of precipitation although the data intrinsically       carry information that is averaged over long time spans. in this study, we       investigate how the presence of incongruence between consecutive graph pairs       influences conceptualization of the represented information about precipitation.       for this, we analyzed gestures and verbal descriptions produced by the       participants as indicators of event conceptualizations. the results of the       experimental investigation reveals that when incongruent graph pairs are       presented, the participants show tendency to produce directional gestures that       accompany the verbal descriptions of the specific regions represented by one/two       bars. additionally, the presence of incongruence seems to enhance the production       of comparative words accompanied with non-directional gestures.  
we report an experiment investigating how concurrent verbalisation       during a task can affect performance (a so-called "reactivity" effect).       participants studied three-variable line graphs while (a) concurrently thinking       aloud or (b) silently studied the graphs and provided an interpretation once they       felt they had understood it. results showed that verbalisation hindered       performance significantly compared to the silent condition. to support the claim       that the act of verbalising was hindering performance, competing explanations       were also tested, which confirmed thinking aloud as the most likely cause. this       contradicts claims by ericsson and simon (1993) that thinking aloud reflects but       does not affect performance and provides further evidence that verbalising       thought processes can hinder performance.       
recent research into the impact of labelling on infants’       visual       category formation has led to controversial results, with       some findings indicating a beneficial role and others pointing       to interference effects in the presence of labels. here we       present an eye tracking study with 12-month-olds investigating       the impact of the label’s timing on categorisation. we find       that synchronous presentation of words and objects leads to       a decreased novelty preference, creating the impression of a       dramatic detrimental impact on learning. asynchronous presentation       of the word one second after the image onset does       not appear to interfere with processing. detailed analyses of       infants' gaze patterns with respect to object parts reveal that       even synchronous labels do not hinder learning but slow down       infants' shift from familiarity to novelty preference. besides       offering detailed insight into the effects of labelling on infants'       attention our findings offer the potential to reconcile previous       contradictory results.       
when identifying basic-level categories (e.g., airplane, cow),       typically developing (td) children commonly use the overall shape of objects as       basis for their judgments. this so-called shape bias is tied to the size of a       child’s vocabulary and as such might be a way of adaptively organizing an       ever-growing vocabulary. the current study looks at whether the same is true for       children with autism spectrum disorder (asd). a group of participants with asd       and td controls were asked to categorize objects that differed in the amount of       item detail. results show that vocabulary size was related to success in       categorizing objects for td participants, but not for asd participants. we       discuss the degree to which a link between shape bias and vocabulary size in asd       children may be an indication of differentiated patterns of adaptation.
there have been contradictory reports of sex differences in       language processing. a novel approach is adopted here which       explores the experiential basis of such differences. two       studies examine the auditory processing of grammatical       gender in bulgarian in a gender decision (gender monitoring)       task and a cued shadowing (word repetition) task. reaction       times in both experiments reveal significant two-way       interactions between the grammatical gender of words       (masculine vs. feminine) and the sex of the voice (male vs.       female). the sex of participants in the gender decision task       also interacted with word gender in terms of decision       accuracy. women were relatively more accurate on their       “own reference” word gender (feminine) and less accurate on       masculine gender words. a two-way interaction between       word gender and participant sex on response latencies in the       cued shadowing task supports the view that these effects are       not strategic but have a highly automatic nature instead.       findings are interpreted in terms of individual differences in       the experience of grammatical gender in such gender-marking       languages.
prominent theories of decision making, such as {\it proportional       difference model}, {\it priority heuristics}, {\it decision field theory} and       {\it regret theory} assume that people do not evaluate options independently of       each other. instead, these theories predict that people compare the options'       outcomes with each other. therefore the theories' predictions strongly depend on       the association between outcomes. in the present work, we examine how the       association between options can be best described. for options with two outcomes       the standard correlation measure between option's outcomes does not provide a       meaningful interpretation. therefore, we propose the standardized covariance       between options a and b, denoted as $\sigma^*_{ab}$. we describe the properties       and interpretation of this measurement and show its similarities and differences       with the correlation measurement. finally, we show how the predictions of       different models of decision making vary depending on the value of the       standardized covariance.
in this paper, we introduce a novel dynamical bayesian network       model for probabilistic language modeling. we refer to this as the hidden       stochastic automaton. this model, while based on a generalization of the hidden       markov model, has qualitatively greater generative power than either the hidden       markov model itself or any of its existing variants and generalizations. this       allows the hidden stochastic automaton to be used as a probabilistic model of       natural languages in a way that is not possible with existing dynamical bayesian       networks. its relevance to cognitive science is primarily as a computational ---       in the marr (1982) sense of the term --- model of cognition, but potentially also       as a model of resource bounded cognitive processing, and as a model of the       implementation of computation in physical dynamical systems.
in this work, we propose an evolutionary account of reactions to a       wrong as an integrated set. unlike other theories, we are not interested in       revenge, punishment or sanction per se, but in their co-existence. we posit that       this variety of reactions is needed in order to achieve different goals, but it       also implies an increase in cognitive costs that requires to be explained from an       evolutionary perspective.  moving from the identification of the psychological       traits that uniquely define each reaction, two concurrent hypotheses are       suggested and discussed: either the richness of human social life requests a       variety of reactions, or the benefits of single reactions at the psychological       level allowed these reactions to be maintained in the social life.
research suggests that gestures influence cognitive processes, but       the exact mechanism is not clear. additionally, it has been shown that when a       linguistic task (metaphor explanation) involves the right brain hemisphere, the       left hand becomes more gesturally active. we hypothesized that gestures with a       particular hand activate cognitive processes in the contra-lateral hemisphere. we       examined whether gestures with the left hand enhance metaphoricity in verbal       responses. results showed participants produced more metaphoric explanations when       instructed to produce gestures with their left hand as compared to the right hand       or not gesture at all. in addition, we measured the mouth asymmetry during       metaphorical speech to determine individual differences in right-hemisphere       involvement in metaphor processing. the left-side mouth dominance, indicating       stronger right-hemisphere involvement, positively correlated with the       left-hand-over-right-hand advantage in gestural facilitation of metaphorical       speech. we concluded that left-hand gestures enhance metaphorical thinking in the       right hemisphere.
when proponents of cognitive externalism (ce) have turned to       empirical studies in cognitive science to put the framework to use, they have       typically referred to perception, memory or motor coordination. not much has been       said about reasoning. one promising avenue to explore here is the theory of       bounded rationality (br). in this paper, we try to clarify the potential       relationship between these two programs. we start by discussing andy       clark’s interpretation of  br, which we find unconvincing in several       respects. next, we take a closer look at ce in order defend a version of it that       stands against mainstream internalism without committing itself to constitutional       claims about the mind. we then turn to analyze br from the ce perspective.       finally, we argue that internalism about cognition cannot explain important       aspects of the br program.
graphical password is an alternative method of authentication to       alphanumerical passwords. from the perspective of research on human memory, it is       yet another novel technology that introduces challenges on human memory       components. in this study, we aim to investigate the previous findings in human       visual memory in the domain of graphical passwords by analyzing the role of       visual coherence in passwords. the results of an experimental study reveal that       in terms of memorability, coherent images are better candidates as graphical       password images than jumbled images.
systematic research of instruction-based conceptual change in       mathematics and science is characterized by examining the effectiveness of a       particular instructional principle in isolation. it is suggested that the field       could gain from studying how different instructional principles interact when       they are combined. the goal of this research was to systematically study the       combined effects of collaborative learning and hypothesis testing on cognitive       growth. in a randomized experiment, 496 9th graders solved challenging tasks that       required fully developed proportional reasoning. half of them were given the       opportunity to test their solutions. based on individual pretests, each student       was assigned to one of three competency levels (low, medium, high), and randomly       assigned to either work alone or with a (low, medium, high) peer. the findings       show that the effectiveness of hypothesis testing are conditioned by fine-grained       differences in the contingencies between the target student’s level of       competence, the peer partner’s level of competence and the feedback they       receive from the objective testing device.
we investigated the use of iconic and deictic gestures during the       communication of spatial information. expert structural geologists were asked to       explain one portion of a geologic map. spatial gestures used in each       expert’s response were coded as deictic (indicating an object in the       conversational space), iconic (depicting an aspect of an object or event), or       both deictic and iconic (indicating an object in the conversational space by       depicting an aspect of that object). speech paired with each gesture was coded       for whether or not it referred to complex spatial properties (e.g. shape and       orientation of an object). results indicated that when communicating spatial       information, people occasionally use gestures that are both deictic and iconic,       and that these gestures tend to occur when complex spatial information is not       provided in speech. these results suggest that existing classifications of       gesture are not exclusive, especially for spatial discourse. 
recent research suggests that children’s ability to learn       words via fast mapping is strongly related to the attentional demands of the       task. here we explore whether lowering the attentional demands during the initial       fast mapping task facilitates word learning. three-year-old children completed       fast mapping and test trials using a touch screen computer. for half of the       children, the non-targets (competitors) repeated across trials and for other       children there was no repetition. all children received the same word learning       test trials. only children who had received repeating competitors (lower       attentional demands) during the initial fast mapping task demonstrated word       learning. thus, these data suggest that children’s ability to learn novel       names is strongly influenced by the competition and attentional demands of the       initial fast mapping context.
in the debate around the extended mind, the special alliance that       the extended thesis often has with functionalism usually plays in favor of the       former, with functionalism providing support for the extended thesis. here i want       to consider this alliance in the opposite direction: does the extended thesis       provide support for functionalism by promoting the need of a level of explanation       that is independent of implementational (in particular neural) details? in spite       of a seemingly promising line of reasoning for an affirmative answer, i show here       that a commitment to the extended thesis or any version of externalism neither       paves the way for a functionalist (or any other anti-reductionist) position nor       is incompatible with an explanatory reductionism about the mind. i arrive to that       conclusion after analyzing an argument by van eck et al. (2006) meant to conclude       the opposite, and showing why it is unsound.
categorical perception is a well studied phenomenon in, for       example, colour perception, phonetics and music. in this article we implement a       dynamical systems model of categorical rhythm perception based on the resonance       theory of rhythm perception developed by large (2010). this model is used to       simulate the categorical choices of participants in two experiments of desain and       honing (2003). the model is able to accurately replicate the experimental data.       our results supports that resonance theory is a viable model of rhythm perception       and they show that by viewing rhythm perception as a dynamical system it is       possible to model properties of categorical perception.
researchers since at least darwin have debated whether and to what       extent emotions are universal or culture-dependent. however, previous studies       have primarily focused on facial expressions and on a limited set of emotions.       given that emotions have a substantial impact on human lives, evidence for       cultural emotional relativity might be derived by applying distributional       semantics techniques to a text corpus of self-reported behaviour. here, we       explore this idea by measuring the valence and arousal of the twelve most popular       emotion keywords expressed on the micro-blogging site twitter. we do this in       three geographical regions: europe, asia and north america. we demonstrate that       in our sample, the valence and arousal levels of the same emotion keywords differ       significantly with respect to these geographical regions --- europeans are, or at       least present themselves as more positive and aroused, north americans are more       negative and asians appear to be more positive but less aroused when compared to       global valence and arousal levels of the same emotion keywords. our work is the       first in kind to programatically map large text corpora to a dimensional model of       affect.
using a computational model of verb argument structure learning,       we study a key assumption of the usage-based theory: that       the acquisition of a construction relies heavily on the existence       of a high-frequency exemplar verb that accounts for a large       proportion of usages of that construction in the input. importantly,       unlike the psycholinguistic experiments that focus       on the learning of an artificial novel construction using novel       verbs, here we examine the acquisition of the english sentential       complement construction from naturalistic input. our       results provide new insights into exemplar-based learning in       the context of naturalistic input with multiple semantic classes,       and a diverse set of constructions for the verbs.
we explore the interaction between information sampling and the       structure of the social environment in the case of two prominent social learning       strategies: imitate-the-best and imitate-the-majority. in a series of simulations       a group of agents made repeated choices between options. we varied the building       blocks of the strategies used by agents, the structure of the social network and       characteristics of the task environment. a key factor influencing       strategies’ success is the speed with which they are able to respond to       environmental change. in general, imitate-the-best provides a faster response       compared to imitate-the-majority and larger samples help the former but hurt the       latter. less efficient networks decrease the performance of both, but are more       detrimental for imitate-the-majority. our findings highlight the role of sampling       and social structure in the study of social learning, an area not sufficiently       explored before.
related languages, like english and spanish, often have similar       orthographies but use the same letters for different sounds. learning a second       language frequently involves learning additional letter-sound mappings that       mismatch native language mappings. in the current study, we investigated whether       l2 spoken words activate l2 orthography despite conflict with l1       orthography-to-phonology mappings. participants first learned an artificial       language with letter-sound mappings that mismatched english (e.g., the letter 'g'       represented /h/, and the word /gufo/ was spelled 'hane'). next, fixations of l1       orthographic competitors (e.g., 'cane') in response to auditory l2 input (e.g.,       /gufo/) were assessed using the visual world paradigm. results showed that       participants fixated l1 competitors that overlapped with targets orthographically       (but not phonologically) more than unrelated fillers. we conclude that second       language learners can rapidly acquire novel letter-sound mappings, and words       based on these mappings are integrated into the existing lexicon, activating       orthographic competitors in the native language.
syntactic category ambiguities are very frequent in natural       languages, and all architectures of language processing need a mechanism for       disambiguating syntactic category ambiguities. corley and crocker (2000)       suggested that syntactic category disambiguation can be assigned its own module       within a modular architecture. we will show that the model defined by corley and       crocker can account for a considerable amount of variance in reading times of       naturally occurring texts. in addition, we provide evidence that syntactic       category disambiguation may be independent of syntactic top-down expectations,       emphasizing the important role of bottom-up processes within an architecture of       human language processing.
as tools in science, diagrams not only serve as vehicles for       communication but also facilitate and constrain scientific reasoning. we identify       roles that diagrams play when computational models and synthesized organisms are       used to recompose mechanisms proposed to explain biological phenomena. diagrams       not only serve as locality aids for constructing computational models but also       help in identifying ways to manipulate these models and interpret the results.       moreover, they serve as blueprints for constructing synthetic organisms and then       guide the interpretation of discrepancies between these organisms and       computational models.
the development of social robots that convey emotion with their       bodies---instead of or in conjunction with their faces---is an increasingly       active research topic in the field of human-robot interaction (hri). rather than       focusing either on postural or on dynamics aspects of bodily expression in       isolation, we present a model and an empirical study where we combine both       elements and produce expressive behaviors by adding dynamic elements (in the form       of perlin noise) to a subset of static postures prototypical of basic emotions,       with the aim of creating expressions easily understandable by children and at the       same time lively and flexible enough to be believable and engaging.  results show       that the noise increases the recognition rate of the emotions portrayed by the       robot.
recent evidence shows tense-response compatibility effects only       when the task relates to sentence tense (ulrich & maienborn, 2010). in two       eye-tracking experiments, we investigated tense-response compatibility effects.       in our first experiment (e1, where sentence tense was relevant to the task) we       found compatibility effects at the beginning of the sentence (e.g., yesterday       versus tomorrow), which shifted to interference effects by sentence end. overall,       we also found compatibility effects in response times, replicating ulrich and       maienborn. both compatibility effects in experiment 1 (e1) were stronger for low-       compared to high-wm readers. in experiment 2 (e2, where tense was irrelevant), we       found compatibility effects for high-wm readers, but only in early reading       measures. these results suggest that compatibility effects are weaker depending       on the task, but not eliminated; an implication which may help refine a strict       view of embodied cognition.
when a child first begins to acquire a lexicon, the sources of       word-meanings must be available from the situational context. however, it has       been argued that the situational availability of the meanings of relational       terms, such as verbs, is lower than that of whole-object labels, such as nouns.       in this paper, we present a corpus of child-directed language, paired with       situational descriptions, that enables us to explore the situational availability       of word-meanings using a computational learner.
instructional analogies can overload children’s executive       function and working memory resources (see richland,       morrison & holyoak, 2006), though structure-mapping lies at       the core of recommended pedagogy in mathematics       instruction (national mathematics panel, 2008; nrc, 2001).       videotaped mathematics instruction was manipulated to test       the role of visual representations in instructional analogy.       pretest, posttest, and delayed posttest measures assessed 11-       13 year old children’s learning from one of three versions of       the same lesson in which three solution strategies (one a       misconception) were compared. analogs were either a) not       visible (nv) - presented only orally, b) partially visible (pv)       – only the most recent solution was visible, or 3) all visible       (av) - all solutions were visible throughout the instruction.       overall, av students experienced greater learning gains in       procedural knowledge, procedural flexibility, and conceptual/       schematic knowledge compared to pv students. these results       persist after one-week delay. apart from procedural       knowledge, the same trend is evident when comparing av       students’ to nv students’ immediate learning gains. overall,       visual representations of analogs within an instructional       analogy appear to support schema formation only when they       are all visible simultaneously and throughout structuremapping.       showing students visual representations of analogs       but not enabling them to be simultaneously visible led to the       lowest performance overall, suggesting this may lead to more       object-level encoding than schema formation.
current theories of communication yield predictions about the       expression choice of overhearers as well as primary discourse participants. we       discuss three such theories and evaluate them with reference to new data on       object naming elicited through a confederate priming paradigm. our results show       that participants adopt primed referring expressions if they are highly involved       in the task, but mere exposure to the object labels yields very limited priming       effects. also, common ground is a relatively marginal factor in expression choice       here. we interpret these results as supportive of the importance of grounding and       challenging for interactive alignment-based accounts of expression choice.
task influence has long been known to play a major role in the way       our eyes scan a scene. interestingly, how the task modulates attention when       interacting with objects has been less investigated. only few studies have       contrasted the distribution of eye fixations during viewing and grasping objects.       how is at- tention differently deployed when different actions have to be planned       on objects in contrast to a purely perceptual viewing condition? to investigate       these issues, we conducted an eye- tracking experiment showing participants 2d       images of real- world objects. in blocks of trials, participants were asked       either to assign the displayed objects to one of two classes (classification       task), to mimic lifting the object (lifting task), or to mimic opening the object       (opening task). mean fixation locations and attention heatmaps show different       modes in gaze distribution around task-relevant locations, in accordance with       previous literature. reaction times, measured by button release in the manual       response, suggest that the more demanding the task in terms of motor planning the       longer the latency in movement initiation. results show that even on simplified,       two dimensional displays the eyes reveal the current intentions of the       participants. moreover, the results suggest elaborate cognitive processes at work       and confirm anticipatory behavioral control. we conclude with suggesting that the       strongly predictive information contained in eye movements data may be used for       advanced, highly intuitive, user-friendly brain-computer interfaces.
self-explanation is an important constructive cognitive process       that helps students learn in such a way that they can flexibly transfer their       knowledge to solve novel problems (chi, bassok, lewis, reimann, & glaser, 1989).       however, research has not addressed what leads students to spontaneously       self-explain, in the absence of prompting. the present study experimentally       manipulates student motivation (in terms of achievement goals) and measures what       influence this has on self-explanation and transfer. participants (n = 140)       received goal framings that reflected either a mastery-approach goal (striving to       develop one’s understanding), a performance-approach goal (an aim to       outperform others), a performance-avoidance goal (avoid doing worse than others)       or a no-goal control. this framing was applied to a set of learning and test       tasks on basic statistics, which participants completed while thinking aloud.       results showed a benefit for a performance-avoidance condition in terms of both       higher levels of self-explanation and transfer. this unexpected result is       discussed in terms of theories of motivation and learning, and their potential       impact on educational practice. 
we investigated the behavior of participants tasked with com-       municating in a novel environment. participants had to use their mouse to draw       graphical representations (termed squig- gles in the game) of human faces in       order to communicate with fellow players. experiment 1 investigated the effect of       varying features of the input images on the resulting drawings. ex- periment 2       introduced varying comprehension conditions that were predicted to produce       differences in how features of faces would be graphically represented. in       experiment 1, the fea- tures of the different faces significantly shaped the       structure of the resulting squiggles. in experiment 2, the structure of the       squiggles was influenced by the environment in which they were interpreted.
analogical reasoning and its applications are gaining attention       not only in cognitive science but also in the context of education and teaching.       in this paper we provide a short analysis and a detailed formal model (based on       the heuristic-driven theory projection framework for computational       analogy-making) of the calculation circular staircase, a tool for teaching basic       arithmetic and insights based on the ordinal number conception of the natural       numbers to children in their first years of primary school. we argue that such       formal methods and computational accounts of analogy-making can be used to gain       additional insights in the inner workings of analogy-based educational methods       and tools.
we formalize the biased activation theory of anchoring using a       bidirectional associative memory network. anchors determine the starting state of       this network. as the network settles, we show that the nodes representing       numerical responses activate and deactivate consecutively, generating sequential       adjustment. by demonstrating that anchoring as adjustment emerges naturally from       the dynamics of the biased activation process, we are able to unify the two main       theories of the anchoring effect, and subsequently provide a parsimonious       explanation for a large range of findings regarding anchoring, and its       determinants. although we focus largely on phenomena related to anchoring, the       results of this paper apply equivalently to all judgments under the influence of       bidirectional processing, including those involving constraint satisfaction.
distributed models of lexical semantics increasingly incorporate       information about word order. one influential method for encoding this       information into high-dimensional spaces uses convolution to bind together       vectors to form representations of numerous n-grams that a target word is a part       of. the computational complexity of this method has led to the development of an       alternative that uses random permutation to perform order-sensitive vector       combinations. we describe a simplified form of order encoding with convolution       that yields comparable performance to earlier models, and we discuss       considerations of neural implementation that favor the use of the proposed       encoding. we conclude that this new encoding method is a more neurally plausible       alternative than its predecessors. 
this study investigated the ability of learner-generated       visualizations to improve learning in science. the hypothesis       was tested in two domains, a mechanical system and a       chemical system, and the results were analyzed separately to       compare low and high spatial ability learners. the production       of visual explanations of a mechanical system, a bicycle tire       pump, increased understanding of the pump particularly for       participants with low spatial ability. in the domain of       chemical bonding, visual explanations were more effective       than verbal explanations for all participants. visual       explanations often included crucial yet invisible features; their       accurate construction requires and provides a check for       completeness of explanations.
in times of globalization, differences between cultures and in the       interpretation of linguistic terms can lead to misunderstanding in communication.       the present study focuses on the influence of cultural dimensions, especially       uncertainty avoidance, on the interpretation of verbal probability expressions.       it is hypothesized that uncertainty avoidance has an effect on the interpretation       of uncertainty expressions. therefore, spanish and german participants were asked       (1) for uncertainty avoidance and (2) to estimate numerical equivalents for 12       verbal probability expressions (e.g., possible). the estimation data were modeled       using fuzzy membership functions. results neither show differences in uncertainty       avoidance nor in the interpretation of the probability expressions between these       two languages. possible reasons and future research perspectives are       discussed.
people tend to react more strongly to a dread risk, a rare event       that kills many people at once, than to a continuous risk, a relatively frequent       event that kills many people over a longer period of time, even when both cause       the same number of fatalities. this different reaction to the dread risk is often       considered a bias, but we show that it is an ecologically rational strategy. in a       series of simulations, we found evidence that dread risks affect the population       more severely over time than continuous risks causing the same number of       fatalities. this holds particularly true when the risks affect children and young       adults who would have produced future offspring if they had survived longer. 
past research suggests that spatial configurations play an       important role in graph comprehension.  the present study investigates       consequences of this fact for the relative utility of graphs and tables for       interpreting data.  participants judged presence or absence of various       statistical effects in simulated datasets presented in various formats.  for the       statistical effects introduced earlier in the study, performance was better with       graphs than with tables, while for the effect introduced last in the study, this       trend reversed.  additionally, in the later sections of the study, responses with       graphs, but not tables, reflected increasing influence from the presence of       stimulus features which had been relevant earlier in the study, but were no       longer relevant. the findings suggest that graphs, relative to tables, may better       facilitate perception of complex relationships among data points, but may also       bias readers more strongly to favor some perspectives over others when       interpreting data.
we examined lexical choice and variability in referring       expressions during direction-giving to pedestrians. a stationary partner (the       giver) directed a mobile partner by telephone (the follower) to walk about 1.8       miles, to 18 destinations on a medium-sized campus. followers returned to the lab       and partners were tested individually on their spatial ability and memory for the       destinations; then they participated in 6 rounds of a referential communication       task to repeatedly match duplicate copies of pictures of the destinations.       results include significant rates of lexical entrainment and evidence for       partner-specific conceptual pacts. joint navigation efficiency was affected by       direction-givers’ (but not followers’) spatial ability. the walking       around corpus, an experimentally parameterized collection of spontaneous spoken       dialogues produced by 36 pairs of people communicating by mobile telephone,       provides a testbed for lexical entrainment “in the wild” as well as a       resource for pedestrian navigation applications; it is available to the research       community. 
tracking persons, that is, determining that a person now is or is       not a specific earlier person, is extremely common and widespread in our way of       life and extremely important. if so, figuring out what we are tracking, what it       is to persist as a person over a period of time, is also important. trying to       figure this out will be the main focus of this paper. (this paper will introduce       a theme on tracking persons in topics in cognitive science.)
belief revision is required when new facts are incompatible with       existing beliefs. in the present experiment, participants changed their mind       about the spatial and non-spatial relations between objects. the participants       received information about relations, which were subsequently contradicted by       irrefutable counterfacts. the task was to decide which of the initial relations       to retain and which ones to give up. previous experiments showed that these       decisions are guided by the linguistic asymmetry between located (lo) and       reference objects (ro). reasoners have a strong preference to relocate the lo of       the counterfactual relation. our experiment explores whether this robust effect       can be overwritten by the plausibility of revised beliefs; and how       visualizability of problems affects revision. we found the lo-preference to be       robust even when the resulting representation is implausible; and that revision       is impeded when problems are easy to visualize. the results shed new light on       relational belief revision in humans.
many in cognitive science have noted the importance of external       visualizations for reasoning and learning, and have suggested that such       visualizations play a role in complex reasoning contexts such as scientific       investigation.  however, what cognitive role diagrams play in scientific       reasoning is unclear.  i suggest that mechanistic diagrams function as search       organizers in active research projects. diagrams aid in scientific reasoning by       being uniquely positioned to coordinate cognitive search through multiple search       spaces, both within an individual and within a field. i examine this role using a       number of published diagrams from mammalian chronobiology.
participants estimated allocentric headings using pictures of       familiar buildings around a college campus, in an allocentric-heading recall       task. a weak relationship between sense-of-direction and accuracy, an alignment       effect, and a novel relationship between strategy and accuracy were found. these       results demonstrate that sense-of-direction and strategy use differentially       affect accuracy across heading disparities. our findings suggest that individual       differences and strategy differences need to be incorporated into current       hypotheses regarding allocentric-heading – specifically, into the       animal-model hypothesis.
in two experiments we explored whether participants would be able       to use probabilistic cues to simplify perceptually demanding visual search in a       task we call the retrieval guidance paradigm. on each trial a background cue       appeared prior to (and during) the search task and the diagnosticity of the       background cue(s) was manipulated to provide complete, partial, or non-diagnostic       information regarding the target’s color on each trial. only when       participants were made aware of the possible relationship between the background       cues and target features were they able to utilize the cue information for       search. when participants were not made aware of the possible connection, they       were only able to use target base rates. in the general discussion we address how       a recent computational model of hypothesis generation (hygene, thomas, et al.,       2008), provides a useful framework for understanding how long-term memory,       working memory, and attention coordinate in visual search.
people judge that harmful side effects are intentional, e.g., a       ceo who introduces a new program to increase profits that results in harm to the       environment is judged to have intentionally harmed the environment. they judge       helpful side effects are unintentional, e.g., a ceo who introduces a new program       to increase profits that results in helping the environment is not judged to have       intentionally helped the environment. we report two experiments that suggest the       effect arises because people believe individuals can make alternative choices in       bad situations and not in good ones. 
we report two visual-world eye-tracking experiments that       investigated how and with which time course emotional information from a       speaker’s face affects younger (n = 32, mean age = 23) and older (n = 32,       mean age = 64) listeners’ visual attention and language comprehension as       they processed emotional sentences in a visual context. the age manipulation was       aimed at testing predictions by socioemotional selectivity theory of a positivity       effect in older adults. after viewing the emotional face of a speaker (happy or       sad) on a computer display, participants were presented simultaneously with two       pictures depicting opposite-valence events (positive and negative; iaps database)       while they listened to a sentence referring to one of the events.       participants’ eye fixations on the pictures while processing the sentence       were enhanced when the speaker’s face was emotionally congruent with the       sentence/picture compared to when it was not. the enhancement occurred from the       early stages of sentence-reference disambiguation; importantly, it was modulated       by age, in that for the older adults it was more pronounced with positive faces,       and for the younger ones with negative faces.         these findings demonstrate for the first time that emotional facial expressions,       similarly to previously studied speaker cues such as eye gaze and gestures, are       rapidly integrated into sentence processing. they also provide new evidence for       positivity effects in older adults in online incremental situated sentence       processing.
research on how information should be presented during inductive       category learning has identified both interleaving of categories and blocking by       category as beneficial for learning. previous work suggests that this mixed       evidence can be reconciled by taking into account within- and between- category       similarity relations. in this paper we present a new moderating factor. one group       of participants studied categories actively, either interleaved or blocked.       another group studied the same categories passively. results from a subsequent       generalization task show that active learning benefits from interleaved       presentation while passive learning benefits from blocked presentation.
relational match-to-sample is a difficult task for young children.       however, it has been shown that either presenting two examples of the relation or       adding a label to a single presentation can improve children’s performance.       the role of labels has been seen as increasing the likelihood of comparing the       instances available. in this paper, we present sustained attention as an       alternative to this view. children completed a relational match-to-sample task in       different conditions while an eyetracker registered their eye movements. when       only one instance was available, children benefited from the addition of a label.       this benefit was associated with an overall decrease in switching behavior,       indicating greater sustained attention. moreover, in the absence of a label,       children who showed greater sustained attention were able to achieve good       performance by the end of the task.
the current study examined reactions to the precision of       earnings’ forecasts in hypothetical investment decisions. in a forced       choice task, participants were found to be indifferent between point (e.g., $2)       or range (e.g., $1.70-$2.30) forecast formats when both outcomes were favorable       (i.e., above market expectation). when the outcomes were unfavorable (below       expectation), participants’ preferences were significantly biased towards       range estimates. when faced with options which mixed forecast formats and       favorability, participants almost always opted for forecasts with a favorable       outlook regardless of format. these results are inconsistent with domain specific       ambiguity reactions found previously (du, 2009) and also offer no support for the       domain specific anchoring hypothesis (e.g. du, 2009; du & budescu, 2005). these       findings raise some doubts about the generality of domain specific reactions to       uncertainty and suggest that such effects might be dependent, in part, on the       (financial) sophistication of participants. 
this paper examines whether producing gestures would facilitate       encoding of spatial relation in a navigation task. in this experiment, we focused       on gestures produced without accompanying speech. adult participants were asked       to study spatial sequence of routes shown in four diagrams, one at a time.       participants rehearsed the routes with gestures, actual hand movements (actually       drew the routes on papers), or mental simulation. they then were asked to       reconstruct the routes with sticks. participants who moved their hands (either in       the form of gestures or actual drawing) recalled better than those who mentally       simulated the routes and those who did not rehearse, suggesting that hand       movements produced during rehearsal facilitate encoding of spatial relation.       interestingly, participants who gestured the routes in the air recalled better       than those who drew them on papers, suggesting that gesture, as a kind of       representational action, exerts more powerful influence on spatial relation       encoding.
this study examined the processing correlates of aspectual       coercion among native and non-native speakers of english.       for native english speakers, results suggested that the       processing delay associated with aspectual coercion is       minimal. aspectual coercion was perhaps cognitively easy       to perform. by contrast, non-native speakers of english from       unlike first language (l1) backgrounds differed in their       reading performance. the differences varied systematically       as a function of aspectual contrasts in l1 after controlling       for second language (l2) english proficiency. korean       participants showed trends of aspectual coercion despite the       absence of significant effects; german participants exhibited       indifference across experimental conditions; chinese       participants showed aspectual coercion effects opposite to       the predictions specified by the english grammar. a       coupling of these data with evidence from the semelfactive       progressive (e.g. coughing) in english suggests that the socalled       online aspectual coercion effects may arise from a       prototype organization of aspectual categories that is prone       to l1 influence.
we examined the role of spatial representations and word order on       thematic role assignment in greek. previous studies suggest that spatial       representations influence thematic role assignment; agent is typically depicted       on the left, and patient on the right. here, we address this issue using a       language with flexible word order which allows us to manipulate sentence       structure (svo–ovs) orthogonally to thematic role. greek speakers heard       svo/ovs sentences while viewing depictions of actions involving two characters       and they judged whether sentence and picture matched in meaning. the       agent’s position in the picture was directly manipulated. the results       support the effect of left bias on language processing. however, this bias may be       better understood when its interaction with other sources of information and       language-specific constraints are taken into account. theories of prediction may       help us illuminate how spatial biases and linguistic factors interactively affect       the way we process our world.
do chinese and english speakers think about time differently?       inconsistent findings have been reported even when the same paradigms were used.       one of the factors that might have contributed to the inconsistency is       participants’ reading experience of horizontal and vertical texts. the       present study manipulated this factor experimentally by randomly assigning       chinese participants from taiwan and china to a reading task involving       horizontally or vertically arranged texts. a temporal judgment task       (spatial-temporal association of response codes or starc) followed the reading       task immediately. it asked the participants to judge if the event depicted in a       second picture occurred earlier or later than that depicted in the first.       responses were faster when the left keys represented the ‘earlier’       responses than when the right keys did (a starc effect). half of the participants       responded with a horizontally oriented keypad while the rest with a vertically       oriented keypad. for the taiwan participants, the starc effect was greater when       the response keys were oriented vertically than horizontally, but no difference       was observed for the china participants. the results also showed that both       immediate and lifetime reading experiences modulated the vertical bias. for the       taiwan participants, the vertical bias was strong following the vertical prime,       but it disappeared following the horizontal prime. for the china participants,       the horizontal prime led to a nonsignificant vertical bias whereas the vertical       prime brought about a significant horizontal bias. a questionnaire administered       upon completion of the starc task indicates that the two groups of participants       had similar lifetime experience of reading horizontal texts, but the taiwan       participants read vertical texts in their life far more frequently than the china       participants. we conclude that the directionality of orthography and       speakers’ (immediate and lifetime) reading experience can better explain       the vertical bias (or the lack of it) in the chinese speakers.
here we investigated whether hemispheric asymmetry effects can be       observed in nonconscious processing with a basic-level animal categorization       (cat/dog) task. we found a significant nonconscious congruency priming effect       when the prime was presented in the right visual field/left hemisphere but not       when it was presented in the left visual field/right hemisphere when the prime       duration was only 10 ms; the left-lateralized congruency priming effect was       consistent with the left hemisphere superiority in processing abstract category       information reported in the literature (e.g., marsolek, 1999). this result thus       showed that nonconscious processing can go beyond the sensory level to influence       hemispheric asymmetry in the processing of category information. in contrast,       this hemispheric difference was not observed when the prime was presented for 50       ms (nonconscious) or 150 ms (conscious). this effect may be because 10 ms       subliminal information was insufficient to allow inter-hemispheric       transfer/processing, allowing the hemispheric difference to emerge. it also       suggests that hemispheric asymmetry may be better observed at subliminal level.       
bayesian analogy with relational transformations (bart) is a       discriminative model that can learn comparative relations from non-relational       inputs (lu, chen & holyoak, 2012). here we show that bart can be extended to       solve inference problems that require generation (rather than classification) of       relation instances. bart can use its generative capacity to perform hypothetical       reasoning, enabling it to make quasi-deductive transitive inferences (e.g.,       “if a is larger than b, and b is larger than c, is a larger than       c?”). the extended model can also generate human-like instantiations of a       learned relation (e.g., answering the question, “what is an animal that is       smaller than a dog?”). these modeling results suggest that discriminative       models, which take a primarily bottom-up approach to relation learning, are       potentially capable of using their learned representations to make generative       inferences.
logical consistency and objectivity are cornerstones of science       that distinguish it from cult and dogma.  scientists’ concern with       objectivity has led to the dominance of associative statistics, which define the       basic concept of independence on observations.  the same concern with avoiding       subjective beliefs has led many scientific journals to favor frequentist over       bayesian statistics.  our analysis here reveals that to infer causes of a binary       outcome, (1) the associative definition of independence results in a logical       inconsistency -- even for data from an ideal experiment -- for both frequentist       and bayesian statistics, and (2) removing the logical error requires defining       independence on counterfactual causal events. the logically coherent causal       definition is the one intuitively adopted by humans. our findings have direct       implications for more consistent and generalizable causal discoveries in medicine       and other sciences.
prosociality emerges early in ontogeny, but the mechanisms driving       its early-emergence are not well understood. we propose that the experience of       choice is tied to the expression of children’s prosocial behavior. in       experiment 1, preschoolers shared with a puppet by either making a costly choice       (giving a resource they could have kept for themselves), non-costly choice       (giving a resource that would otherwise be thrown away), or no choice. subsequent       prosociality was measured by allowing children to share with a new puppet. while       most children shared initially, children who were given costly choices shared       more with the new puppet. experiment 2 replicated this result using a different       manipulation for costly vs. non-costly choices. experiment 3 found that       preschoolers were more likely to infer that actions are intentional when they are       costly. results suggest a prosocial construal hypothesis: that children       rationally infer their prosociality through making difficult, autonomous       choices.
video-sharing websites have begun to provide easy access to       user-generated video content. how do we find what we want to view among the huge       video database? when people search for a video, they may want to know whether the       video evokes a certain emotional sensation. the evoked emotion is one of the       important factors we consider when we select a video. one of the key concepts of       evoked emotions from videos: the evoked emotions are different for each scene and       for each viewer. considering these differences, we obtained human- evoked       emotions from 33 videos. we used these emotions to estimate the multiple emotions       evoked by each scene of the videos. using a computational model of emotion       estimation based on mid-level visual features, we found that, in individual       videos, the same scene evoked multiple emotions. our results show that a video       evoked different emotions from different people. a computational model might       deliver probabilistic multiple-evoked emotions from video analyses. 
we investigated the way in which working memory (wm) constrains       the learning of relational concepts – categories defined by the way objects       are assigned to roles in the structure of an underlying relation, and not by       objects’ intrinsic features. by applying to a large sample a novel test of       concept learning as well as the battery of wm tasks, we found that wm is a strong       predictor of the scores on the test, but the wm-learning correlation decreases as       the relational complexity of the to-be-learned concepts increases. such results       support those theoretical models of relational learning, which assume that       learning of relational concepts (and relations, in general) consumes more wm       resources than just the processing of relations which have already been       learned.
the aim of the present study was to investigate whether face age       and social status information associated with faces have different effects on       gaze following behaviour as an index of joint attention. participants were       instructed to perform goal-directed saccades towards a peripheral stationary       target, while a task-irrelevant face with averted gaze was presented. faces of       three different age groups (younger adults; middle-aged adults; and older adults)       were associated with fictional résumés which could describe distracters       as high or low social status people. results showed that face age affected both       saccade accuracy and latencies. social status did not have an effect on accuracy       and only affected correct saccades with higher latencies by modulating the face       age effect. it is argued that the overt orienting of joint attention could be       affected both by perceptual and higher order socio-cognitive factors, but at       different stages of processing.
the question of whether it is possible to characterise grammatical       knowledge in probabilistic terms is central to determining       the relationship of linguistic representation to other cognitive       domains. we present a statistical model of grammaticality       which maps the probabilities of a statistical model for       sentences in parts of the british national corpus (bnc) into       grammaticality scores, using various functions of the parameters       of the model. we test this approach with a classifier on test       sets containing different levels of syntactic infelicity. with        appropriate tuning, the classifiers achieve encouraging levels of       accuracy. these experiments suggest that it may be possible to       characterise grammaticality judgements in probabilistic terms       using an enriched language model.
a clear, growing consensus indicates an urgent need for humans to       reduce the burgeoning effects of global climate change (“global       warming” or gw). apt public instruction seems central to achieving critical       behavioral changes, but some researchers suggest that u.s. climate attitudes are       doomed to cognitive stasis (i.e., that little will be gained by educating the       public). herein are four studies that counter the stasis view. our laboratory has       previously reported findings that (1) virtually no americans know the basic       climate change mechanism, yet it (2) is quickly learned (in a few minutes, e.g.,       with a 400-word text), which (3) increases climate change acceptance. below,       studies 1 and 4 replicate and extend these results to demonstrate (a) efficacy       with an online presentation and broader populations and (b) retention up to a       month after learning the mechanism. studies 2-4 explore roles for germane       numerical information using estimation with feedback. study 2 shows that (d)       misleading, cherry-picked, statistics can decrease climate change acceptance (and       shake metacognition), while studies 3 and 4 show that (e) surprising scientific       information must be presented with care for it to foster beliefs in line with       climate science’s consensus. in sum, contrary to unnecessarily pessimistic       (and correlational) "stasis" arguments, highly germane science information can       clearly change the public’s understandings and opinions.
the current experiments investigated the fractal structure in the       nested actions of tapping behavior. the results revealed that task constraints       (e.g., tapping to a metronome) alter the fractal structure of a given aspect of       the behavior (e.g., inter-tap interval) and decouple its long-term interactions       with other aspects of the behavior (e.g., key-press duration). these results       support the idea that fractal structure reflects the dynamical organization of       complex systems.
recent theory suggests that action prediction relies of a motor       emulation mechanism that works by mapping observed actions onto the observer       action system so that predictions can be generated using that same predictive       mechanisms that underlie action control. this suggests that action prediction may       be more accurate when there is a more direct mapping between the stimulus and the       observer. we tested this hypothesis by comparing prediction accuracy for two       stimulus types. a mannequin stimulus which contained information about the       effectors used to produce the action and a point stimulus, which contained       identical dynamic information but no effector information. prediction was more       accurate for the mannequin stimulus. however, this effect was dependent on the       observer having previous experience performing the observed action. this suggests       that experienced and naive observers might generate predictions in qualitatively       difference ways, which may relate to the presence of an internal representation       of the action laid down through action performance.
generalization to new examples is an essential aspect of       categorization. however, recent category learning research has not focused on how       people generalize their category knowledge. taking generalization to be a       critical basis for evaluating formal models of category learning, we employed a       ‘minimal case’ approach to begin a systematic investigation of       generalization. human participants received supervised training on a two-way       artificial classification task based on two dimensions that were each perfect       predictors. learners were then asked to classify new examples sampled from the       stimulus space. most participants based their judgments on one or the other       dimension. varying the relative levels of dimension salience influenced       generalization outcomes, but varying category size (2, 4, or 8 items) did not. we       fit two theoretically distinct similarity-based models (alcove and diva) to       aggregate learning data and tested on the generalization set. both models could       explain important aspects of human performance, but diva produced a superior       overall account. 
in this paper, we examine the impact of three learning activities       designed to foster more robust learning in a genetics cognitive tutor module on       pedigree analysis problem solving, in an experimental study. the three activities       are (1) interleaved worked examples with student explanations; (2) enhanced       feedback with tutor-provided explanations of problem solving steps; and (3)       explicit scaffolding of the reasoning steps in this abductive       process-of-elimination reasoning task. the study included four between-subject       conditions, a baseline condition in which students exclusively solved standard       problems, and three conditions in which students engaged in one of the new       learning activities along with standard problem solving. the scaffolded-reasoning       condition was most successful in fostering robust learning, as measured by       transfer, retention, and preparation for future learning tests. the enhanced       feedback condition, in contrast, yielded the poorest performance on the robust       learning measures.
we introduce a class of artificial stimuli that lack       preexperimental associations or encoding strategies.  in a set of recognition       memory experiments using these stimuli, we manipulate the similarity between       studied items and between targets and foils, thus investigating the effects of       pure perceptual similarity.  we also assign values to studied items in order to       induce encoding strategies that might emphasize encoding distinctive or       overlapping features.  applying a stochastic signal detection model to these       data, we find that blocked presentation and increased category size lead to       poorer encoding of individual items, indicating that participants fail to encode       distinctive features when list homogeneity is increased.  further, items assigned       a negative value are encoded more poorly, a sign that participants may attempt to       find overlapping features among negative items.
how is musical memory organized? while classic studies of music       perception appealed to schematic or symbolic knowledge structures, recent work       suggests that listeners form highly-detailed auditory representations of music.       studies of metrical restoration—memory fill-in of the “beat” of       a metrically-ambiguous melody—suggest some organizing dimensions in musical       memory. however, many potential dimensions remain unexplored. the current study       looked for effects of mode (major vs. minor)—a substantial organizing force       in western music—and timbre (what instrument is playing) on metrical       restoration. both mode and timbre can signify particular musical styles. in       experiment 1, listeners showed timbre specificity in metrical restoration, but       not mode specificity. however, in experiment 2, when timbres were extremely       unique (one per melody), restoration effects were not observed, suggesting that       too much variability leads to diffuse representations which are too weak to       support metrical restoration. implications for the nature of musical memory are       discussed.
this study investigated the role probabilistic and deductive       relations play in the reasoning process. it was predicted that when taking an       analytic stance to a problem, it would take longer to evaluate inferences when       asked how probable it is that the conclusion is true, than when asked whether the       conclusion follows or not from the premises. contrary to this prediction, people       responded faster when the response format was continuous. however, there was no       effect of argument type with continuous response format, suggesting people did       not assess entailment relations in this condition. options to address the issue       further are discussed.       keywords: deductive/inductive reasoning; dual process theories; task effects;       response times.
systems of noun classification serve to categorize entities based       on a set of semantic and/or phonological features. previous work, for the most       part focused on gender-based classes, has suggested that learners acquiring such       systems rely primarily on phonological cues, while semantic cues are used only       weakly. we show, using an artificial language learning task with adults, that       semantic information alone is sufficient to learn a realistic shape-based       classification system, challenging the view of phonology bias. further, our       results show that compared to learners exposed to semantically cohesive       categories, learners trained on randomly assigned classes are less successful at       recalling the category of exposure items. this finding suggests that, contrary to       memory-based theories of learning, categories are not necessarily formed by       abstraction from memorized exemplars, but can instead be constructed from       lower-level properties that category members share.       
arguments, claims, and discussions about the “level of       description” of a theory are ubiquitous in cognitive science. such talk is       typically expressed more precisely in terms of the granularity of the theory, or       in terms of marr’s (1982) three levels (computational, algorithmic, and       implementation). i argue that these ways of understanding levels of description       are insufficient to capture the range of different types of theoretical       commitments that one can have in cognitive science. when we understand these       commitments as points in a multi-dimensional space, we find that we must also       reconsider our understanding of intertheoretic relations. in particular, we       should understand cognitive theories as constraining one another, rather than       reducing to one another.
infants and children are avid learners. this constant aggregation       of new knowledge, however, can interfere with past and future learning. proactive       interference (pi) occurs when past learning interferes with new learning, while       retroactive interference (ri) is the attenuation of memory for previous learning       as a result of new knowledge. previous work has demonstrated that adults and       children display pi and ri effects, but the developmental trajectories of these       effects are less clear. the current study developed a new associative learning       paradigm to concurrently test pi and ri in preschoolers and adults. results       demonstrated the presence of ri, and these effects were stable across age groups,       suggesting that the mechanisms that modulate ri effects may already be mature in       these age groups. no pi effects were found in either group, however. this       surprising result suggests the role of associative complexity as a possible       modulator of pi in these age groups. 
graphical overviews have been studied as a method to improve       hypertext learning and digital search. although previous studies have found       learning benefits to graphical overviews of single hypertext, it is unclear if       these benefits extend to online learning across multiple (independent) documents.       previous research also has found that graphical overviews facilitate domain focus       during online search, but it has not been established whether these benefits are       derived from the spatial organization of the graphic or its textual content. this       research examined the impact of using graphical overviews organized either       spatially (i.e., network view) or textually (i.e., outline view) during       self-regulated online learning. assessments focused on deep understanding of       science concepts and the relationships between them. results indicated that the       outline view promoted deeper understanding of science concepts and fewer errors       about the relationships between them. implications are discussed for the design       and implementation of instructional materials to support self-regulated       learning.
in a word association task, the probability of producing a certain       response to a cue is considered to be a direct measure of associative strength       between words in the mental lexicon. the common single word association procedure       is limited, since the number of words connected to a cue might be underestimated       when a single response is asked. the continued association task overcomes this       limitation by asking a person to generate multiple associative responses. to test       whether continued strengths allow a better approximation of our lexicon, an       experiment was conducted in which participants judged the associative strength       between words.         our results show that in contrast to other semantic tasks, continued strength       predicts weak to moderate judgments only. two explanations based on the sampling       of information and differential semantic activation of later responses in       continued association are proposed. theoretical implications for semantic       activation and methodological implications for derivation of strength are       discussed.
this paper reports experimental results on the index of cognitive       activity (ica), a recent micro-level measure in pupillometry which relates       processing load to the frequency of rapid small variations in pupil diameter. we       collected pupil size data during three language processing tasks (german subject       vs. object relative clauses, a grammatical gender violation, and semantic       anomalies). we report the first results on the index of cognitive activity for       language processing and show that the ica is responsive to all of our       manipulations. we also compare the ica results to overall pupil dilations and       self-paced reading as a measure of processing difficulty. overall, the use of the       ica as opposed to traditional pupillometry seems promising, as our data provide       initial evidence that the ica may be a faster and more fine-grained measure of       cognitive load than overall pupil dilation.       
this paper reports experimental results on the index of cognitive       activity (ica), a recent micro-level measure in pupillometry, which relates       processing load to the frequency of rapid small dilations of the pupil. we       collected pupil size during a tracking task which was cast in a simulated driving       context, as       well as for a dual task of simultaneous tracking and language processing. the       present results are the first to evaluate the ica measure on these tasks. we find       that the ica is sensitive both to the simulated driving and the language task,       and that it is more responsive to our driving task than overall pupil dilation.        overall, the use of the ica as opposed to traditional pupillometry seems       promising, as our data provide initial evidence that the ica may be more       responsive, and a more fine-grained measure of cognitive load than traditional       macro-scale pupil dilation measures.       
 in their evaluation of the integration cost component of       dependency         locality theory on the dundee corpus, demberg and keller (2008)         found no significant main effect of dlt integration cost on reading         times, but suggested that this might be due to auxiliaries incurring         some of the full verb's integration cost and thus facilitating         processing of the verb. this hypothesis however, has to date not         been tested. the present paper fills this gap by reporting an         experiment on subject vs.~object relative clauses including         auxiliaries, as well as by testing demberg and keller's hypothesis         directly on the dundee corpus.          a further contribution of this paper is methodological: we replicate         experimental results on the subject vs.~object relative clause         assymmetry in a self-paced-reading experiment run remotely on the         web using webexp.       
what information do people extract in the course of category       learning? and how does training affect this process? the current study addressed       these questions by examining the effects of training on the outcome of category       learning in 4- to 5-year-olds and adults. in two experiments, participants were       trained on either a classification task or an inference task and then tested with       categorization and recognition tasks. the categorical information (i.e.,       deterministic and probabilistic features) was explicitly given to participants in       experiment 1 but not in experiment 2. results with adults replicate previous       findings indicating that participants form different representations in the       course of classification and inference training (rule-based representation in the       former case and similarity-based representations in the latter case).  in       contrast, regardless of the type of training, young children form       similarity-based representations. 
we study three-person groups solving a simple, two alternative       forced choice task of perceptual nature. the group members provide individual       answers and afterwards discuss and reach a joint decision. different models of       information sharing describe the theoretical relationship between group and       individual performance. experimental data shows that average-performing members       can benefit from cooperation, but the groups do not outperform their best       members. results point to voting as the best explanation of the behavior of the       groups.
societies sometimes stick to the status quo instead of switching       to superior technologies and institutions. existing explanations often attribute       this to a coordination failure due to payoff externalities: people may know that       another alternative is superior but nobody has an incentive to switch unless many       others do so. we show that a simple learning argument can provide an alternative       explanation. when people learn about the alternatives from their own experiences       but tend to adopt the behaviors of others, they will mistakenly learn to believe       that a popular alternative is superior to a better, but unpopular alternative.       our model neither assumes that agents engage in motivated cognition nor that they       transmit mistaken information to others. rather, it emphasizes the role of a       fundamental asymmetry in access to information about popular versus unpopular       alternatives. our model thus provides a novel, sampling-based, explanation of how       conformity in behavior can lead to private acceptance.
an ignored stimulus is later recognized at enhanced levels if it       had previously been aligned with a target from a separate task. this has been       demonstrated using both visual and auditory presentations. here we extend these       findings to multisensory conditions. participants were required to detect       immediate repetitions in a sound or picture stream while ignoring superimposed       words presented in the opposite modality (either written or spoken,       respectively), and then underwent a surprise recognition test for these words.       contrary to the previous unisensory examples (dewald, sinnett, & doumas, in       press; dewald & sinnett, 2012), a significant difference between recognition       rates for target-aligned and non-aligned words was not observed. however, a       highly significant difference in response latency was observed, with       target-aligned words being responded to much more quickly. this finding was       robust and observed when the surprise test was presented in either the visual or       auditory modalities, as well as across modalities.   
this paper proposes a model giving theory of mind (tom)       capabilities to artificial agents to allow them to carry out deceptive       behaviours. it describes a model supporting an n-level theory of mind and reports       a study to assess whether equip- ping agents with a two-level tom results in them       being perceived as more socially intelligent than agents with a single-level tom.       a deception game being developed for intercultural training of children, used for       this study, is described. finally, we report results from this study consistent       with the hypothesis that a two-level theory of mind better supports agents in       deceptive behaviour.
one of the challenges in developing multi-agent systems is the       creation of agents able to exhibit human-like behaviours in complex social       situations. in order to do so, agents need to be socially aware of their       environment and perceive other agents not only as individuals but also as social       group members. following social identity and self-categorization theories, we       developed the dynamic identity model for agents that provides agents with the       ability to adapt their identity and behaviour to the social context. we then       implemented it in a social dilemma scenario where different situations were       explored.
it has been repeatedly debated which strategies people rely on in       inference. these debates have been difficult to resolve, partially because       hypotheses about the decision processes assumed by these strategies have       typically been formulated qualitatively, making it hard to test precise       quantitative predictions about response times and other behavioral data. one way       to increase the precision of strategies is to implement them in cognitive       architectures such as act-r. often, however, a given strategy can be implemented       in several ways, with each implementation yielding different behavioral       predictions. we present and report a study with an experimental paradigm that can       help to identify the correct implementations of classic compensatory and       non-compensatory strategies such as the take-the-best and tallying heuristics,       and the weighted-linear model.  
the executive functions have been studied separately in the fields       of neuropsychology and of motor control. however, it is not clear whether across       fields one is referring to similar cognitive functions. in the present study, we       compared the performance scores obtained in a motor spatial-tapping task with       those scores obtained in a battery of three neuropsychological tasks which assess       respectively the executive functions of updating (n-back task), inhibiting       (go-nogo task) and switching (letter-number task). multiple regression analyses       revealed significant and specific effects between the motor task and the       classical neuropsychological tasks: the timing error measured at slow tempi in       the tapping task predicted the scores observed in the updating task only; the       spatial error at faster tempi predicted the scores obtained in the switching task       only; the contact times at intermediate tempi predicted the scores obtained in       the inhibiting task only. hence, we introduce this easy-to-use non-verbal task as       a novel paradigm to assess executive functioning.
spatial congruity effects are often interpreted as evidence for       metaphorical thinking, but an alternative markedness-based account challenges       this view. here, we compared metaphor and markedness explanations for spatial       congruity effects, using musical pitch as a testbed. english speakers who talk       about pitch in terms of spatial height were tested in space-pitch compatibility       tasks. to determine whether congruency effects could be elicited by any marked       spatial continuum, participants classified pitches as 'high' and 'low' or as       'front' and 'back' (both pairs of terms represent marked continuums). we found       congruency effects in high/low conditions but not in front/back conditions,       indicating that markedness cannot explain congruity effects. a second experiment       showed that congruency effects were specific to spatial words that cued a       vertical schema (tall/short), and that congruity effects were not based on       polysemy (e.g., 'high' referring both to space and pitch). together, these       results suggest that congruency effects reveal metaphors, not markedness.
previous accounts of the mechanism which generates improvement in       memory when people freely choose items, compared to other methods of item       assignment, conflict and lack integration.  i examine facial recognition       performance of 40 participants asked to choose either the most or least       attractive face from a series of pairs, and find that recognition of chosen faces       is greater than recognition of unchosen, while no effect is found for the valence       of faces.  considering these results in tandem with prior results and theories, i       argue that a two process account of memory improvements due to choice is       necessary, with one deliberative process occurring across all options available       to choose from, and the other selective process focused on the actual chosen       item.  i detail the delineation of these processes, and describe and test the       current best accounts of each — the multiple-cue hypothesis, and the       self-reference effect for memory.
in contrast to symbolic models of language understanding, embodied       models of language comprehension suggest that language is closely connected with       visual and motor processing. in the current study we show that motion words, such       as rise or fall, are processed faster if displayed against a background of       compatible motion (e.g., upward vs. downward random dot motion with 60% motion       coherence). however,       this interaction between semantic processing and visual processing only occurred       if the word and the motion display were presented simultaneously. if the visual       motion display was short-lived and occurred 100 or 200 ms after word-onset, no       interactions between language and visual motion were       found. we suggest that only in situations that do not allow ignoring or       strategically suppressing the visual motion display, supra-threshold visual       motion can affect language       comprehension.
music is sometimes compared to language as a system of       communication, however this comparison is usually at a generic formal, cultural       or social level. this paper explores this analogy at the detailed level of       interaction: to what extent can musical contributions act as conversational       turns? we explore this question through an ethnographic study of music lessons.       we describe a new transcription notation designed to capture the interactional       details of musical contributions. using this notation we show that although the       ultimate objective of a lesson is development of musical performance, the       detailed structure of the musical contributions depends on their interactional       organisation. we show that musical contributions display interactional structure       at the turn and sub-turn level and are closely integrated with other verbal and       non-verbal cues as part of the unfolding conversation.
the top-down guidance of visual attention is an important fac- tor       allowing humans to effectively process incoming visual information. our       understanding of the processes governing attention is not complete, with growing       evidence for attention selection based on cognitive relevance. in this paper, we       investigate whether models for salient object detection from computer vision can       be used to predict attentional shifts in visual tasks. our results show that the       object-based interpretation of saliency provided by these models is a       substantially bet- ter predictor of fixation locations than traditional       pixel-based saliency.
although the word “dog” and an unambiguous barking       sound may point to the same concept dog, verbal labels and nonverbal cues appear       to activate conceptual information in systematically different ways (lupyan &       thompson-schill, 2012). here we investigate these differences in more detail. we       replicate the finding that labels activate a more prototypical representation       than do sounds, and find that sounds activate exemplars consistent with the       source of the sound, such that after hearing a barking sound, people are faster       to recognize a dog with an open-mouth than a closed mouth, but critically, only       when the sound and picture are presented simultaneously. the results are       consistent with perceptual cues indexing their source while labels activating a       more decontextualized representation of the target category.
we investigate the effect of linguistic complexity on cognitive       load in a dual-task scenario, namely simultaneous driving and language use. to       this end, we designed an experiment where participants use a driving simulator       while listening to spoken stimuli and answering comprehension questions. online       physiological measures of cognitive load, including the recently established       index of cognitive activity, as well as measures of performance in both tasks       have been collected with high temporal resolution. the resulting aligned data       streams can be used to test a vast array of different hypotheses about the       relationship between performance, difficulty, and cognitive load in dual tasks at       various levels of temporal resolution and linguistic structure. we present       results of the data analysis, including evidence that different linguistic       structures may cause measurable changes in cognitive workload on a very fine       temporal scale in cases of increased primary task difficulty.       
metacognition plays a fundamental role in forming self-judgments       of ability and knowledge.  is metacognition domain and gender specific?        metacognitive judgments and performance were measured across biology, literature,       and math content.  undergraduates took three shortened sat ii subject tests, and       provided estimates of their performance both before and after taking each test.        the results were that judgments differed across domain and gender.        overconfidence was evident in all domains, although estimates of ability were       more accurate after taking a test.  males tended to be more overconfident, while       females were less confident yet more accurately calibrated when estimating       ability.  students were over-confident in math, bringing into question the       existence of math phobia.  improvement in calibration and gender difference in       calibration were most noticeable in math.
we applied the mouse-tracking methodology to a phonological cohort       task interpretable as a version of the a-not-b task. in the first experiment,       participants had to click a word like “candle” repeatedly on the same       side of the computer screen. they then had to click a phonological competitor       (“candy”) on the other side. this was contrasted with a condition in       which the word to be clicked repeatedly on the same side was phonologically       unrelated to the word at the critical trial. we found that the phonological       priming increased attraction toward the competitor. in the second experiment,       mouse movements revealed attraction towards the competitor as a function of the       number of previous presentations. the results demonstrate that phonological       competitors can exert influence on responses even if the competitors are not       simultaneously presented. these results are predicted by and provide evidence for       the dynamic field theory of movement preparation and execution. 
almost two decades of research has demonstrated that labels       facilitate infants’ categorization of novel objects. some interpret this as       evidence of an early link between infants’ linguistic and conceptual       systems. others suggest that these effects stem exclusively from lower-level       processing mechanisms in cross-modal perception, and that words promote       categorization only because they are more familiar to infants than non-linguistic       acoustic stimuli and therefore easier to process. here we address these       discrepant interpretations using a novel approach. we expose infants to       unfamiliar non-linguistic stimuli (sine-wave tone sequences), manipulating the       exposure conditions. for 6-month-olds, if the novel acoustic stimuli were       embedded within a communicative episode, they subsequently facilitated       categorization (experiment 1), but if they were presented in a non-communicative       episode, they had no such effect (experiment 2). we propose a developmental model       that takes infants’ burgeoning perceptual and conceptual capacities into       account in identifying how communication and words are linked to concepts.
the critical step facing every decision maker is when to stop       collecting evidence and proceed with the decision act. this is known as the       stopping rule. over the years, several unconnected explanations have been       proposed that suggest nonoptimal approaches can account for some of the       observable violations of the optimal stopping rule. the current research proposes       a unifying explanation for these violations based on a new stopping rule       selection (srs) theory. the main innovation here is the assumption that a       decision maker draws from a large set of different kinds of stopping rules and is       not limited to using a single one. the srs theory hypothesizes that there is a       storage area for stopping rules—the so-called decision operative space       (dos)—and a retrieval mechanism that is used to select stopping rules from       the dos. the srs theory has shown good fit to challenging data published in the       relevant literature.
human language is characterized by variability in that the way in       which language is used varies depending, for example, on facts about the identity       of the speaker or author, the social context, and surrounding linguistic       material. variability poses formidable challenges to the systems underlying       language comprehension, which are known to exploit statistical contingencies in       the input to overcome the inherent noisiness of perception; nevertheless, we seem       to comprehend language with apparent ease.  how is this possible?  here we argue       that we are able to comprehend language efficiently in part by continuously       adapting to the statistics of novel linguistic situations.  we argue further that       adaptation specifically allows comprehenders’ expectations to converge       towards the actual statistics of the linguistic input.  concretely, we show that       readers can adjust their linguistic expectations in light of recent experience       such that (a) previously difficult structures become easier to process, and, even       more strikingly, (b) previously easy to process structures come to incur a       processing cost.  
the current study investigated whether children and adults can       distinguish between actions they are afforded and those afforded to an actor.       participants judged the maximum height they could reach while jumping and they       judged the maximum height that the actor could reach while jumping. they did so       with and without a weighted backpack, and they did so with and without walking       several laps. results show that before the addition of the weighted backpack,       participants rated the actor’s abilities as much closer to their own. while       wearing the weighted backpack and then walking with it, participants’       estimates decreased for themselves, but remained mostly unchanged for the       adult.
the present study explores the effects of non-linguistic       experiences on biases for linguistic judgments, specifically consonant deletion       patterns. when two adjacent consonants come into contact as a result of       morphological concatenation, many languages will delete the first consonant       (e.g., /bepdok/ becomes /bedok/). speakers of these languages (as well as english       speakers) prefer deletion of the first consonant to the second consonant because       the first consonant is perceptually weaker, making it more prone to       misrepresentations and modifications. following exposure to a non-linguistic       analogue of consonant deletion in which the second consonant was deleted instead       of the first, participants no longer preferred deletion of the first consonant in       the metalinguistic judgment task. these results suggest that exposure to       non-linguistic materials can interact with linguistic judgments. 
for both human and machine learners, it is a challenge to make       high-level sense of observations by identifying causes, effects, and their       connections.  once these connections are learned, the knowledge can be used to       infer causes and effects where visual data might be partially hidden or       ambiguous.  in this paper, we present a bayesian grammar model for       human-perceived causal relationships that is learnable from video.  two       experiments investigate high-level causal induction from low-level visual cues.        in the first experiment, we show that a computer can apply known heuristics used       for causal induction by humans to learn perceptual causal relationships.  in the       second experiment, we show that our learned model can represent humans'       performance in reasoning about hidden effects in video, even when the computer       initially misdetects those effects.
stock-flow (sf) systems involving the accumulation of a stock over       time are pervasive in many areas of human life. however, people make consistent       mistakes when regulating such systems, a phenomenon termed sf failure. we       introduce holistic (global) versus analytic (local) processing as a cognitive       mechanism underlying the hardly understood sf failure. using a classic sf problem       (department store task), we found that (a) solutions to sf problems were up to       four times higher when a global task format highlighting global structure       compared to a local task format highlighting local elements was used; (b) a more       global processing style is connected to higher solution rates to the sf problem;       and (c) procedurally priming participants with more global processing results in       higher solution rates to the sf problem. in sum, our results point towards       global-local processing as a basic explanation for sf failure.
this study investigates the effect of grammatical aspect marking       in dutch sentences, on speakers’ estimations of the duration of highly       familiar, everyday events. we first established the ‘inherent’ or       natural duration of different events (exp. 1). this was then used for the       manipulation of aspect (exp. 2). participants dragged a slider across the       computer screen to estimate the duration of progressive and non-progressive event       descriptions. findings show how the progressive form extends duration estimations       for short events, whereas it shortens the perceived duration of inherently medium       and long events. we interpret this as psycholinguistic evidence for the function       of aspect in dutch, i.e., giving an ‘inside’ view of the event and       focusing a specific internal time span of the event.
the time is space metaphor consists in the use of a spatial mental       time line (either left-right or front-back) to represent time. one of the issues       still to be resolved is whether these space-time mappings can be automatically       activated independently from the goals of the task. prior attempts to settle this       issue have failed to match adequately the temporally relevant and irrelevant       tasks. in the present study we presented spanish verbs and nonverbs conjugated in       past and future forms in both a time judgment and a lexical decision task.       results showed that the left-right space-time mapping is only active when the       task requires temporal discrimination, speaking against an automatic activation       of the mental time line.
why are some events more surprising than others? we propose that       events that are more difficult to explain are those that are more surprising. the       two experiments reported here test the impact of different event outcomes       (outcome-type) and task demands (task) on ratings of surprise for simple story       scenarios. for the outcome-type variable, participants saw outcomes that were       either known or less-known surprising outcomes for each scenario. for the task       variable, participants either answered comprehension questions or provided an       explanation of the outcome. outcome-type reliably affected surprise judgments;       known outcomes were rated as less surprising than less-known outcomes. task also       reliably affected surprise judgments; when people provided an explanation it       lowered surprise judgments relative to simply answering comprehension questions.       both experiments thus provide evidence on this less-explored explanation aspect       of surprise, specifically showing that ease of explanation is a key factor in       determining the level of surprise experienced.
in this paper we compare several mechanisms for using       distributional statistics to derive word class information. we contrast three       different ways of computing statistics for independent left and right neighbours       with the notion of a frequent frame. we also investigate the role of utterance       boundaries as context items and weighting of frequency information in terms of       the successful simulation of the noun-verb asymmetry. it is argued that       independent contexts can classify items with a higher degree of accuracy than       frequent frames, a finding that is more pronounced for larger input sets.       frequent frames classify a larger number of items, but do so with lower accuracy.       utterance boundaries are useful for the development of a noun category,       particularly at intermediate levels of frequency sensitivity.
how does language knowledge affect processing of paralinguistic       information—vocal properties that are not directly related to understanding       words? this study investigates links between a listener’s native language,       any other languages they may have experience in, and the ability to identify       vocal emotional information in those languages. the study focuses on two       particular classes of languages: those with lexical tone, such as mandarin       chinese, which use pitch properties to distinguish otherwise-identical words; and       those without lexical tone, such as english. english listeners and bilingual       mandarin-english listeners listened to sentences and categorized the emotional       content of english and mandarin sentences. half of the sentences were presented       normally; the other half were low-pass filtered to remove all but prosodic cues       (pitch and timing). english listeners were better at identifying emotions in       english sentences, while bilinguals were equally good at identifying emotions in       both languages. this indicates better overall emotion recognition from prosody       alone for listeners more familiar with a language. it may point to a connection       between tone language experience and augmented paralinguistic processing       capabilities. 
cooperation among children can appear haphazard, a finding often       attributed to deficient social skills and moral reasoning. here we took a game       theoretical approach to understand development of cooperation, using the       prisoner’s dilemma to test an alternative source of age-differences in       cooperative behavior—how children and adults represent the numerical       magnitudes of payoffs for cooperating versus not. we found that as incentives       increased solely in numerical magnitude, speed of incentive comparisons decreased       and cooperation increased. further, though children tended to be more cooperative       than adults, effect of age on cooperation was moderated by speed of incentive       comparison. we conclude that representations of numeric value constrain how       economic rewards affect cooperation and that children’s greater       cooperativeness may be attributed to a poor sense of numerical value.
we tested the computational feasibility of the proposal that       open-ended cultural evolution was made possible by two cognitive transitions: (1)       onset of the capacity to chain thoughts together, followed by (2) onset of       contextual focus (cf): the capacity to shift between a divergent mode of thought       conducive to `breaking out of a rut' and a convergent mode of thought conducive       to minor modifications. these transitions were simulated in evoc, an agent-based       model of cultural evolution, in which the fitness of agents' actions increases as       agents invent ideas for new actions, and imitate the fittest of their neighbors'       actions. both mean fitness and diversity of actions across the society increased       with chaining, and even more so with cf, as hypothesized. cf was only effective       when the fitness function changed, which supports its hypothesized role in       generating and refining ideas.
under conditions where an object is inside another object and only       a single face is visible, is there a bias to assume smooth continuation of the       surface straight back into the object?  to examine the ability to estimate how       features progress into a volume, participants viewed 16 pictures of everyday       objects (rocks, food, wood) presented with only a single face visible (see figure       1).  participants reported whether a highlighted region of a picture was present       on the surface or extended into the object.  if they perceived the region as       extending in, they positioned a rod to indicate the angle.  surface responses       were rare and instead participants’ readily perceived 3d forms from 2d       views.  inspection of frequency histograms revealed a systematic bias to estimate       the angle of extension in the 80-110° range. this type of completion process       suggests constraints on models of visual completion and has implications for stem       education, in particular, how students deal with ambiguity.
drawing artists and non-drawers are like any adult both experts at       face recognition. yet, artists have a richer learning experience with faces: they       were trained in rapid sketching of faces. zhou, cheng, zhang and wong (2011)       found that drawing experts showed less holistic processing (hp) for face       recognition than non-drawers. using a computational model of face recognition       that did not implement motor processing, we examined whether engagement of local       attention and nature of the learning task could account for the reduced hp in       drawers without the influence from motor experience. we showed that compared with       the non-drawer model that had a global face input (i.e., hsiao, shieh & cottrell,       2008), a drawer model that incorporated both global face and local facial parts       (eyes and mouth) in the input showed reduced hp, suggesting the modulation of       local attention engagement. in contrast, the other drawer model that used only       global face input but learned to perform an additional face part identification       task did not show the reduced hp effect. in addition, both drawer models       demonstrated stronger left side (right hemisphere) bias than the non-drawer       model. our data thus suggest that engagement of local attention is sufficient to       account for the reduced hp in drawers, and that hp and left side bias effects can       be differentially modulated by visual attention or task requirements.
in two experiments we provided evidence for a joint interference       effect in picture naming. participants took longer to name pictures when they       believed that their partner concurrently named pictures than when they believed       their partner was silent (experiment 1) or concurrently categorized the pictures       as being from the same or from different semantic categories (experiment 2).       however, picture naming latencies were not affected by beliefs about what       one’s partner said. these findings are consistent with the idea that       speakers represent whether another speaker is preparing to speak, but not what       they are preparing to say.
resolution of the meaning of a semantically ambiguous word       requires knowledge about the space of possible meanings of that word, and the       selection of a meaning in the light of available evidence and given situational       constraints. as such, ambiguity resolution bears many similarities to decision       making scenarios more generally. we report on an experiment exploring this       analogy by applying some standard manipulations from the decision making       literature to a semantic disambiguation task. we explore two particular       proposals: (1) that depth of semantic processing can be cast as strategy       selection reflecting a risk-sensitive effort-accuracy tradeoff, and (2) that       thresholds for inference about meaning in context are situationally flexible and       learnable via feedback. one robust property of decision making is people’s       ability to use feedback in order to adjust responses to maximize payoffs.       participants completed a semantic entailment judgment task in which they received       trial-by-trial feedback, and payoff matrices and decision thresholds were       manipulated across conditions. we find an effect of risk, with participants       employing different comprehension strategies depending on relative gains and       losses. we also find that participants were in fact sensitive to varying decision       thresholds and accurately adjusted their behavior to match the constraints on       what qualified as a true conclusion in different conditions. we take these       findings as preliminary evidence that ambiguity resolution in language can be       modeled, at least in part, as involving more general decision processes.
the visual impedance effect describes the fact that unnecessary       visual information can impede reasoning (knauff & johnson-laird, 2002). we       explored how this effect is modulated by individual differences in reasoning       styles. the main hypothesis of the present work is that the magnitude of the       impedance effect depends on the degree to which people use visual mental images       during thinking. we conducted two experiments with participants with highly       imagistic and highly verbal reasoning strategies. the relational inferences       differed in how easily they could be visualized. our results indicate that (1)       verbalizers do not show the visual impedance effect, and (2) that people with a       high preference for mental imagery try to imagine even non-visual information       visually, always showing the strongest impedance by visualization.
learning to plan sequences of actions and appropriately adapt our       actions during interactions with others are both critical skills upon which much       of human society is built. we know that children’s joint action and       planning skills are both undergoing development during the preschool years, but       not much is known about how the joint action context influences young       children’s planning. in this study, we examined the effect of playing alone       or with a joint partner on sequence planning during a problem-solving game in       three-year-old children. we found that children were better at planning ahead in       the individual than the joint condition of the game despite the joint condition       requiring fewer actions on the part of the child. in contrast, children were       equally good at problem-solving (i.e., correcting an error) in both conditions.       the possible reasons for this difference and directions of future research are       discussed.
would dan have died if bob hadn’t shot? in this paper, we       show that people’s answer depends on whether or not they are asked about       what would have caused bob not to shoot. something needs to change in order to       turn an actual world into a counterfactual world. previous findings of how people       reason about counterfactuals have been mixed: sometimes people appear to       backtrack and reevaluate the causes of a counterfactual state (e.g. rips, 2010).       at other times, people appear to treat counterfactuals like interventions that       leave the past unchanged (sloman & lagnado, 2005). we experimentally manipulated       the order in which participants were asked to consider the consequences of a       counterfactual state. the results show that participants are more likely to       backtrack when explicitly asked to consider a counterfactual’s causes.       however, when directly asked about the effects of a counterfactual state, most       people don’t backtrack.
people demonstrate a consistent tendency to favor holistic or       global       processing over processing of local details in many perceptual       domains; this tendency is called global-local precedence.  formal       musical training is associated with qualitative changes in auditory       processing, but the number of years required remains unclear,       particularly for any perceptual differences between untrained and       minimally trained participants.  in this study, participants with zero       to over ten years' music training identified the direction of pitch changes        in three-sound sequences.  only participants with three or more years'       training demonstrated a significant global-local precedence.       individuals without musical training consistently identified the local       direction of pitch-change sequence elements better than global pitch       changes across each sequence.  although musical training was       associated both with greater task accuracy and with global-local       precedence, improved accuracy did not explain the musically trained       participants' preferential processing of global auditory       characteristics.
development of analogical reasoning is often explained by general       maturation of executive functions. a consequence of the involvement of executive       functions would be that children and adults differ in the visual strategies they       apply when solving analogical problems. since visual strategies can be studied by       means of eye-tracking, we compared the visual scanpaths of children and adults in       three different analogical reasoning tasks. this comparison was done by means of       a novel technique that combined a recently developed algorithm for computing  a       “distance” between any pair of scanpaths (jarodzka, holmqvist, &       nyström, 2010), multidimensional scaling (mds), and a neural network       classifier. this analysis clearly showed a difference between adults' and       children's visual strategies in solving analogy problems. we focus both on the       demonstration that adults and children employ different visual search strategies       to solve analogy problems and on the novel technique used to do this. this       general technique complements other approaches to eye-movement analysis that rely       on local properties of scanpaths, in particular, item-fixation times.
this study addresses conceptual blending theory, originated by j.       fauconnier and m. turner. the author raises some criticism of the theory’s       underpinnings and methodology.  particularly, he points at the lack of       cultural-historical analysis and the neglect of experimental data as the       shortcomings of the theory as stated. it is shown in the paper that the view on       blending as an important tool to adapt knowledge to the experience of average       people is more correct than its interpretation as a basic instrument for the       creation of new knowledge.
we provide evidence that primacy and / or recency effects play       a crucial role in infant visual categorization. first, we demon-       strate that a connectionist model of infant categorization based number and type       of categories formed is modulated by the on a self-organizing map (gliozzi,       mayor, hu, & plunkett,       2009) predicts an increased influence of the first and the last       stimuli during familiarization on the category boundaries. we       then present data from 10-month-old infants which confirm recency effects.       these effects. future research will allow to discriminate be-       tween a primacy or a recency effect.
solving an open problem as proposed by inventing and productive       failure approaches has been shown to prepare learners effectively for subsequent       direct instruction even though invented solutions are often suboptimal for the       given problems. inventing can make the learners aware of knowledge gaps       (cognitive) and more curious about and interested in the learning contents       (motivational effects). however, working on the same problem with a given       (optimal) solution helps avoid misconceptions and disorganized knowledge, while       providing useful basic knowledge. therefore, a given solution could be more       effective. in an experiment (n = 42), we tested to what extent working on an open       problem (inventing) versus a solution prepares student teachers for learning       strategy evaluation. the inventing group invented criteria to evaluate learning       strategies while the worked solution group studied the same problem in a solved,       worked-out version. we found differential effects: inventing enhanced       knowledge-gap experience, curiosity, and interest. however, studying the       worked-out solution enhanced learning outcomes.
prior research indicates a protracted developmental course in       category-based reasoning. one possible explanation for the development of this       ability is the gradual reorganization of semantic knowledge. to measure       development of semantic knowledge we developed a new paradigm, the semantic space       task, which uses distance in a two-dimensional space to infer semantic       similarities between two objects. using this paradigm we examined development of       semantic knowledge in young children (preschoolers, kindergarteners, and       first-grade children) and in adults. we also examined whether conceptual       organization as measured by the semantic space task is predictive of       children’s scores on a category-based reasoning task. the findings point to       the possibility that development of semantic knowledge plays an important role in       the development of category-based reasoning. 
maintaining focused attention in the classroom is considered an       important factor for successful learning. loss of instructional time due to       off-task behavior is recognized as a significant challenge by both researchers       and practitioners. however, there has been little research into the factors       contributing to off-task behavior. this paper reports results from the first       large-scale study investigating how elementary school children allocate their       attention in classroom environments and how patterns of attention allocation       change as a function of gender, grade level, and instructional format. the       findings indicate that instructional format is related to off-task behavior in       elementary school students. these findings can begin to form a foundation for       development of research-based guidelines for instructional design aimed to       optimize focused attention in classroom settings. 
listeners are sensitive to contrastive alternatives in online       language comprehension (e.g., braun & tagliapietra, 2010). such alternatives play       a crucial a role in the definition of particles like only which have been found       (i) to facilitate recall of contextual alternatives (spalek, et al., in revision)       and (ii) to hamper the rejection of unmentioned alternatives (gotzner et al., in       preparation). the present study investigated the impact of combining a       contrastive accent with a particle on memory for contextual alternatives. the       results revealed that l+h* accents (contrastive) facilitate recognition of a       contextual alternative to the accented item compared with h* accents       (non-contrastive). adding either the particle only or also to the l+h* accent       slows probe recognition relative to a condition with bare l+h* accent. hence,       while contrastive accenting directly increases the salience of alternatives in a       listener’s mental model, focus particles lead to an initial processing       cost. 
two experiments investigated the production and comprehension of       referring expressions that contain a negative property ("the marker without a       cap"). experiment 1 showed that participants do use negative properties in their       object descriptions, but that they were almost always accompanied by other       properties, leading to referential overspecification. in experiment 2,       participants identified objects based on descriptions that contained negative       properties. while participants were faster in identifying objects that were       described with preferred properties such as color, response times for objects       described with a negative property ("the marker without a cap") and a positive       property ("the marker with a cap") did not differ. the results provide behavioral       grounds for extending referring expression generation algorithms to include       negative properties.
we present an approach to health interventions based on the       insight that throughout life, individuals construct intuitive theories to       predict, explain, and determine how to act on the world. we propose that	 an       intuitive theory-based approach may be useful for teaching adults about the       body's biochemical response to exercise. the first step in using this approach is       to document the theories that a target population brings to bear on a health       domain. we therefore present what is to our knowledge the first investigation of       adults' reasoning about exercise. specifically, we explore how adults explain why       exercise confers various benefits, how plausible adults find the physical,       emotional, and cognitive benefits of exercise, and how contingent on weight loss       adults believe such benefits to be. these findings lay the groundwork for       constructing an intervention to motivate adults to exercise more.
the adaptive experimentation methodology has been adopted in       visual psychophysical modeling in the pursuit of efficiency in experimental time       and cost. the standard scheme only optimizes one design in each experimental       stage, although simultaneous optimization of multiple designs per stage can be       beneficial, but difficult to implement because of a surge in computation.  in       this study, we incorporated the adaptive experimentation methodology under a       bayesian framework with differential evolution (de), an algorithm specialized in       multi-dimensional optimization problems to explore the multiple-designs-per-stage       approach. by taking advantage of parallel computing, de is computationally fast.       the results showed that the multiple-designs-per-stage scheme resulted in a more       stable estimation in the early stages of the parameter estimation. 
while formal theories of language consider function words to have       little semantic content, more recent theoretical work has argued that even       function words have meaning. yet, there is little experimental work on the       representations underlying the meaning of function words such as conjunctions. in       two offline experiments, we examined whether conjunctions (and, or, but,       either…or) are associated in systematic but distinctive ways with spatial       information. in experiment 1, participants drew schematic representations to       depict how two abstract conjuncts might be connected by each of the four       conjunctions. these drawing were evaluated on three spatial dimensions (distance,       containment and size). in experiment 2, participants evaluated how well schematic       sketches (that differed in distance, containment, and size) represented different       conjunctions. in both experiments, spatial information was systematically and       distinctively associated with conjunctions. either… or and or conjunctions       were reliably associated with the use of large distance and separation via       containment of the conjuncts. and, by contrast, was associated with shorter       distance between, and no containment of, the conjuncts.  finally, but was       associated with differences in size. we discuss implications of these results for       the spatial foundation of linguistic meaning, and the link between lexical       semantics and logic.
apprehending the development of complex emotions is crucial to       understand the development of decision-making. regret and relief are complex       counterfactual emotions, which can arise in private or in social contexts. the       aims of the present study were (i) to uncover the development of regret and       relief and (ii) to explore the development of a social form of regret and relief       in a context of competition. the first experiment provides evidence that the       ability to experience regret and relief continues to develop until adolescence,       consistent with the implication of the orbitofrontal cortex in their experience.       in a context of competition, we observed that adolescents were less able to       experience social regret compared to children and adults, whereas their feeling       of social relief was reinforced. besides, adolescents failed to question the       appropriateness of their initial decision. this result could provide an       explanation for adolescents’ enhanced propensity to engage in risky       behaviours.
one of the more challenging research areas in cognitive science is       the attempt to understand how the brain supports consciousness. this historically       philosophical endeavor is now actively studied in the sciences, with research on       visual attention being an especially promising area that can further our       understanding of consciousness. a major problem with this cross-disciplinary       pursuit, however, is that for philosophers and scientists, the terms       consciousness, attention, and conscious attention are ambiguous and used       differently even by those within the same academic discipline. the goal of this       paper is to begin laying the groundwork for a unified study of consciousness by       delineating common terminology for attention and consciousness and by identifying       the relationship between the two within the study of conscious attention. this       includes categorizing current theories according to a spectrum of theoretical       complexity.
quantification plays a central role in human reasoning and models       thereof, but the discovery and development of quantification remains an open       question. we present a theory of how such concepts are learned from experience in       the dora model, a neurally-plausible computational model of relational learning       and reasoning (doumas et al., 2008). the same theory accounts for how concepts of       number are acquired in this class of model. we are unaware of any prior model       that accounts for the development of both quantification and number from       unstructured (e.g., perceptual) input.
an interesting subclass of noun-noun combinations in english can       take two meanings depending on whether the first or second word is stressed in       speech. a brick factory is one that makes bricks, whereas a brick factory is one       made of brick. an explanation is offered in terms of a bias for nouns from       particular ontological categories to trigger particular semantic interpretations       for a combination, together with the proposal that the unstressed noun provides       the relation to be used. the explanation is tested in three empirical studies.       
there is substantial evidence from many domains that visual       representations aid various forms of cognition. we aimed to determine whether       learning to construct visual representations of argument structure enhanced the       acquisition and development of argumentative writing skills within the context of       first-year college writing course. we found a significant effect of the use of       argument diagrams, and this effect was stable even when multiple plausible       correlates were controlled for. these results suggest that natural⎯and       relatively minor⎯modifications to standard first-year composition courses       could provide substantial increases in student writing ability.
verbal overshadowing refers to a phenomenon whereby verbalization       of a non-verbal stimulus (e.g., he had slant eyes) impairs subsequent non-verbal       recognition accuracy. in order to understand the mechanism by which this       phenomenon occurs, we constructed a computational model that was trained to       generate an individual-face-specific representation upon input of a       noise-filtered retinotopic face (i.e., face recognition). when the model       verbalized the facial features before receiving the retinotopic input, the model       incorrectly recognized a new face input as one of the different, yet       visually-similar, trained items (that is, a false-alarm occurred). in contrast,       this recognition error did not occur without prior verbalization. close       inspection of the model revealed that verbalization changed the internal       representation such that it lacked the fine-grained information necessary to       discriminate visually-similar faces. this supports the view that verbalization       causes unavailability/degradation of fine-grained non-verbal representations,       thus impairing recognition accuracy.
we investigated the influence of reflections on self/others’       trust within group-based problem solving. we assessed the role of trust dynamics       on perspective-taking activities within conflictive groups, extending the       experimental framework used by hayashi (2012) and including conversational agents       for controlling participants’ interactions related to trust dynamics and       perspective taking behavior. results showed that (1) reflections of self/other       trust in conflictive groups may influence trust towards other members, and (2)       reflections of trust by members with conflicting perspectives may facilitate       trust and perspective taking. this suggests that the level of trust dynamics       facilitates trust and can function to manifest perspective taking within       cooperative groups.
listeners normally provide speakers with simultaneous feedback       such as nods, "yeah"s and "mhm"s. these`backchannels' are important in helping       speakers to talk effectively. two factors are known to influence when a       backchannel is produced; if the speaker is looking at the listener or if the       speaker is presenting new information. we investigate a third factor: whether the       speaker is having trouble speaking i.e. self-repair. if dialogue is an active       collaborative process then listener's responses should be especially critical       when trouble is encountered. using data from a corpus of three person dialogues       we show that speaker's rate of self-repair is a better predictor of listener       responses than speech rate. we also show that listeners respond strongly to       speaker troubles independently of whether the speaker is looking at them.       we argue that it is the points at which conversation threatens to go off-course       that are most significant for coordination.
memory reconsolidation, the re-stabilization of consolidated       memories after reactivation-induced destabilization, has received considerable       attention in recent years. nevertheless, the neural processes underlying the       phenomenon remain elusive. with the aim of contributing to the development of a       theory in this area, we here present a computational model of reconsolidation at       the “systems” level. the model is an extension of tracelink, which       has previously been used to account for a range of memory phenomena related to       consolidation.
to act efficiently in the classroom, teachers need to be able to       judge the difficulty of problems from a novice’s perspective. however,       research suggests that experts use their own knowledge as an anchor, adjust       estimations for others to their own knowledge and thus underestimate the       difficulty that a problem may impose on novices. similarly, experts should       underestimate the benefit for novices of task designs derived from cognitive load       theory (clt), as – following the expertise reversal effect – these       should be rather disadvantageous for experts. we investigated pre-service and       in-service teachers’ competencies in estimating the difficulty of       mathematical tasks for novices. thirty-four pre-service teachers and thirteen       experienced teachers solved tasks that varied in instructional design (optimized       for novices following clt versus non-optimized). participants solved each task       and then estimated how many students of a fictional 9th grade class would be able       to solve that task. solution frequencies were collected from fifty-two 9th grade       students. in both expert groups, overestimation was clearly more pronounced for       non-optimized than optimized tasks, suggesting an expert blind spot that can be       explained in terms of an expertise-reversal effect. the experts failed to       adequately take into account the benefits of didactic task variation for novice       learners. however, whereas pre-service teachers’ overestimations of student       performance were large and significant both for non-optimized and optimized       tasks, in-service teachers’ overestimations were generally small and failed       to approach statistical significance. in contrast to pre-service teachers,       in-service teachers seem to have a better mental model of what a student is able       to achieve, thus making better judgments of student performance.
the goals of this research were to (1) determine if there is       agreement both amongst viewers, and between viewers and the performer, about the       extent to which performances are authentic, and (2) ascertain whether or not       performers and/or viewers can distinguish between authenticity and skill. an       authentic performance is one that is natural or genuine, while an inauthentic       performance feels faked, forced, or imitative. study participants were asked to       rate the authenticity and skill level of a series of videotaped performances by       dancers and stand-up comedians. performers also rated their own performances.       authenticity ratings amongst viewers were significantly positively correlated.       ratings between viewers and performers were not significant but all positive. a       higher correlation between ratings of both authenticity and skill of performances       for viewers than for performers suggests that viewers make less of a distinction       between authenticity and skill than performers. the relationship between       authenticity and creativity is discussed. 
tutoring gives tutors the opportunity to engage in interactive       strategies that help them to assess a tutee’s understanding. however,       tutors without teaching experience often do not engage in interactive strategies       and, thus, have difficulty with accurately assessing a tutee’s       understanding. we conducted an experiment with 39 tutor-tutee dyads to test       whether tutors who received training in interactive strategies would become more       interactive and more accurate in assessing a tutee’s understanding. results       showed that trained tutors provided a more interactive style of tutoring than       untrained tutors. however, due to being more interactive, trained tutors produced       less accurate assessments than untrained tutors. this suggests that changing the       style of tutoring to implement interactive strategies puts a high burden on a       tutor’s cognitive capacity. hence, there is obviously little cognitive       capacity left that could be used to assess a tutee’s understanding.       training methods that automate strategy use might enhance a tutor’s       assessment accuracy.
accurate judgments and decisions are crucial for success in many       areas of human life. the accuracy of a judgment or decision depends largely on       the cognitive process applied. in research on judgment, decision making, and       categorization, two kinds of cognitive processes have often been contrasted:       exemplar-based processes, which use similarity to previously encountered items to       make judgments, decisions, and categorizations, and rule-based processes, which       use abstracted cue knowledge. although most cognitive models of judgment and       decision processes assume that people rely on both processes, they differ in       whether they assume that one process is selected or that both processes are       blended into a single response. the present research takes a functional       perspective and investigates what kind of interaction between the two processes       leads to accurate responses. based on cross- validated simulations in real-world       domains, it shows that blending rule- and exemplar-based processes generally       leads to better judgments than does choosing between them, suggesting that the       default strategy should be a blend of both processes, which is abandoned only       when feedback justifies it.
the present research investigates semantic priming with an adapted       version of the word fragment completion task. the letter decision task, as we       will call it, holds some advantages over the traditionally used lexical decision       task in that it eliminates retrospective semantic matching effects, it avoids the       need to construct pseudowords, it is more engaging for participants and it       enhances semantic processing, which in turn allows for a more fine-grained       investigation of semantic activation. the letter decision task requires       participants to complete words, from which one letter was omitted like lett_ce       (lettuce), as fast as possible. the study found that words are completed faster       when the preceding trial comprised a semantically related fragment like tom_to       (tomato) than when it comprised an unrelated fragment like guit_r (guitar).       furthermore, the study provides insight in the nature of the priming effect. it       demonstrates that priming effects are larger for strongly associated prime-target       pairs.
recognition  of  motion  is  vitally  important  to  any  animal.        vision  research  has  proposed  a  number  of  algorithms applicable to action       recognition. however, unlike successes in early  visual  perception,  the  past        studies  have  not  yet established the computational theory of action       recognition. in the present study, we employ a dynamical systems approach and        hypothesize  that  motions  are  encoded  cognitively  as  a topological       structure abstracted from physical particulars. we investigated  whether  a        common  topological  nature  could  be found  in  a  type  of  rhythmic        movement.  the  topological nature of action dynamics showed a striking       similarity, which could  not  have  been  identified  with  other  analyses        where physical properties were retained. the result suggests that the dynamical        perspective  serves  as  a  theoretical  basis  in studying complex human       movements. 
subjects' eye movements were recorded while they read sentences       for comprehension. sentences were presented with capitalized nouns—in       agreement with german spelling rules—or completely in lowercase. overall       reading speed was not influenced by the manipulation of capitalization, but       fixation durations were affected by the interplay between capitalization and the       word classes of the fixated and the succeeding word. as expected, fixations were       shorter for capitalized than lowercase nouns, but unexpectedly they were longer       when the upcoming word was also a noun. this modulation was reduced when all       words were printed completely in lowercase. we interpret the results as evidence       for distributed processing across several words.
in human face-to-face communication, language comprehension is a       multi-modal, situated activity. however, little is known about how we combine       information from these different modalities, and how perceived communicative       intentions, often signaled through visual signals, such as eye gaze, may       influence this processing. we address this question by simulating a triadic       communication context in which a speaker alternated her gaze between two       different recipients. participants thus viewed speech-only or speech+gesture       object-related utterances when being addressed (direct gaze) or unaddressed       (averted gaze). two object images followed each message and participants’       task was to choose the object that matched the message. unaddressed recipients       responded significantly slower than addressees for speech-only utterances.       however, perceiving the same speech accompanied by gestures sped them up to a       level identical to that of addressees. that is, when speech processing suffers       due to not being addressed, gesture processing remains intact and enhances the       comprehension of a speaker’s message. 
previous research indicates learning words facilitates       categorization. in the current study, we investigated whether learning about a       category facilitates word learning (retention) by presenting 2-year-old children       with multiple referent selection trials to the same object category. children       either encountered the same exemplar repeatedly or encountered multiple exemplars       across trials. all children did very well on the initial task. however, only       children who encountered multiple exemplars retained these mappings after a short       delay. overall, these data provide strong evidence that providing children with       the opportunity to compare across exemplars during referent selection facilitates       retention.
in cognitive science there is a paradox: researchers studying       decision making have repeatedly shown that people employ simple and often less       than optimal strategies when integrating information from multiple sources.       however, researchers working in fields such as categorization, memory, and       perception have had great success using optimal models to account for information       integration. is this conflict due to the use of different materials and       procedures? we test the hypothesis that stimuli requiring more controlled       information integration lead to suboptimal performance, while stimuli that lend       themselves to more automatic processing produce more optimal integration. we test       for one canonical example of sub-optimal information integration, the dilution       effect, using stimuli more commonly found in perception experiments. dilution was       indeed reliable across several conditions. the largest effects occurred in       stimuli manipulated so as to discourage automatic processing. we use the       multi-component information accumulation model to explain how stimulus       presentation influenced cognitive processing.
the paper aims to extend the findings of a previous study       (grinberg et al., 2012) exploring the impact of social relations on the       cooperation in the prisoner’s dilemma game. relations between players are       manipulated by assigning different roles. the roles embodied the four basic types       of human relations in line with fiske’s relational models theory (fiske,       1991): communal sharing, authority ranking, equality matching, and market pricing       (players are assigned roles of team mates, chief and subordinate, partners, and       opponents, respectively). cooperation rates, mutual cooperation, mutual       defection, and payoffs gained were subsequently analyzed and compared for a       series of forty games. as a result we identified that the market-pricing       condition is characterized by considerably lower individual and mutual       cooperation, higher mutual defection and lower payoff in comparison to the       conditions impersonating the remaining three relational types.
in order to learn about the world, young children rely on       information provided by social partners. past research has shown children       consider a variety of factors when learning from others, including consensus.       corriveau, fusaro, and harris (2009) found that in an object labeling task,       children trust responses that receive majority support, and they concluded that       children prefer members of a majority as social informants. however, it is       possible that children prefer majority members only in domains that rely strongly       on socially constructed norms, such as object labeling, where non-social       information is unavailable. we formalized this prediction using a rational model       of learning from testimony across tasks, and compared our model’s       predictions to children’s responses in object labeling and causal learning       tasks. we find that in a causal learning task, a domain that relies less on       socially constructed norms, children rely more on their personal observations       than informant testimony.
we present a novel, biologically plausible model of visual motion       processing and perceptual decision making that is independent of the number of       choice categories or alternatives. the implementation is a large-scale spiking       neural circuit consisting of: 1) a velocity filter using the principle of       oscillator interference to determine the direction and speed of pattern motion in       v1; 2) a representation of motion evidence in the middle temporal area (mt); and       3) integration of sensory evidence over time by a higher-dimensional attractor       network in the lateral intraparietal area (lip). we demonstrate the model by       reproducing behavioral and neural results from classic perceptual decision making       experiments that test the perceived direction of motion of variable coherence dot       kinetograms. specifically, these results capture monkey data from two-alternative       forced-choice motion decision tests. we note that without any reconfiguration of       the circuit, the implementation can be used to make decisions among a continuum       of alternatives.
concept-location facilitation effects for words presented in       isolation have been cited as evidence for embodied cognition. prior work has       demonstrated that words found in high physical locations (e.g., bird) are       processed faster at the top of the screen and words found in low physical       locations (e.g., fish) are processed faster at the bottom of the screen. in a       response time experiment we presented participants with physical-location words       from existing studies at the top or bottom, top or center, and center or bottom       of the screen. we did this in order to determine if word judgments were made with       respect to an absolute location on the screen (embodied explanation) or with       respect to a relative location in comparison to other words included in the       experimental session (statistical linguistic explanation). for animate words we       found a concept location facilitation effect for words presented at the top of       the screen, at the center of the screen, and at the bottom of the screen. in       addition, bigram frequencies explained rts to center words. findings indicated       that subjects made judgments relative to other words on the screen and not       relative to their absolute location on the screen, lending support to a       statistical linguistic explanation of the findings.
research has shown that spatial referencing differs across       cultures. whether “western” samples, specifically ones speaking the       same native language, show the same referencing patterns has not been       investigated thus far. examining spatial referencing behavior across different       tasks, we compared samples from four different countries speaking the same       language with respect to their application of the intrinsic frame of reference       (for) and the three variants of the relative for. our findings indicate       influences of factors beyond language: while the four french-speaking samples       showed an overall preference for the reflection variant of the relative for, they       differed significantly regarding the extent to which reflection and the intrinsic       for were applied. moreover, in all samples, characteristics of the referenced       objects, namely whether they were animate or inanimate, influenced for use. the       order of tasks also had an impact on referencing behavior.
this study investigates whether viewing human gestures facilitates       learning about non-human biological movements and whether correspondence between       gesture and to-be-learned movement is superior to non-correspondence. functional       near-infrared-spectroscopy was used to address whether gestures activate the       human mirror-neuron-system (hmns) and whether this activation mediates the       facilitation of learning. during learning participants viewed triples of       visualizations (animation – gesture video – animation). results       showed that for low-visuospatial-ability learners corresponding gestures led to       higher cortical activation in the inferior-frontal cortex (part of the hmns) and       better learning outcomes, whereas for high-visuospatial-ability learners the type       of gesture had no influence. furthermore, results showed that – if       presented with non-corresponding gestures – only low-visuospatial-ability       learners who activated their inferior-parietal cortex (also part of the hmns),       improve their learning. thus, activating the hmns facilitates learning about       movements and stimulating the hmns via gestures seems to be an adequate       instructional strategy to enhance learning with dynamic visualizations for       low-visuospatial-ability learners.
models of cognitive processes often include simplifications,       idealisations, and fictionalisations, so how should we learn about cognitive       processes from such models? particularly in cognitive science, when many features       of the target system are unknown, it is not always clear which simplifications,       idealisations, and so on, are appropriate for a research question, and which are       highly misleading. here we use a case-study from studies of language evolution,       and ideas from philosophy of science, to illustrate a robustness approach to       learning from models. robust properties are those that arise across a range of       models, simulations and experiments, and can be used to identify key causal       structures in the models, and the phenomenon, under investigation. for example,       in studies of language evolution, the emergence of compositional structure is a       robust property across models, simulations and experiments of cultural       transmission, but only under pressures for learnability and expressivity. this       arguably illustrates the principles underlying real cases of language evolution.       we provide an outline of the robustness approach, including its limitations, and       suggest that this methodology can be productively used throughout cognitive       science. perhaps of most importance, it suggests that different modelling       frameworks should be used as tools to identify the abstract properties of a       system, rather than being definitive expressions of theories.
one significant challenge in creating accurate models of human       decision behavior is accounting for the effect of context. research shows that       seemingly minor changes in the presentation of a decision can lead to drastic       shifts in behavior; phenomena collectively referred to as framing effects.       previous work has developed context dependent utility (cdu), a framework       integrating appraisal theory with decision-theoretic principles. this work       extends existing research by presenting a study exploring the behavioral       predictions offered by cdu regarding the multidimensional effect of context on       decision behavior.        the present study finds support for the predictions of cdu regarding the impact       of context on decisions: 1) as perceptions of pleasantness increase, decision       behavior tends towards risk-aversion; 2) as perceptions of goal-congruence       increase, decision behavior tends towards risk-aversion; 3) as perceptions of       controllability increase, i.e., perceptions that outcomes would have been       primarily caused by the decision maker, behavior tends towards risk-seeking.        
episodic future thinking refers to a human cognitive process which       generates successive predictions of events that are likely to occur in a       cue-specific context in the future. an emerging view is that semantic memory as       well as episodic memory contributes to this process, but the exact mechanism       remains unclear. we built a computational model that learned to predict the next       event upon a presented event (sequence prediction model). after learning the       statistical structure in the training sequence, the model was tested for       generating successive self-predictions of events triggered by a cue. the       generated sequence of events captured some phenomenological features of patients       with semantic dementia when the semantic system of the model was damaged. the       role of semantics in episodic future thinking and the usefulness of a sequence       prediction model are discussed.
creative reasoning in ill-defined problem spaces operates       differently from classical reasoning in well-defined spaces. to systematically       compare the two in an identical knowledge domain, we applied a classical       intelligence test: the standard progressive matrices (spm), in combination with       two tests of creativity: the test for creative thinking - drawing production       (tct-dp) and the newly developed creative reasoning task (crt), in which       participants are asked to create an spm-like item, to two age groups (n1 = 511,       4-12y old; n2 = 205, 6-10y old). for spm and crt the knowledge domain consists of       relationships amongst geometrical components in 3 x 3 matrices. we developed a       typology for scoring the number and complexity of the relationships used in these       matrices. for the spm, we scored frequencies of relationships solved and for crt       those created, and interpreted the scores in terms of differences and       similarities between classical and creative reasoning in cognitive       development.
we develop and implement a new approach to utilizing color       information for object and scene recognition that is inspired       by the characteristics of color- and object-selective neurons in       the high-level inferotemporal cortex of the primate visual system.       in our hierarchical model, we introduce a new dictionary       of features representing visual information as quantized color       blobs that preserve coarse, relative spatial information. we run       this model on several datasets such as caltech101, outdoor       scenes and underwater images. the combination of our color       features with (grayscale) shape features leads to significant increases       in performance over shape or color features alone. using       our model, performance is significantly higher than using       color naively, i.e. concatenating the channels of various color       spaces. this indicates that usage of color information per se is       not enough to produce good performance, and that it is specifically       our biologically-inspired approach to color that results in       significant improvement.
we introduce a method for encoding co-occurrence of features       in the hmax model of visual recognition, and conduct a series       of experiments to investigate the contribution of co-occurrence       towards better recognition performance. we show that classification       accuracy is increased by adding a higher-order layer       to the hmax processing hierarchy, whereby co-occurrence       of features is encoded as a new dictionary of features. we       show that concatenation of mean pooling, max pooling and       co-occurrence information results in better classification results       on three datasets (caltech101, a subset of caltech256,       and tmsi underwater images). overall, we show that incorporating       co-occurrence statistics into a biologically-inspired       model of visual recognition provides a boost in classification       performance above that produced by incorporating occurrence       statistics alone.
this paper investigates the role of the assumption of       class-conditional independence of object features in human       classification learning. this assumption holds that object feature values are       statistically independent of each other, given knowledge of       the object's true category. treating features as class-conditionally independent       can in many situations substantially facilitate learning and categorization even       if the assumption is not perfectly true. using optimal experimental design       principles, we designed a task to test whether       people have this default assumption when learning to categorize. results provide       some supporting evidence, although the data       are mixed. what is clear is that classification behavior adapts to the structure       of the environment: a category structure that is unlearnable under the assumption       of class-conditional independence is learned by all participants.
similarity is a notion that is widely used both in cognitive       science and in argumentation theory. these research programs have, however,       developed in large part separately and in consequence rely on disparate notions       of similarity. only recently there has been a proposal for specifying how       similarity actually plays a role in judging slippery slope arguments. we present       here further theoretical discussion and empirical evidence in order to show how       similarity can play a role in slippery slope arguments and in argumentation in       general. in the experiment presented here, we manipulated the availability of       causal information, and showed that people are sensitive to it when judging       arguments’ strength. we conclude that similarity between causal properties       of the elements presented in arguments is crucial for arguments’ strength       assessments.
how do we assign causal responsibility for others’       decisions? the present experiments examine the possibility that an optimality       constraint is used in these attributions, with agents considered less responsible       for outcomes when the decisions that led to those outcomes were suboptimal. our       first two experiments investigate scenarios in which agents are choosing among       multiple options, varying the efficacy of the forsaken alternatives to examine       the role of optimality in attributing responsibility. experiment 3 tests whether       optimality considerations also play a role in attribution of causality more       generally. taken together, these studies indicate that optimality constraints are       used in lay decision theory and in causal judgment.
humans, as a cooperative species, need to coordinate in order to       achieve goals that are beyond the ability of one individual. modeling the       emergence of coordination can provide ways to understand how successful joint       action is established. in this paper, we investigate the problem of two agents       coordinating to move an object to one agent’s target location through       complementary action. we formalize the problem using a decision-theoretic       framework called decentralized partially observable markov decision processes       (dec-pomdps). we utilize multiagent q-learning as a heuristic to obtain       reasonable solutions to our problem and investigate how different agent       architectures, which represent hypotheses about agent abilities and internal       representations, affect the convergence of the learning process. our results       show, in this problem, that agents using external signals or internal       representations will not only eventually perform better than those that are       coordinating in physical space alone but also outperform agents that have       independent knowledge of the goal. we then employ information theoretic measures       to quantify the restructuring of information flow over the learning process. we       find that the external environment state varies in its informativeness about       agents’ actions depending on the agents’ architecture. finally, we       discuss how these results, and the modeling technique in general, can address       questions regarding the origins of communication.
representational shifts in memory have been a recent topic of       interest and debate (blanco & gureckis 2012; lupyan, 2008; richler, gauthier &       palmeri, 2011; richler, palmeri & gauthier, 2012). whether there are true       systematic biases in memory due to a stimulus being labeled has been proposed and       contested. the fundamental proposal that representations shift toward the       prototype has not previously been demonstrated. in the present experiment,       participants judged colored silhouettes by color category or by preference, then       were asked to remember the hue of the original silhouette among five narrowly       distinct options. by using the single dimension of hue, we are able to show       prototypical representational shifts in memory for colored silhouettes after a       few minutes. we did not observe a difference between color labeled and preference       judged silhouettes, refuting the claim that labeling is the source of       prototypical representational shifts.
foraging is a search process common to mobile organisms, and       foraging paths commonly exhibit statistical patterns akin to lévy walks.       there may be common factors and benefits underlying these patterns, but       investigations are hindered by difficulty in assessing and manipulating search       environments and task conditions. in the present study, a simple foraging game       was developed to isolate and manipulate two factors hypothesized to make       lévy walks adaptive search strategies—sparsity, and spatial clustering       of targets in the search environment. players navigated a fuel-limited ship over       a 2d grid to find as many targets as possible, rendered as asteroids in outer       space. over 1800 participants were recruited to play using amazon’s       mechanical turk, in order to widely sample the parameter space defined by degrees       of target sparsity and clustering. observed search paths resembled lévy       walks with memory, and those of high performers were found to vary adaptively       with clustering, but not sparsity. results indicate that lévy-like walks can       emerge from search strategies and algorithms adapted to environments with       clustered resources.
we propose a modular neural-network structure for implementing the       bayesian framework for learning and inference. our design has three main       components, two for computing the priors and likelihoods based on observations       and one for applying bayes' rule. through comprehensive simulations we show that       our proposed model succeeds in implementing bayesian learning and inference. we       also provide a novel explanation of base-rate neglect, the most well-documented       deviation from bayes' rule, by modelling it as a weight decay mechanism which       increases entropy. 
in daily conversations, what information do people use to assess       their conversational partner’s explanations? we explore how a metacognitive       cue, in particular the partner’s confidence or uncertainty, can modulate       the credibility of an explanation. two experiments showed that explanations are       accepted more often when delivered by an uncertain conversational partner.       participants in experiment 1 demonstrated the general effect by interacting with       a pseudo-autonomous robotic confederate. experiment 2 used the same methodology       to show that the effect was applicable to explanatory reasoning and not other       sorts of inferences. results are consistent with an account in which reasoners       use relative confidence as a metacognitive cue to infer their conversational       partner’s depth of processing. 
we describe two studies that show that when individuals who are       not programmers create algorithms, they rely on mental simulations. our studies       concerned a railway domain in which carriages are rearranged – a simple       environment but equivalent in computational power to a turing machine.       participants successfully solved rearrangement problems (experiment 1), and       created algorithms to solve them (experiment 2) and their performance       corroborated the use of simulation. the participants tended to use loops and to       prefer while-loops even though they are of greater computational power than       for-loops. their ability to create algorithms for abstract problems improved when       they first had to create algorithms for more concrete problems. we devised a       computer program that creates its own algorithms for rearrangement problems. it       generates lisp functions that operate on lists and creates descriptions of them       in everyday language. the complexity of the resulting algorithms predicts       participants’ difficulty in devising them.
when people communicate in normal environments, they use several       communication channels, such as the verbal channel, prosody (non-segmental       aspects of sound) and the visual channel. there is a great variety of views on       the relative contribution of these channels to the overall understanding of       messages. linguists typically limit their interests to the verbal channel alone,       while social psychologists often emphasize the importance of non-verbal       components. this study offers an experimental methodology allowing to empirically       evaluate the contributions of different channels. two experimental studies are       reported that used different stimulus material: movies and recorded conversation.       according to the results of the experiments, all of the communication channels       are highly significant, the verbal channel being the leading one. experiment       participants experienced difficulties in certain unusual conditions, such as the       combination of the prosodic and visual channels without the verbal component.       this paper is a contribution to the field of multimodal studies.
coherent collective behavior emerges from local interactions       between individuals that generate group dynamics. an outstanding question is how       to quantify group coherence in order to understand the nature of these dynamics.       we investigate this problem in the context of a small group of pedestrians       instructed simply to walk to a goal. to measure the degree of coordination in a       group, we employed principal components analysis to estimate dimensional       compression, and cross-recurrence quantification analysis to estimate the       coupling strength between individuals. the results indicate lower-dimensional       behavior and more stable coupling in real groups compared to reshuffled virtual       groups. these findings demonstrate spontaneous local coordination in pedestrian       groups that gives rise to coherent collective behavior, and offer an approach for       investigating group dynamics in more complex contexts. 
we describe a model designed to learn word-concept pairings using       a combination of semantic space models. we compare various semantic space models       to each other as well as to extant word-learning models in the literature and       find that not only do semantic space models require fewer underlying assumptions,       they perform at least on par with existing associative models. we also       demonstrate that semantic space models correctly predict different word-concept       pairings from existing models and can be combined with existing models to perform       better than either model can individually.
turkish emphatic reduplication (ter) occurs in adjectives       and adverbs to accentuate their meanings. the current experimental       study to investigate the selection of the linker type in       ter indicated that responses from the participants correlate       with some lexical statistics. the result relies on the statistics       from a corpus with approximately 2 million turkish words,       which we use in lieu of lexical statistics. the frequency order       of linker choice reported by the participants was exactly       the opposite of the order of frequency of words in which the       linker and the first consonant co-occur consecutively in the corpus.       such a direct link to lexicon was unexpected. we suggest       that ter, an apparently phonological operation, depends on       lexical access for selecting the appropriate linker whose cooccurrence       with the initial consonant of the reduplicated word       is infrequent. our results relate morphology and lexicon in       more ways than the blocking phenomena, and suggest that       ter may be morpholexical.
growing bodies of research have investigated how digital games       might be used as pedagogical tools and separately, how playing commercial games       influences basic cognitive capacities or skills. the goal of the present research       is to draw from these separate lines of research to ask how changes in basic       cognitive capacities and formal learning gains may be related. the present study       employed a game in which a ship moves through different environments using       forces. the game teaches the basic relationships between objects and forces in       newton’s laws of motion. students played one of two versions of the game.       the predictive version encouraged planning and reflection, by allowing students       unlimited time to place forces along a path. in the real-time version, forces       immediately affected the player when selected. the results suggest that learning       was equivalent across the versions, but changes in attentional capacities may       differentially contribute to learning between versions.
bilingual speakers are confronted with a unique challenge when       learning language as they must learn to express the same concept in two separate       languages. here, we examine whether learning number words in one language (i.e.,       l1) facilitates the acquisition of analogous number words in a second language       (i.e., l2) or whether extensive experience and familiarity with numbers within       the second language is required to learn words in l2. to do so, we tested 68       bilinguals speakers between the ages of 2 and 4 years and show that conceptual       knowledge of numbers in l1 reliably predicted children’s conceptual       knowledge of numbers in l2, suggesting that knowledge transferred from one       language to the other. the effect, however, was limited to two developmental       transitions: one-knower to two-knower and subset knower to cp-knower. familiarity       with l2 numbers as well as age were also significant predictors of       children’s conceptual understanding of numbers. 
the contextuality of changing attitudes makes them extremely       difficult to model. this paper scales up quantum decision theory (qdt) to a       social setting, using it to  model the manner in which social contexts can       interact with the process of low elaboration attitude change. the elements of       this extended theory are presented, along with a proof of concept computational       implementation in a low dimensional subspace. this model suggests that a       society's understanding of social issues will settle down into a static or frozen       configuration unless that society consists of a range of individuals with varying       personality types and norms.
language abilities gradually decline as we age, but the mechanisms       of this decline are not well understood. the present study investigated       comprehension of subject vs. object who and which direct questions (dqs),       embedded questions (eqs) and relative clauses (rcs) in 39 cognitively healthy       native speakers of spanish. the elderly participants (n = 21) were further       classified according to their scores on a general cognitive test, montreal       cognitive assessment (moca), into a group with low moca scores, lm (n = 10), and       a group with normal moca scores, nm (n = 11). a mixed-model, repeated-measures       analysis of variance (anova) showed that the elderly participants achieved       significantly worse accuracy and speed than the young participants (y) in all       tasks. accuracy was significantly lower and reaction times significantly longer       in the lm group compared to the nm group in dqs and rcs. accuracy in       comprehension of eqs was also worse in lm compared to nm, with no significant       difference in rts between the two groups. the results are explained within the       competition model and reliance on a language-specific cueing strategy. reliance       on cueing strategies in sentence comprehension may be an effective indicator of       cognitive decline associated with aging.
mental time travel (mtt) is, roughly, an individual’s       capacity to project herself into the past or future by remembering or imagining       first-personal experiences respectively. mtt is further presumed to have a       distinct, concrete though dispersed neural correlate, and hence describes a       neuro-cognitive phenomenon.       opening with a brief sketch of the development and current state of the art, the       essay pursues three central aims: firstly, it constitutes a plea for more       conceptual rigour on the cognitive side of the fence, so as to ensure that       meaningful lessons can be drawn from neurological enquiry about it. secondly, a       partial conceptual qualification of the necessary requirements of mtt as       traditionally conceived is proposed, as they seem vague, uninformative and       arbitrary. finally, a revision of mtt is attempted, which aspires to include a       variety of mental states so far not associated with mtt. mtt, as it is currently       defined and investigated, i will argue, stands too heavily in the genealogical       debt of research into episodic memory, and suffers from an astonishing neglect of       considerations pertaining to imagination.
while there is some evidence that causal discourse rela-       tions are processed incrementally, the time-course of compre-       hending concessive discourse markers (e.g., nevertheless) has       hardly been investigated. given that concessives are often de-       fined as negative causals, there may be similarities between the       processing of concessives and negations (e.g., a delay).        this paper investigates the time-course of processing causal       versus concessive discourse markers in german within both       a visual-world experiment and a reading experiment. we       find that while concessive discourse markers can be processed       rapidly if the context is constraining enough, there is a delay       compared to causal contexts.       
we directly compared the effectiveness of a spelling intervention       focused on morphological structure with one that emphasized the meanings of       complex words, to differentiate their relative contributions to spelling       acquisition in grade 3 and grade 5. we found that the morphology intervention       provided a greater improvement than the vocabulary intervention, especially for       children in grade 5. to compare the long-term effects of the two interventions,       we tested the children’s spelling ability six-months after the conclusion       of the intervention program. results show that both grades maintain an increase       in spelling accuracy compared to their pre-intervention performance.       additionally, the children in grade 5 who received morphological instruction       retained more spelling knowledge than those who received the vocabulary       instruction. these results suggest that teaching children about the structure of       complex words supports their spelling ability in the long-term, providing       evidence for the important role of morphological knowledge in literacy       development.
in two experiments we study how redundant size modifiers influence       the perceived size of objects. we show that when objects are referred to with       overspecified descriptions (for example, using a description like “the       large red chair” in a situation where all chairs are equally large but       different in color), participants subsequently estimate the object to be larger       than when objects are referred to using minimally distinguishing descriptions       (e.g., “the red chair”). in experiment 1, we show this effect with       adult language users and different kinds of size modifiers. in experiment 2, the       same effect is shown for children of two different age groups (7- and 10-year       olds), and for different kinds of visual size contrasts. interestingly, we       observe an inversely proportional relation between the age of our child       participants and the difference in size estimates for minimal and overspecified       descriptions, suggesting that language users gradually become better at avoiding       false pragmatic inferences from redundant adjectives as they grow older.
cognitive ecology is a term that has been used in environments       that are more tightly coupled and purpose-specific than environments of everyday       life. in this paper i consider cases from a cognitive ethnography of older       adults. these cases show the analytical use of understanding the diachronic and       synchronic cognitive ecology in which cognitive processes of everyday life occur.       specifically i discuss how the social and physical ecology and changes in these       can shape goals, the use of cognitive artifacts and the use of other cognitive       resources in agent environments that are not as purpose created and not as       tightly coupled as environments of previous studies in this field.
cyberbullying is defined as bullying via electronic means       including the defining characteristics of repetition over time, intent to harm,       and power imbalance. however, this normative top-down definition is discussed       controversially. we argue that the term “cyberbullying” and the       associated defining criteria might constrict our focus artificially. therefore,       we investigate bottom-up which aspects of cyber cruelty contribute to       victims’ distress in an adaptive conjoint design with two independent       samples (sample 1: n = 131; sample 2: n = 82). six potentially relevant factors       were investigated, each with multiple attributes: number of incidents,       perpetrator status, perpetrator motive, and type, medium, and publicity of cyber       incident. contrary to the definition of cyberbullying, number of incidents,       publicity, and type of cyber cruelty emerged as most important factors. these       results allow us to further map the cognitive representation of cyber cruelty and       are practically relevant for the definition and measurement of cyberbullying.
while recent studies show dissociation between the implicit and       explicit aspects of ‘sense of agency’, the mechanisms underlying       these different aspects of agency are not yet clearly understood. we argue that       the control achieved at different levels of hierarchy is important for different       aspects of agency. in the current study, we investigate how changes in control at       the perceptual-motor level and at goal level influence implicit and explicit       measures of sense of agency. in a given trial, participants were first required       to aim at a target in a noisy environment and then shoot at the target. after       certain interval, a circle flashed at the location where participant aimed while       pressing the trigger. participants estimated the interval between action and       presentation of the circle that acted as a measure of intentional binding, an       implicit measure of agency and also rated an explicit sense of authorship. the       results suggest that different aspects of agency and dissociation between       implicit and explicit aspects of agency are mediated by control achieved at       various levels.
although many psychometric tests, like raven’s progressive       matrices, are commonly evaluated according to total score, additional variables       can lend insight into the underlying cognitive processes.  we examine conceptual       errors on the raven’s standard progressive matrices (spm) test. we present       a complete classification of error types on the spm using a two-kind coding       scheme, yielding ≥ 95% inter-rater reliability. we also examine how to       extract error data from a computational model, and we present a method for       measuring errors through systematic ablation to create a “population”       of models whose performance can be examined as a group.  we present a preliminary       analysis of error patterns on the spm from typically developing individuals,       individuals diagnosed with autism, and a computational model called asti. we       discuss what the error patterns suggest regarding cognition on the spm and routes       towards improving the asti model.
experts and intermediates fundamentally differ in the ways they       explain subject matter to novices. experts provide less details but in a highly       coherent format, whereas intermediates provide many additional details but in a       format with low coherency. in a recent study, we found that experts’       explanations enabled novices to acquire more transferable and flexible knowledge       as opposed to explanations by intermediates mainly due to the higher coherence of       experts’ explanations. in order to investigate more directly how       experts’ and intermediates’ explanations differently triggered       novices’ processing of the explanations, we conducted a think-aloud study.       results indicated that novices learning with an expert’s explanation       processed the explanations deeper than novices with intermediates’       explanations. in line with this, deep processing was significantly related to       novices’ transfer. thus, expertise can be regarded as an essential       prerequisite for generating effective instructional explanations that engage       novices to process the subject matter deeply and to generate transferable       knowledge.
we studied decision making in situations in which there is a       monetary incentive to take risk, and in which the risk taking option sometimes       involves deception. we conducted a within participant experiment in which we       compared risk taking in deception conditions to pure (non-deceptive) gambles with       equivalent risks and outcomes. we confirmed the four-fold pattern of risk       attitudes in both conditions. we found that participants chose fewer risky       options when the risky       option was associated with deception, but that those who deceived more in the       deception condition also took more risks in the gamble condition. we conclude       that people who tend to take risks in gambles, also take them when it involves       deception, although to a lesser extent.       
utilizing a preparation for future learning paradigm and the       interactive-constructive-active-passive framework, this study examined how two       different kinds of cognitively engaging activities prepared students to learn       from collaborating. findings show that preparing prior to collaborating improved       learning, but a difference was not detected in the type of preparation. in       addition, differences in learning outcomes were only present in measures of deep       knowledge. analyses used a multilevel method targeted to dyadic data. discussion       addresses designing collaborative classroom activities that are effective and       efficient for deep learning, as well as the importance of aligning assessments to       depth of learning.
the present study examined how time-on-task (i.e., practice and       fatigue) influences eye movements during visual search. first, we examined how       practice influences eye movements during an extended visual search task. results       replicate the findings that over the course of a visual search task, performance       improves and fixation duration increases. yet changes in fixation duration did       not correlate with changes in search performance. next, we examined how fatigue       influences eye movements during an extended visual search task. to manipulate       fatigue, participants either did or did not receive breaks. those who did not       receive breaks replicated our initial findings. critically, participants who did       receive breaks showed no increase in fixation duration over the course of the       visual search task. these results indicate that the increase in fixation duration       with time-on-task reflects fatigue, and that this measure of fatigue can be       derived independent of measures of performance improvements, such as shorter       response times
in prior work, we have demonstrated that attention to the neural       implementation of cognitive function is critical in creating models capable of       simulating the physiological traces of those functions (e.g., event-related       potentials; erps).  here, we extend our parallel distributed processing (pdp)       model of erp data elicited during the reading of single word forms to the       simplest more temporally extended phenomenon: the erp repetition effect.        simulations demonstrate that reproducing the dynamics of the erp repetition       effect can be accomplished by imposing the temporal envelope of post-synaptic       potentials on individual units in the model.       
it has been demonstrated that brief exposure to behavioral       information is sufficient for making accurate social judgments. movement       coordination during social interaction, is one potential cue. although       coordination between individuals has been identified, our ability to perceive it       when making judgments regarding affiliation (friends vs. strangers) is unknown.        in the present studies, we investigated how correlated movement contributes to       observers’ accuracy when judging affiliation. using correlation map       analysis to quantify coordination, we showed that individuals familiar with each       other correlated their movements more frequently. observers were able to use       coordination as a cue, but only when the information presented was restricted to       movement related to speech (i.e. while only viewing faces). these results suggest       that observed movement coordination is influenced by speech-related movements. we       suggest that social perception is multi-faceted and cues may be prioritized       differentially based on availability.
when studying, the reliability of metacognitive monitoring, the       predicted achievements at test, is strongly associated with the quality of study       regulation and with ultimate performance at test. previous studies that compared       learning texts on screen to learning from printed texts found that screen       learners performed worse and were overconfident about their success. the present       research examined two methods for overcoming screen inferiority in these       respects. gaining experience with the study-test task with six different texts       allowed improvement. writing keywords after a delay from learning already       eliminated screen inferiority from the first studied texts. in both methods,       predictions of performance did not reflect changes in test scores. the two       methods clearly affected screen and paper learners differently. this study       outlines directions for overcoming screen inferiority, but also calls attention       to the effects of context on cognitive and metacognitive processes, beyond the       mere interaction between the person and the task content.
this study examined the effect of an explicit relational rule on       sequence learning in a 3-choice serial reaction time task. simple probabilistic       contingencies between pairs of response cues were used in such a way that the       sequence of cues moved predominantly in one direction (i.e. either clockwise or       counterclockwise). performance on cued and miscued responses was compared for a       group given a hint about the abstract rule describing the relationship between       the response cues, and a group given no information about this relationship.       experiment 1a demonstrated that xyz and xyx subsequences showed performance       differences when the location of the target on each trial was random. experiment       1b showed that giving participants the explicit hint affected xyz subsequences       more than xyx subsequences. implications for sequence learning and, specifically,       the interaction between rule and instance learning are discussed.
in this paper we present a neural network model of motor learning       structured around circuits which associate motor actions with their sensory       effects, as proposed by hommel et al. (2001). the network implements a novel       model of causative actions, which bring about specified distal movements in       manipulated target objects (e.g. bending a lever). it also serves as the basis       for a novel embodied account of the syntax of causative sentences such as 'john       bent the lever'.
'thinking outside the box' is a nice metaphor, but we are so used       to putting things in boxes that it may seem essential to our way of thinking.       this idea is enforced by the standard view of relations that says that relata       always come in a certain order. there is, however, an alternative view on       relations, the antipositionalist view, according to which the constituents of the       complexes of a relation neither come in a certain order, nor do they occupy       positions. instead, a relation is conceived as a network of interrelated       complexes. we show that this view facilitates a coordinate-free way of thinking       and that it may thus have a heuristic value.
chess experts remember meaningful chess positions better than       novices (de groot, 1978; chase & simon, 1973). this can be explained with a       larger number of chunks in experts' long-term memory (gobet & simon, 1998). these       chunks are mainly based on visual representations, that is, pieces on squares.       however, a recent experiment highlighted that experts prefer to group chess       positions by abstract similarities that cannot be explained purely visually       (linhares & brum, 2007). based on these data it was claimed that chess expertise,       in addition to chunks, crucially relies on abstraction and analogies. these data       and the conclusions were heavily criticized because the instructions strongly       biased the participants to group positions in a certain way (bilali'c & gobet,       2009). here, we successfully replicated this experiment with less explicit       instructions. in addition, we collected category labels for the groupings that       allowed us to explore the abstract principles that participants used.
we report three experiments that explore the effect of prior       linguistic knowledge on implicit language learning. native speakers of english       and native speakers of cantonese participated in implicit learning (il)       experiments that involved different learning materials. in experiment 1, both       participant groups showed evidence of learning a mapping between articles and       noun animacy. in experiment 2, neither group showed learning of the mapping       between articles and a linguistically anomalous concept (the number of capital       letters in an english word or the number of strokes in a chinese character). in       experiment 3, the chinese group, but not the english group, showed evidence of       learning a mapping between articles and a concept derived from the chinese       classifier system. it was concluded that first language knowledge affected       implicit language learning, and that il, at least when natural language learning       is concerned, is not a completely unconstrained domain-general mechanism.
some evidence in very recent psychological studies have       demonstrated that motor simulation ability is crucial for the correct       understanding of social intentions. the present study was conducted first to       confirm that the nature of the motor intention leads to early modulations of       movement kinematics. then, we tested whether humans could read an agent’s       intention when observing the very first element of a complex action sequence.       results revealed early variations in movement kinematics and further showed that       human agents can use these deviants to distinguish above chance level between       three different social actions. similar performance levels were found using an       artificial classifier (neural network) and this procedure demonstrated       furthermore that decisions could be taken on the basis of information contained       in the first 500ms of movement kinematics. taken together these results confirm       the importance of motor simulation for adapted social interaction, and suggest       how robotic adaptive controllers may use as input low-level motor information       (e.g. kinematics) to afford biologically inspired social behaviors.
the purpose of the current work is to examine when and how       knowing collective opinion influences people’s judgments       and decisions in social media environments. in particular, the       present work focuses on people’s true-false judgment of       statements found on websites and the likelihood of sharing       these statements. the results from experiment 1 revealed that,       for false statements, collective opinion had little influence on       people’s true-false judgments, but, for true and debatable       statements, their judgments were biased toward collective       opinion. the results from experiment 2 indicated that the       likelihood of sharing the true, debatable, and false statements       followed the collective opinion, and that people were less       likely to share false statements than debatable or true ones       without collective opinion. these findings extend past work       on social influence and advance understanding of how people       make judgments and decisions in social media websites.
neural correlate of human inductive reasoning process is still       unclear. number series and letter series completion are two typical inductive       reasoning tasks, and with common core component of rule induction. previous       studies have demonstrated that different strategies are adopted in number series       and letter series completion tasks even the underlying rules are identical. in       the present study, we examined cortical activation as a function of two different       reasoning strategies for solving series completion tasks. the retrieval strategy,       used in number series completion tasks, involves direct retrieving of arithmetic       knowledge to get the relations between items. the procedural strategy, used in       letter series completion tasks, requires counting a certain number of times to       detect the relations linking two items. the two strategies require essentially       the equivalent cognitive processes, but have different working memory demands       (the procedural strategy incurs greater demands). the procedural strategy       produced significant greater activity in areas involved in memory retrieval       (dorsolateral prefrontal cortex, dlpfc) and mental representation/maintenance       (posterior parietal cortex, ppc). an act-r model of the tasks successfully       predicted behavioral performance and bold responses in dlpfc and ppc. the present       findings support a general-purpose dual-process theory of inductive reasoning       regarding the cognitive architecture.
this study examined the hypothesis that individuals with       obsessive-compulsive disorder (ocd) show a selective deficit in inductive       reasoning but are unimpaired in their ability to make deductive inferences. 100       participants from an analog sample made inductive or deductive inferences about       arguments that differed according to causal consistency and validity. they also       completed a task examining sensitivity to the implications of diverse evidence in       induction. participants who were high or low on obsessive-compulsive symptoms       showed similar patterns of induction based on causal knowledge and similar       patterns of deduction. however, those with the highest level of ocd symptoms       showed less of a preference for diverse evidence when evaluating inductive       arguments, compared to those with the lowest level of symptoms. this difference       was found across both ocd-relevant and ocd-neutral items, and persisted when the       effects of group differences in general ability were controlled. these results       indicate that both inductive reasoning based on background knowledge and       deductive reasoning are intact in individuals with high ocd-traits but the use of       inductive heuristics such as evidence diversity is impaired.
the processing of incoming sensory information relies on       interacting mechanisms of sustained attention (the ability to focus attention and       ignore irrelevant stimuli) and attentional capture (the ability of certain       stimuli to reflexively attract one’s attention). being able to precisely       predict what can capture attention when it is engaged in a demanding task is       important both for understanding the nature of attention as a cognitive system       and also for practical applications. while evidence indicates that exogenous       capture, a mechanism previously understood to be automatic, can be eliminated       while concurrently performing a demanding task, we reframe this phenomena within       the theoretical framework of the ‘attention set’ (most et al., 2005).       consequently, the specific prediction that cuing effects should reappear when       dimensions of the cue overlap with those in the attention set (i.e., elements of       the demanding task) was empirically tested and confirmed. suggestions for further       theoretical refinement and empirical testing are discussed.
as a ubiquitous trend in the cognitive development of children,       the ‘relational shift’ accounts for a change in preference for       absolute percepts towards a preference for relational percepts, and is observed       across a wide variety of domains. extensive evidence indicates that this       prepotency for relational processing is also observed in how children process       melodies. when recalling melodies, younger children typically recall more       absolute pitch properties than older children, while the exact opposite occurs in       older children. using dora (discovery of relations by analogy; doumas et al.,       2008), a domain-general symbolic-connectionist model of relation learning, we       simulated the relational shift in melodic perception of children age 3-6 years       based on an experiment by sergeant and roche (1973). dora’s performance       matched the children’s well, suggesting common developmental and perceptual       mechanisms between the relational shift in melodic processing and the shift seen       across other domains.
human adults, infants, and non-human animals are believed to be       equipped with an approximate number system (ans) supporting non-symbolic       representations of numerical magnitudes. recent research has questioned both the       validity and reliability of tasks intended to measure acuity in the ans. issues       with validity and reliability might be due to differences in methodology. in the       present study, we compare four tasks designed to measure ans acuity, using a       within-subjects design. the tasks are compared with respect to response and       presentation format effects previously studied in the psychophysics literature,       but largely ignored in the ans literature. we find a presentation format effect       and show that when non-symbolic numerical stimuli are presented sequentially the       magnitude of the second stimulus is overestimated. further, the results indicate       that people’s sensitivity to differentiate between non-symbolic       numerosities is dependent on response format. the implications of the results to       measures of ans acuity are discussed.
successful learning from text takes place when the cognitive       demands of the learning task – i.e. the comprehension and retention of text       material – and the metacognitive demands of the learning task – i.e.       the accurate assessment of one’s own learning process—are met. the       present study was designed to investigate text titles – a factor known to       affect cognitive learning processes- as well as the timing of keywording tasks       – a factor known to affect metacognitive processes – and their       effects on metacognitive monitoring and learning outcomes. the results of the       study showed that both factors affected learning on the cognitive as well as the       metacognitive level. 
the blocking effect in causal learning, once taken as a hallmark       of associative learning, has recently been explained in terms of an explicit       deductive reasoning process. yet when the conditions necessary for deduction are       removed, a small blocking effect is often still present. we examined the       relationship between blocking and participants’ performance on analytical       thinking and probabilistic reasoning measures. inferential processes predict       blocking or an absence of blocking in this situation, depending on the       observer’s consideration of conditional probabilities. although bayesian       inference predicts blocking, most individuals are not inclined to use this form       of probabilistic reasoning explicitly, an observation we confirmed using a       logical problem with similar properties to the relationships present in the       blocking effect. furthermore, participants who showed the greatest capacity for       analytical reflection were less likely to show a blocking effect, suggesting that       blocking in causal learning is the product of an intuitive and unreflective       thought process.
visual working memory (vwm) is a crucial part of our cognitive       system.       currently there is an active debate how the apparent limitations of vwm should be       described. limited-slot and flexible-resource theories are discussed, but so far       the temporal dynamics of representations stored in vwm are not fully understood.       in this paper we present data that supports the notion of dynamic vwm contents       with changing precision. to account for these observations in a qualitative way,       we propose a neural network that is able to account for emerging capacity limits       as well as for changes in the precision of stored information.
communication depends on the production and interpretation of       representations, but the study of representational processes underlying       communication finds little discussion in computational experiments. here we       present an experiment on the emergence of both interpretation and production of       multiple representations, with multiple referents, where referential processes       can be tracked.   results show the dynamics of semiotic processes during the       evolution of artificial creatures and the emergence of a variety of semiotic       processes, such as sign production, sign interpretation, and       sign-object-interpretant relations.
recent works indicated that performing a joint spatial       compatibility task with an incompatible stimulus-response mapping affects       subsequent joint simon task performance, eliminating the social simon effect       (social transfer of learning effect or stol effect). crucially, the stol effect       was not tuned to the specific identity of the co-actor, and depended on the       overlap between the spatial relations of the practice and transfer tasks.       starting from these findings, this study aimed at investigating which spatial       relations between stimulus (s), response (r) or participant (p) positions are       relevant for the stol effect to occur. two experiments were run in which the       participant-response associations were incompatible (participants were required       to respond with crossed arms), whereas the  stimulus-response and       stimulus-participant associations were manipulated. we found that learning       derived from the practice task did not transfer to the subsequent task when       stimulus-response associations were spatially incompatible and       stimulus-participant associations were compatible (experiment 1). however, a stol       effect was evident when stimulus-participant associations were spatially       incompatible and stimulus-response associations were compatible (experiment 2),       hence suggesting that the spatial relation between stimulus and participant       positions is crucial for the stol effect to occur.
aim of the present study is to investigate whether and to what       extent movements performed with the whole body can influence calculation       processes. participants were asked to perform additions or subtractions while       executing an ascending or descending movement in a passive (i.e., by taking the       elevator) or active (i.e., by taking the stairs) mode. results revealed a       congruency effect between the type of calculation made and the direction of the       movement performed, but only when participants experienced it through a passive       mode. our data are in line with studies providing evidence of a strict link       between numerical and spatial representations, and between motor actions and       number magnitude processing (motor-to-semantic effect). implications of the       results for the embodied and grounded nature of numerical cognition will be       considered and discussed.
individuals are frequently asked to make sacrifices in an attempt       to produce benefits for future generations.  such decisions are referred to as       intergenerational dilemmas.  previous research on intergenerational dilemmas has       shown that situational manipulation of factors such as the delay between       sacrifice and benefits and the perceived similarity with future others modulate       intergenerational preferences.  however, it is unclear whether there are traits       that predict intergenerational preferences across a variety of dilemmas.        individual differences were quantified using econometric measures of delay       discounting and social discounting.  results indicated that individual       differences on these measures accounted for a significant portion of the variance       observed in a broad measure of intergenerational preferences.
linguistic features can predict several aspects of human behavior.       little is known, however, about whether syntactic, semantic and structural       language features can also predict psychological disorders such as posttraumatic       stress disorder (ptsd). the current study investigated whether the linguistic       properties in trauma narratives written by survivors of a motor vehicle accident       (mva), change as function of the intensity of ptsd symptoms. a short form       diagnostic tool known as the posttraumatic stress disorder checklist (pcl) was       used to determine the severity of participant ptsd symptomatology. using a text       capture paradigm participants were then asked to write a neutral narrative or a       narrative that described their traumatic event. pcl scores were compared to       linguistic variables from eight different computational linguistic algorithms.       results from this study suggested that the relative intensity of ptsd       symptomatology affects syntactic, semantic, and structural aspects of the       narrative.
languages differ in the way they package elements of the world       into words, which poses a challenge for bilinguals. we examined word use patterns       for common household objects for late-immersed chinese-english bilinguals to       investigate how the bilingual lexical network develops when the first language is       fully mature at the time of second-language immersion. we found changes to both       first- and second-language word use with increased english dominance, indicating       continued plasticity and mutual influence.  
this study examined whether language structure or language       proficiency might influence students’ use of evaluative language in written       reports, and whether instruction might improve students’ use of evaluative       language. reports in japanese and in english written by second year japanese       university students, who had received instruction in academic discourse       pertaining to critical evaluation, were analyzed for use of evaluative       statements. this revealed no disadvantage for use of the japanese language, which       is considered as having a more indirect structure that may make critical       evaluation more difficult. english proficiency test scores, however, were found       to correlate with production of evaluative statements in english, but not in       japanese, suggesting that inadequate second language proficiency could limit       critical evaluation use. the second year students’ use of evaluative       statements was also found higher than their first year counterparts’ (who       had not yet received instruction), suggesting that such instruction is beneficial       for skills development in both languages.
a wide literature demonstrates that people prefer harm caused by       omissions over equal or lesser harm caused by actions. this omission bias has       been explained referring to several principles, such as causality or       responsibility. a convincing research view has been suggested by sunstein (2005):       harmful acts are generally worse than harmful omissions when moral intuitions       reflect the “do not play god” principle: inactions interfere less       with the “natural order.” in two preliminary studies, we examine the       influence of the “do not play god” principle on individuals moral       preferences, using the switch version of the trolley problem. study 1       demonstrates that our participants’ justifications for their inaction       choice explicitly refer to the intention of not interfering with the       “natural order”. study 2 demonstrates that the presence of stimuli       influencing a reduction of protagonist’s decisional autonomy (e.g. an       authority) activates the “do not play god” principle, leading them to       prefer inaction.
creating autonomous virtual agents capable of exhibiting       human-like behaviour under uncertainty is becoming increasingly relevant, for       instance in multi-agent based simulations (mabs), used to validate social       theories, and also as intelligent characters in virtual training environments       (vtes). the agents in these systems should not act optimally; instead, they       should display intrinsic human limitations and make judgement errors. we propose       a bdi based model which allows for the emergence of uncertainty related biases       during the agent's deliberation process. a probability of success is calculated       from the agent's beliefs and attributed to each available intention. these are       then combined with the intention's utility using prospect theory, a widely       validated descriptive model of human decision. we also distinguish risk from       ambiguity, and allow for individual variability in attitudes towards these two       types of uncertainty. in a travelling scenario, we demonstrate more realistic       agent behaviours can be obtained by applying the proposed model.
we present a computational framework for the detection of unknown       objects in a 3d environment. it is based on a visual attention system that       detects proto-objects which are improved by iterative segmentation steps. at the       same time a 3d scene model is built from measurements of a depth camera. the       detected proto-objects are projected into the 3d scene, resulting in 3d object       models which are incrementally updated. finally, environment- and object-based       inhibition of return enables to withdraw the attention from one object and switch       to the next. we show that the system works well in cluttered natural scenes and       can find and segment objects without prior knowledge.
this study investigates how participants reject an initial rule       when they face positive and negative instances of an initial rule. using eye       movement data, we analyzed a perspective that indicated the type of rules that       participants consider. the results show that, only in negative instances,       participants considered rules from the perspective that they used for finding and       confirming the initial rule. we concluded that, when participants face negative       instances, they tried to change the initial rule peripherally to explain them.       this appeared in the form of a longer consideration from an initial perspective       in negative instances.
the input to a cognitively plausible model of language acquisition       must have the same information components and statistical properties as the       child-directed speech. there are collections of child-directed utterances (e.g.,       childes), but a realistic representation of their visual and semantic context is       not available. we propose three quantitative measures for analyzing the       statistical properties of a manually annotated sample of child-adult interaction       videos, and compare these against the scene representations automatically       generated from the same child-directed utterances, showing that these two       datasets are significantly different. to address this problem, we propose an       interaction-based framework for generating utterances and scenes based on the       co-occurrence frequencies collected from the annotated videos, and show that the       resulting interaction-based dataset is comparable to naturalistic data. we use an       existing model of cross-situational word learning as a case study for comparing       different datasets, and show that only interaction-based data preserve the       learning task complexity.
few studies have investigated multitasking in joint actions,       especially two joint actions performed by two people together and coordinated via       multimodal communication. we investigate the case of two people walking and       talking together, a common combination of joint actions. in an experiment, pairs       talked together in four varying conditions of mobility. a narrator told a story       to a partner. they did this while either standing immobile, walking along a       straight-line itinerary, or walking along a complex itinerary featuring several       turns. they also completed a walking task along a complex itinerary without       having to tell a story. one person (the navigator) was also entrusted with a map       of the itinerary. we analyzed how participants coordinated turning while telling       a story. narrators relied more on verbal means to signal turning, and were more       distracted during the turn, leading to more repetition of story-related content.       
the phenomenon of insight is frequently characterized by the       experience of a sudden and certain solution. anecdotal accounts suggest insight       frequently occurs after the problem solver has taken some time away from the       problem (i.e., incubation).  here we used compound remote associates problems to       examine how incubation affects the subjective experience of insight at different       levels of problem fixation.  we hypothesized that incubation would elicit a       mind-set change resulting in improved problem solving performance regardless of       the initial level of fixation. second, we predicted to the extent that insight       reflects a person’s assessment of mind-set change, the experience of       insight would be more likely after incubation. results were consistent with these       predictions. these findings suggest that the role of incubation in producing       insight may have more to do with changing mind-set than forgetting information       that fixates problem solvers.
this paper presents a reaction time (rt) experiment that follows       on from the work of perruchet, cleeremans, and destrebeceqz (2006), investigating       the extent to which reaction times (rts) are governed by the conscious expectancy       of a particular response. in this experiment, participants were presented with a       single stimulus (which we will call the conditioned stimulus; cs) followed by one       of two outcomes (which we will call unconditioned stimuli; uss); to which       participants had to make an appropriate instrumental response. on every trial we       recorded the time taken to make this response and participants were asked to rate       their expectancy that one of the uss (us1) was going to occur. we found that the       expectancy rating for us1 correlated negatively with rt on us1 trials. over       successive runs of reinforcement, when participants rated us1 as less likely to       occur they were slower to respond to us1 (lower ratings, higher rts). when we       calculated the expectancy for us2 as the complement of that for us1 expectancy,       expectancy of us2 correlated positively with rts. thus, across runs of       reinforcement, participants responded more quickly to us2 when considering us2       less likely (low rating, low rt). we argue that the requirement to make a       conscious expectancy rating results in participants attending more to us1       occurrences than those of us2. this results in a qualitatively different       relationship between conscious expectancy and automatic responses that cannot be       reconciled by a single processing system account. a dual processing system       explanation of learning is proposed to explain these results. in support of this       position, we successfully modeled our us2 rt data using a modified version of the       augmented simple recurrent network (yeates, jones, wills, mclaren, & mclaren,       2013).
during experiments employing perruchet's (1985) paradigm there are       runs of reinforced (cs-us) trials and non-reinforced (cs-nous) trials.       conditioned responding (cr) is measured, for example, using eyeblink responses       (perruchet, 1985), reaction times (perruchet, cleeremans, & destrebeceqz, 2006),       or changes in skin conductance (scr; mcandrew, jones, mclaren, & mclaren, 2012),       as well as an online measure of expectancy for the unconditioned stimulus (us). a       double dissociation between cr and conscious expectancy of the us is typically       found, whereby expectancy of the us decreases while the cr increases across runs       of successively reinforced trials. a gambler’s fallacy explanation can be       offered for the expectancy data, whereas an associative explanation can be used       to explain variations in the cr (consistent with the dual processing theory of       mclaren, green, & mackintosh, 1994). however, skeptics of this effect have       proposed nonassociative explanations of the cr data seen in these experiments.       they note that every cs-us pairing is confounded by the presence of the us.       therefore, it is possible that us sensitization, the phenomenon whereby repeated       us presentations leads to stronger unconditioned responding to the us, could       produce the increasing cr pattern with successive reinforcements (weidemann,       tangen, lovibond, & mitchell, 2009). two experiments are presented investigating       whether us sensitization can explain the recently published electrodermal version       of the perruchet effect.  
theory of mind (tom) is required when reasoning about mental       states such as knowledge, beliefs, desires, and intentions. many complex       reasoning tasks require domain-general cognitive resources such as planning,       resistance to interference, and working memory. in this paper we present a study       of the additional cognitive costs of reasoning about mental states. we presented       participants with sequential games in which they have to reason about another       player. in the so-called player condition, the other player is reasoning about       the participant, whereas in the so-called balance condition, the other player is       reasoning about a balance scale. both types of games require the same       comparisons, but only differ in the required depth of tom reasoning. games in the       player condition require one additional switch between perspectives. the results       show that participants make different types of mistakes in the player condition       as compared to the balance condition. this finding implies a different reasoning       process when reasoning about mental states. the results also show faster       decreasing reaction times in the balance condition than in the player condition.       based on these findings, we argue that reasoning about mental states requires       unique cognitive resources.
the english definite and indefinite articles (also known as       determiners) are a useful index of early morphosyntactic productivity in       children's speech, and give evidence about children's representation of syntactic       abstractions. previous work (i.e. pine and lieven, 1997) used a measure of       productivity that shows a strong sensitivity to sample size and does not account       for the relationship between adult input and children's learning. in this paper,       we develop a more robust metric by employing a hierarchical bayesian model to       characterize the degree of generalization implicit in observed determiner usage.       by inferring parameters for a generative model over longitudinal corpora, we       measure the trajectory of grammatical category abstraction. our results are       consistent with the hypothesis that child learners exhibit adult-like patterns of       generalization quite early in the acquisition of determiners.
the relationship between reasoning and language has been       frequently studied. here we explore principles of spatial reasoning in germans       and russians. we compared the performance of russians in three different settings       to the performance of germans. the task was to construct layouts of wooden blocks       according to verbal instructions, describing the relations of these blocks.       subsequently pieces of new information, introduced as incontrovertible facts and       partly contradicting the initial descriptions, were given. participants       re-arranged the blocks to take into account the new facts. recent research       conducted with germans has shown that – although alternatives are logical       equivalent - there are preferences for certain solutions. the question was       whether russians show the same or different preferences. our results suggest that       construction and revision of spatial models follow similar principles. however,       we observed differences between the groups regarding the flexibility to apply a       principle based on the order of words in a sentence.
experiment 1 demonstrates that problem solving knowledge can be       applied while a move is in progress in certain tower of london (tol) problems.  a       two-stage move process is often delayed in the second stage when participants       have been misled by similarity to a previous problem.  we suggest this is       indicative of misgivings about the chosen move caused by on-going analysis of the       move that is being made. experiment 2 swapped the stages of the two-stage process       and again reported more hesitancy in the second stage when participants had been       misled.  we conclude that it is desirable for models of problem solving to evolve       so that they can apply the same learned problem solving knowledge both before a       move is selected and while the move is being made.  we then describe a model of       tol problem solving that fulfills these criteria and has been       computationally-implemented within an embodied cognitive architecture.
explanations in cognitive science rely predominantly on       computational modeling. though the scientific practice is systematic, and there       is little doubt about the empirical value of numerous models, the methodological       account of computational explanation is not up-to-date. the current paper offers       a systematic account of computational explanation in cognitive science in a       largely mechanistic framework. the account is illustrated with a short case study       of modeling of the mirror neuron system in terms of predictive coding.
performing inductive generalizations is critical for learning, yet       there is much debate regarding the mechanisms underlying this ability. one view       posits that similarity-based induction, utilizing perceptual features, may allow       for increased encoding and higher memory accuracy on recognition tests. while       category-based induction, utilizing semantic information, may result in limiting       encoding of perceptual detail, thus resulting in decreased memory accuracy. in       experiment 1, we attempted to impair spontaneous categorization by presenting a       second working memory load task. in experiment 2, we attempted to impair       perceptual processing by introducing a second visual search task. results       indicate that adult participants can rely on either mechanism when performing       induction.  
does the typicality of an object affect how we identify it? when       we produce initial reference to a visible object, we are influenced by a variety       of factors, including what is visually salient (bottom-up influences) as well as       our previous experiences with the object (top-down influences). in this study, we       seek to understand how the top-down influence of typicality affects initial       reference to an object. we use real world, every-day objects, and focus on the       visual properties of shape and material. our findings suggest that there is a       tendency to select the atypical over the typical. but we have only begun to       scratch the surface of understanding reference to real world objects. the       annotated corpus from this study is made available for future research on       modeling reference in visual domains.
stoic behavior is defined as a behavior in which students tend not       to seek help with a challenge. we investigated two types of stoic behavior:       keeping-off behavior, in which students restrain themselves from requesting help,       i.e., keep levels of help support at a minimum, and self-fading behavior, in       which students voluntarily lower levels of support on their own volition. three       experiments were conducted. overall, results showed that the participants       actually exhibited stoic behavior when learning in an actual classroom setting.       self-fading was more difficult than the keeping-off behavior. the participants       who maintained levels of support at a minimum through exhibiting active       keeping-off behavior achieved greater learning gains, suggesting that stoic       behavior resulted in positive impacts on learning. however, our experiment did       not detect this effect for self-fading behavior. these experimental results were       discussed with the assistance dilemma problem, generally occurring in instruction       by intelligent tutoring systems.         
in two self-paced reading experiments, subject relative clauses       (e.g., ‘the woman who saw the man’) were read faster than       object relative clauses (‘the woman who the man saw’) in       japanese. previous formulations of working-memory factors       do not predict the patterns observed. a preference to complete       fragments as object relative clauses indicates that ambiguity       and expectation are unlikely to explain the reading-time data.       the results support the proposal that accessibility of the position        relativized affects how natural the relative clause is as a       statement about the modified noun.       
sound symbolism or the nonarbitrary link between language sound       and meaning are commonly found across many languages of the world. a well-known       example is the association between rounded vs. angular shapes and labels (i.e.,       köhler, 1929/1947).  previous research has shown that sound symbolic words       play facilitative role for preschool children’s novel verb learning,       helping children identify what aspects of motion events should be mapped to       verbs. in this research, we explore whether sound symbolism may facilitate       language learning in human infants who have just begun to learn word meanings.       sound symbolism may be a useful cue particularly at the earliest stages of word       learning, because this cue seems to be available without needing prior word       learning experience. using a habituation paradigm and a bayesian model-based       analysis, we demonstrated that 14-month-old infants could detect köhler-type       (1947) shape-sound symbolism, and could use this sensitivity in their effort to       establish the word-referent association.
people's estimations of how certain speakers are of their       knowledge (foak) match speakers' own estimation (fok) of how certain they are       (brennan & williams, 1995). this is because others can interpret the verbal and       nonverbal cues of (un)certainty that a speaker displays (brennan & williams,       1995; swerts & krahmer, 2005). estimating another's certainty thus seems to be       driven by the bottom-up processing of speaker-displayed cues. in this paper, we       explore the top-down influence of beliefs about a speaker on judgments of a       speaker's certainty. in a perception study, we varied whether a speaker's       proclaimed profession would make him an expert or a novice on the topic he was       questioned on. such beliefs were shown to influence participants' ratings of the       speaker's certainty, in addition to speaker-displayed cues. thus, next to the       bottom-up processing of speaker-displayed cues, the top-down processing of       beliefs about a speaker influences judgments of others' certainty.
a high degree of self-disclosure in online social networks (osns)       is associated with several risks. this raises an important question: why       don´t many users protect their personal data more eagerly? we propose that a       lack of memory for what information has been disclosed to which audience       contributes to this privacy-neglecting behavior in osns. we transferred the       paradigm of target monitoring to a fictitious osn and varied the degree of risk       associated with self-disclosure. in a 2x2 experiment we varied both audience size       (large vs. small) and information intimacy (personal vs. non-personal). we used       recognition tests for the association of audience and disclosed information to       assess memory performance. results show that item memory (the memory for what       information has been disclosed) exceeded target memory and that target memory       improved in vulnerable situations (for large audiences and personal information).       our findings widen the realm of offline memory research and expand our knowledge       about which cognitive factors impact privacy-related behavior in online       environments.
music is known to have a profound impact on human cognitive and       emotional response, which in turn are strongly correlated with physiological       mechanisms. this paper presents a system that is designed to create original       musical compositions that elicit particular physiological responses. the       experiments described below demonstrate that the music generated by this system       is as effective as human-composed music in effecting changes in skin resistance,       skin temperature, breathing rate, and heart rate. the system is particularly       adept at composing pieces that elicit target responses in individuals who       demonstrated predictable responses to training selections.
we model the semantic recall sequences of 424 older adults aged       between 69 to 103 years in the animal fluency task. our results suggest that,       under normal intellectual functioning,   memory search in old age (69–84       years) is consistent with a dynamic process that switches between retrieval       probes. with dementia and very old age (85–103 years), however, memory       search seems to become more consistent with a static process that activates items       in memory as a function of their frequency. the weight that probes have in       determining the activation of items in memory seems to be an informative       signature of the impact of healthy aging and dementia on memory search. our       results show that, with healthy aging and dementia, the activation of items in       memory is increasingly more determined by the frequency of past experience with       those items.
in this study, we tested the hypothesis that social relationships       affect the perception of distance. when participants imagined passing through a       wall and a disliked-person, they perceived shorter aperture widths than when they       intended to pass between a wall and a liked-person. this result was observed only       for passable apertures suggesting that social constraints may influence visual       perception only when people can actually perform this action. we discuss the       results according to an embodied approach to visual perception but also with an       alternative explanation in terms of possible demand characteristics. we also       discuss some methodological points supposed to improve the validity of such       experiments. 
according to margaret gilbert, a joint commitment (jc) is a       commitment of two or more agents, called the parties of the jc, to engage in a       common project. creating a jc often involves an explicit agreement, carried out       in a conversa-tional interaction through overt communication. we ex-plored       aspects of such interactions that can be considered as complementary to verbal       exchanges, focusing on how a jc is managed by the parties by means of emotional       and other non-verbal bodily expressions. we analyzed three phases of the jc       lifecycle (creation, maintenance, and violation), and in particular the emotional       reaction of the participants to two types of violations by the experimenter. in       our analysis we used standardized tools such as the ethological coding system for       interviews, the mind reading emotional library, and the facial action coding       system. our results show that certain non-verbal behaviors in the phase of jc       creation are characteristic of the participants who later did not fulfill their       commitment. moreover, the participants’ emotional reactions to jc violation       by the experimenter turned out to depend on the type of violation. finally, the       creation and maintenance of jc, and the emotional reaction to its violation,       appear to be independent of the participants’ personality and empathic       disposition.
prior research has shown that children hold a belief in causal       determinism - the belief that all events are caused – by 4 years of age.        in this study we investigate the developmental origins of this belief.  we showed       toddlers (24 months) a spontaneous or explained novel physical outcome (a toy       that lit up either spontaneously or upon contact from an experimenter) and then       showed them an additional candidate cause (pressing a button) while obscuring the       outcome.  we asked whether toddlers inferred that the two components (the button       and the outcome) were causally linked.  we found that toddlers represented the       candidate cause as the cause of the novel outcome only when the event       spontaneously occurred (experiments 1-2), and that children spontaneously       searched for plausible causes of unexplained outcomes (experiment 3).  these       results suggest that toddlers, like older children, believe physical events have       causes, and that this belief supports exploration and discovery. 
in the present research we analyze the interrelations of spatial       distance and efficaciousness in helping needy others, and we investigate how       these factors affect our judgments of moral helping obligations. the main       question is under which conditions the location of an agent’s means of       helping relative to a victim is regarded as morally relevant. we develop a new       experimental design that allows us to test our hypotheses concurrently in both       separate and joint evaluation modes using a constant procedure across groups. we       find that spatial proximity of an agent’s means to a victim increases       people’s sense of obligation only to the extent to which it is indicative       of increased efficaciousness or personal involvement.
jones and rachlin (2008) found that the amount of money a person       is willing to forgo in order to give $75 to another person decreased as a       hyperbolic function of perceived social distance, in the same way as occurs in       intertemporal choice. this study aimed to extend this finding to the domain of       social networks, in which social distance is defined by degrees of separation. a       total of 334 participants responded to tasks very similar to those in jones and       rachlin (2008), except that they were required to choose whether they would       prefer to receive an amount of money for themselves only or an amount of money       for themselves and a person who is n degrees of separation from them up to six       degrees. the results show that the hyperbolic function fit the data well, and       that several processes appear to contribute to the judgments made in the       experimental tasks.
we report an experiment in which a change in the context of a       stock-flow reasoning problem leads to a 44% reduction in the use of an erroneous       ‘correlation heuristic’ response. in its original context – a       global warming scenario – the majority of participants pattern-match the       output of a system to its inputs (i.e., use a correlation heuristic). in the       changed context – financial debt management – the majority reason       correctly that in-flows and out-flows must converge to stabilize stock. potential       applications for improving communication of climate change science are       discussed.
models of risky choice have attracted much attention in       behavioural economics. previous research has repeatedly demonstrated that       individuals' choices are not well explained by expected utility theory, and a       number of alternative models have been examined using carefully selected sets of       choice alternatives. the model performance however, can depend on which choice       alternatives are being       tested. here we develop a non-parametric method for estimating the utility map       over the wide range of choice alternatives. the estimated maps are compared       against the three of the most well-known models of risky choice: expected utility       theory, cumulative prospect theory, and the transfer of attention exchange model.       model comparison indicates that cumulative prospect theory provides a better       prediction of individuals' choices, but the estimated maps show that the overall       shape of utility map is different from what the model predicts.
decision making from sequential sampling, especially when more       than two alternative choices are possible, requires appropriate stopping criteria       to maximize accuracy under time constraints. optimal conditions for stopping have       previously been investigated for modeling human decision making processes. in       this work, we show how the k-nearest neighbor classification algorithm in machine       learning can be utilized as a mathematical framework to derive a variety of novel       sequential sampling models. we interpret these nearest neighbor models in the       context of diffusion decision making (ddm) methods. we compare these nearest       neighbor methods to exemplar-based models and accumulator models, such as race       and lca. computational experiments show that the new models demonstrate       significantly higher accuracy given equivalent time constraints.
we noticed that human subjects were notably faster and more       accurate in concurrent counting of three location-based events while they ignored       the identity of targets, compared to concurrent counting of three identity-based       events while they ignored the locations. in a control experiment, subjects       performed a location-based triple counting task, while now also paying attention       to the target identity. this did not incur any additional cost, compared to the       cost of the location-based counting. performing each of these tasks relies on       maintaining three running numerical counters, and on switching between them to       increase each one. our results suggest that switching between these counters has       lower cost when they are associated to spatial locations, compared to when they       are associated to identities. this difference is not affected when additionally       processing the identity of items. we argue that this might be related to the       advantage of the space in switching attention between internal       representations.
we measured the sensitivity in detecting a change in the location       of one of two visual targets over a short period of time to investigate the       impact of a secondary intellectual symbolic wm task on the visuospatial       short-term memory, in a dual-task paradigm. we observed that engaging in a wm       task that involves manipulation of symbolic information impacts the ability to       detect a location change, and this impact does not change when more time is       allocated to the wm task. furthermore, we observed that the impact of a mental       sorting task on the ability to detect location changes is spatially selective to       the horizontal orientation.  our results suggest a possible role for       sensory-motor working memory, which supports perception-action schemas in       manipulation of information during the intellectual symbolic working memory       tasks.
negation is one of the most important concepts in human language,       and yet little is known about children’s ability to comprehend negative       sentences. in this experiment, we explore how children’s comprehension of       negative sentences changes between 2- to 4-year-old children, as well as how       comprehension is influenced by how negative sentences are used. children between       the ages of 2 and 4 years watched a video in which they heard positive and       negative sentences. negative sentences, such as “look at the boy with no       apples”, referred either to an absence of a characteristic or an       alternative characteristic. older children showed significant improvements in       speed and accuracy of looks to target. children showed more difficulty when the       negative sentence referred to nothing, compared to when it referred to an       alternative. in addition, children showed an early tendency to look towards the       named noun, even when that noun was negated. this study contributes to our       understanding of children’s comprehension of negative sentences, as well as       our understanding of the conceptual structure of negation.
recent studies show controversial results on the trainability of       working memory (wm) capacity being a limiting factor of human cognition. in order       to contribute to this open question we investigated if participants improve in       trained tasks and whether gains generalize to untrained wm tasks, mathematical       problem solving and intelligence tests.        83 adults trained over a three week period (7.5 hours total) in one of the       following conditions: a high, a medium or a low wm load group. the present       findings show that task specific characteristics could be learned but that there       was no transfer between trained and untrained tasks which had no common elements.       positive transfer occurred between two tasks focusing on inhibitory processes. it       might be possible to enhance this specific component of wm but not wm capacity as       such. a possible enhancement in a learning test is of high educational interest       and worthwhile to be investigated further.
this paper studies how visual perception of a scene is affected by       cognitive processes beyond the scene's bottom-up saliency. the game of set is       taken as an example where contrast-based salient parts of a scene are ignored in       favor of a larger group of similar elements. using results from a laboratory       experiment and a model simulation we explain how three cognitive mechanisms,       differential acuity, visual iconic memory and declarative retrieval, considered       together help to explain player's visual perception in set.
most studies examine holistic processing with respect to facial       identity, but at least one study has also looked at holistic processing of facial       expressions (calder, young, keane, & dean, 2000). however, this work used the       partial composite paradigm, which is known to exhibit bias effects (richler,       cheung, & gauthier, 2011). the complete composite paradigm (gauthier & bukach,       2007) provides a bias-proof way to quantitatively measure holistic processing. in       this paper, we perform the corresponding experiment in our face processing model       (empath, (dailey, cottrell, padgett, & adolphs, 2002)) to predict whether       holistic processing of facial expressions will be found if the corresponding       human experiments are performed, and our prediction is that it will. we also       compared our model’s performance to the participants in recent experiments       in facial expression recognition in humans (tanaka, kaiser, butler, & le grand,       2012). tanaka et al. (2012) concluded that expression recognition is not always       holistic, but our results suggest that it is.
interpretation of a pronoun is driven by properties of syntactic       distribution. consequently, acquiring the meaning and the distribution are       intertwined. in order to learn that a pronoun is reflexive, learners need to know       which entity the pronoun refers to in a sentence, but in order to infer its       referent they need to know that the pronoun is reflexive. this study examines       whether discourse information is the information source that the learner might       use to acquire grammatical categories of pronouns. experimental results       demonstrate that adults can use discourse information to accurately guess the       referents of pronouns. simulations show that a bayesian model using guesses from       the experiment as an estimate of the discourse information successfully       categorizes english pronouns into categories corresponding to reflexives and       non-reflexives. together, these results suggest that knowing which entities are       likely to be referred to in the discourse can help learners acquire grammatical       categories of pronouns.
in his seminal dissertation, henson (1996) identified a number of       constraints on theories of serial order memory. two constraints, the fill-in       constraint, in which an item that is erroneously recalled early is likely to be       followed by its predecessor rather than its successor (recall of acb is more       likely than acd), and the protrusion constraint, in which prior list intrusions       are likely to be recalled in the same output position as their previous serial       position, were considered evidence against chaining theories. we present results       from two experiments which investigate the extent to which these effects are       dependent on experimental methodology. when participants are given an open set of       items, an equal ratio of fill-in and in-fill errors was observed and a protrusion       effect was obtained. however, when a reconstruction of order task was used, a       fill-in effect was observed. implications for theories of serial order memory are       discussed.
a robust empirical regularity in decision making is that the       negative consequences of an option (i.e., losses) often have a stronger impact on       people’s behavior than the positive consequences (i.e., gains). one common       explanation for such a gain-loss asymmetry is loss aversion. to model loss       aversion in risky decisions, prospect theory (kahneman & tversky, 1979) assumes a       kinked value function (which translates objective consequences into subjective       utilities), with a steeper curvature for losses than for gains. we highlight,       however, that the prospect theory framework offers many alternative ways to model       gain-loss asymmetries (e.g., via the weighting function, which translates       objective probabilities into subjective decision weights; or via the choice       rule). our goal is to systematically test these alternative models against each       other. in a reanalysis of data by glöckner and pachur (2012), we show that       people’s risky decisions are best accounted for by a version of prospect       theory that has a more elevated weighting function for losses than for gains but       the same value function for both domains. these results contradict the common       assumption that a kinked value function is necessary to model risky choices and       point to the neglected role of people’s differential probability weighting       in the gain and loss domains.
previous studies of semantic implicit learning in language have       only examined learning grammatical form-meaning connections where learning could       have been supported by prior linguistic knowledge. also, these studies assessed       awareness by verbal report, which is arguably not the most reliable measure. here       we target the domain of verb meaning, specifically semantic preferences of novel       verbs (e.g. a novel verb takes abstract objects). using a reaction time       methodology we show that after exposure to correct verb-noun combinations,       reaction times to incorrect combinations are slowed down even for participants       who are unaware of the semantic regularity. this effect was also obtained even       when the semantic regularity was irrelevant to the tasks being performed,       suggesting that the semantic generalisation is learned and exerts its influence       automatically, hence satisfying one criterion for implicitness. combined with a       lack of verbalisable knowledge in any participant these experiments provide       strong evidence for semantic implicit learning in language. 
in general, young children focus on holistic similarity and older       children focus on dimensional similarity (selectively attending to one property,       such as brightness, to the exclusion of others, such as size). research on early       word learning, however, suggests the process of learning words trains attention       to category-relevant dimensions. we ask: does word learning scaffold dimensional       attention more generally? by showing labels support dimensional attention, these       results clarify the processes involved in similarity perception and unify our       understanding of attentional processes in word learning with those in a broader       context. 
a remarkable property of human cognition is the systematic       co-occurrence of certain cognitive abilities. one challenge for cognitive science       is to determine the (computational) principles that derive this property as part       of a broader goal of establishing the foundations of cognitive architecture (i.e.       the basic processes and modes of combination affording cognitive capacity) for a       science of cognition. this paper continues a category theory approach to       compositionality and cognitive capacity that posits universal construction (e.g.,       products) as a fundamental cognitive architectural component. as shown here,       products can be modeled in other frameworks, thereby providing a link between an       abstract computational principle and a concrete cognitive resource needed for       particular capacities. for example, a network of weighted connections       implementing a categorical product uses fewer resources when the number of task       instances sharing a common product structure is greater than two; otherwise it is       more economic to realize each instance independently. this cross-over may explain       why human cognition is not always systematic: the cost of universal construction       may not outweigh its expected gain.
most computational models of analogy assume they are given a       delineated source domain and often a specified target domain.  these systems do       not address how analogs can be isolated from large domains and spontaneously       retrieved from long-term memory, a process we call spontaneous analogy.  we       present a system that represents relational structures as feature bags.  using       this representation, our system leverages perceptual algorithms to automatically       create an ontology of relational structures and to efficiently retrieve analogs       for new relational structures from long-term memory.  we provide a demonstration       of our approach that takes a set of unsegmented stories, constructs an ontology       of analogical schemas (corresponding to plot devices), and uses this ontology to       efficiently find analogs within new stories, yielding significant time-savings       over linear analog retrieval at a small accuracy cost.       
concepts of kinds of things (e.g. dog), have the dual function of       specifying how to think about indefinitely many things as well as providing the       means for thinking about a single abstract kind which is constituted by       indefinitely many instances.  in this talk, i sketch a theory of conceptual       representation that places this dual function of concepts at its core.  the       theory is shown to provide a natural way of capturing four key characteristics of       the ways in which we think about kinds and instances of kinds.  these       characteristics are not accounted for by standard approaches to conceptual       representation.  in the final section of the paper, i consider how the phenomena       discussed in this paper may be accommodated by current approaches to conceptual       representation. 
many conceptual change theories posit that change occurs when the       learner becomes dissatisfied with the current conception (ohlsson, 2011; strike &       posner, 1992). a necessary component of dissatisfaction is falsifying feedback.       the present experiments investigate whether participants exposed to a novel       method for eliminating the ability to directly falsify a misconception will still       be able to recategorize compared to participants that can directly falsify. the       results suggest that direct falsification of a misconception is not necessary for       recategorization, and that direct falsification may slow the learning process.       implications are discussed.  
proper name systems provide individuals with personal identifiers,       and convey social and hereditary information. we identify a common information       structure in the name grammars of the world’s languages, which makes this       complex information processing task manageable, and evaluate the impact that the       re-engineering of naming practices for legal and political purposes has had on       the communicative and psychological properties of these socially evolved systems.       while east-asian naming systems have been largely unaffected by state       legislation, legal interference has transformed western naming practices, making       individual names harder to process and remember. further, the structural collapse       of western naming systems has not affected all parts of society equally: in the       us, it has had a disproportionate impact on those sections of society that are       least successful in economic and social terms. we consider the implications of       these changes for name memory across the lifespan, and for future naming       practices.
the goal of this study was to investigate the translate-ability of       creative works into other domains. we tested whether people were able to       recognize which works of art were inspired by which pieces of music. three expert       painters created four paintings, each of which was the artist’s       interpretation of one of four different pieces of instrumental music.       participants were able to identify which paintings were inspired by which pieces       of music at statistically significant above-chance levels. the findings support       the hypothesis that creative ideas can exist in an at least somewhat       domain-independent state of potentiality and become more well-defined as they are       actualized in accordance with the constraints of a particular domain.
we present a biologically based neural model capable of performing       reinforcement learning in complex tasks.  the model is unique in its ability to       solve tasks that require the agent to make a sequence of unrewarded actions in       order to reach the goal, in an environment where there are unknown and variable       time delays between actions, state transitions, and rewards.  specifically, this       is the first neural model of reinforcement learning able to function within a       semi-markov decision process (smdp) framework.  we believe that this extension of       current modelling efforts lays the groundwork for increasingly sophisticated       models of human decision making.
difficulty with social interactions is a hallmark characteristic       of autism spectrum disorders. while many studies have investigated the neural       mechanisms underlying atypical social cognition, the methods used have rarely       involved social interaction, relying instead on offline reasoning about a       character. in the current study, we examined whether and which brain systems are       sensitive to online social interactions in individuals with autism. we compared       functional mri data collected from 15 neurotypical (nt) and 15 autism spectrum       disorder (asd) participants during live real-time interactions (live) and during       a video replay of the same interaction (recorded-same) and a novel interaction       (recorded-novel). whole brain analyses demonstrated a significantly greater       response to live than recorded conditions, in nt vs asd, within left posterior       superior temporal sulcus (psts) and regions of the cerebellum bilaterally. region       of interest analyses revealed that right posterior temporal regions were       differentially recruited during online social interactions in the asd and nt       groups. also, regions commonly associated with personal salience (i.e., dorsal       anterior cingulate and bilateral insula) were sensitive to online social       interactions in nt, but to novelty in the asd group. these data suggest reduced       and atypical neural sensitivity to online social interactions in individuals with       autism. 
in a congestion game, individuals exhaust a common resource out of       selfish behavior. in this scenario, drivers create traffic jams by choosing the       shortest route according to their individual knowledge.  they can avoid them by       communicating their belief states about the traffic situation in real-time       through a peer-to-peer network, assuming unlimited bandwidth.  we study two       potential, cognitively inspired models of human behavior: 1) categorization       (quantized memorization and communication), which dampens communication and       belief adoption, but leads to undesired oscillations and lower performance. 2)       instance-based blending with memory decay, which achieves good dynamics and       near-optimal performance without the same bandwidth needs.  we argue that this       supports our hypothesis of co-adaptation of cognitive function and communicating       communities.
the current study examines the generalization of the category       adjustment model (cam) across scales along two dimensions: time and distance.       participants were presented with geologic time and astronomical distance       information either conventionally or using the hierarchical alignment model.       participants provided with hierarchically structured magnitude information for       time and distances were more accurate on similar estimations at large scales than       participants given the same content in a conventional manner. patterns in event       and distance estimation, along with overall group differences, are consistent       with the cam; suggesting people use hierarchically organized categorical       information when estimating across scales and dimensions, and providing salient       category boundary information improves estimation. findings suggest a common       representation of scale information for temporal, spatial, and abstract (numeric)       magnitudes. patterns of abstract magnitude estimations are consistent with       segmented linear models of scale representation. implications of the cam in scale       representation and the hierarchical alignment model in education are       discussed.
this experiment sought to explore the theory that familiar english       words are processed similarly to objects. to do this, we looked for object-based       attentional facilitation where cues in a different location to the target still       facilitate target detection as long as they are inside the same object.       participants were shown two english words in an array, and cues and targets were       embedded inside them. reaction times for target detection were measured. it was       found that in horizontally presented english words, cues presented in a different       location to the target still facilitated target detection if they occurred inside       the same word. this was not the case for vertically oriented words. it was       concluded that familiar words in a familiar orientation are indeed processed in a       similar way to objects. these findings may be indicative that the cortical       networks that evolved for object processing are also involved in the processing       of words.
the artificial neural network class of self-organizing maps (soms)       is a powerful and promising cognitive modeling tool in the study of the brain and       its disorders. under this premise, this paper proposes a novel modification of       the standard som algorithm in the form of an oscillating topological neighborhood       (tn) width function. existing research in neuroscience indicates that soms with       oscillating tn width could exhibit higher biological plausibility than standard       tn width soms. in this paper, two neuro-developmental disorders, autism and       schizophrenia, are modeled, based on existing neurocomputational theories, using       both som approaches. the simulation results demonstrate that there is significant       equivalence between standard and oscillating tn width som modeling in terms of       map formation behavior, output and structure. the theoretical and computational       arguments presented validate the proposed som modification within a cognitive       modeling framework.
verbal analogies produced during naturally occurring instructional       discourse in mathematics were explored using techniques borrowed from studies of       language in use (see wortham & rymes, 2003). close examination of two       eighth-grade instructional analogies reveals that the language practices of       analogy are instrumental in shaping recipients’ relational       re-representation of objects being compared, in particular through markers of       indexicality and poetic parallel structure. at the same time, close examination       of the communicative interactions reveals that these devices may reduce the       burden on recipients’ reasoning to the point that they may appear       successful at solving the verbal analogy, but their responses can be explained by       facility in verbal interaction rather than in mathematical reasoning. these data       provide thereby new insights into the “analogical paradox,” the       finding that analogies are commonly successful as vehicles for interactionally       producing and displaying understanding of new information in everyday contexts       but generally problematic when measured for their effects on reasoning in       controlled laboratory settings (dunbar, 1998). we identify a tension between       interactional and cognitive success of everyday communicative analogies, meaning       that those that are most likely to be interactionally successful may lead to less       cognitive engagement for analogy recipients.
combinatoriality---the recombination of a small set of basic forms       to create an infinite number of meaningful units---has long been seen as a core       design feature of language, but its origins remain uncertain. two hypotheses have       been suggested. the first is that combinatoriality is a necessary solution to the       problem of conveying a large number of meanings; the sec- ond is that it arises       as a consequence of conventionalisation. we tested these hypotheses in an       experimental-semiotics study. our results supported the hypothesis based on       conventionali- sation but offered little support for the hypothesis based on the       number of meanings.
miscommunication is often regarded as noise or uninformative in       psycholinguistic research. however, coupland et al. (1991) suggest that       miscommunication can provide rich information about how interlocutors come to       communicate successfully. successful communication necessarily needs the       individuals involved to coordinate and update their mutual knowledge,       experiences, beliefs, and assumptions. however, the process of updating this       information may be ridden with unsuccessful attempts that eventually help       interlocutors reach a common goal. this study evaluates the relative contribution       of linguistic factors to communicative success, based on verbal grounding (e.g.,       mutual agreement on a referent) and visual congruency (e.g., interlocutor’s       visual environments match or mismatch) during a collaborative task. we show that       varying levels of communicative success are laden with rich linguistic       information that may uncover interesting aspects of successful and less       successful communication. 
the current experiment investigated the effects of target size and       symmetry on the dynamics of precision aiming. participants were asked to sit on a       chair and point at the center of four different targets (a small and big square       target, and a horizontal and vertical rectangular target). the aiming movements       were assessed using linear (root mean square) and non-linear fractal statistics       (dfa and mfdfa). we found that participants spontaneously exhibited more movement       in target dimensions with less spatial constraint (i.e., larger target       dimensions). these larger movements, however, were more deterministic than the       movements accompanying the smaller targets, indicating that more variation in       aiming does not necessarily mean more random. finally, even though       participants’ movements were multifractal, the different manipulations and       task constraints had no effect on the width of the multifractal spectrum. these       results suggest that human performance emerges from the complex relationship and       interactions that exist between the perception and action capabilities of the       human body and the physical environment.
spatial cognition research has recently made much progress in       understanding the cognitive representations and processes underlying human       wayfinding. many theoretical assumptions about the concept of landmark salience       have been established. in this context it is important to define perceptual (or       visual) and structural landmark salience. structural salience is defined as the       position of a landmark at an intersection. perceptual salience is defined as the       visual characteristic of a landmark. it must “stand out” from its       surrounding to be perceptually salient. we investigated the influence of       perceptual salience and the combination of perceptual and structural salience in       landmark selection. we show for a spatial arrangement of four objects that the       different object is preferred almost always. if the same spatial arrangement is       interpreted as an intersection with a directional information, the       participants’ preference is influenced by structural as well as perceptual       salience. findings are discussed within the context of landmark salience.
influential work on human thinking suggests that our judgment is       often biased because we minimize cognitive effort and intuitively substitute hard       questions by easier ones. recent work with adults who solved the bat-and-ball       problem, one of the most publicized examples of the substitution bias, suggests       that people realize they are doing this and notice their mistake. in the present       paper we look at the development of this substitution bias sensitivity. a group       of young adolescents solved standard and isomorphic control versions of the       bat-and-ball problem in which reasoners experience no intuitive pull to       substitute. adults have been shown to be less confident in their substituted,       erroneous bat-and-ball answer than in their answer on the control version that       does not give rise to the substitution. however, the present study established       that this critical confidence drop was less pronounced for young adolescents.       this implies that in contrast with adults, young adolescents do not yet fully       acknowledge the questionable nature of their biased answer and remain more       oblivious to the substitution. that is, young adolescent reasoners seem to behave       more like happy fools who blindly answer erroneous questions without realizing       it. 
this study evaluates how people represent “even if”       conditionals when they have to integrate them with previous “if then”       conditionals and also make an inference. the terms in the premises were ordered       to facilitate their integration (figure 1: if a then b; even if b c). in half the       cases, the “even if” conditional was expressed with a negation       instead of an affirmation (if a then b; even if not b c). participants had to       infer what followed, given a or c. previous results showed that in comprehension       tasks, where information had to be integrated, counterfactual conditionals seemed       to be represented with just one situation (b and c). by contrast, when people had       to make inferences with these conditionals, they seemed to represent two       situations. in any case, counterfactual seem to be represented with two       situations (b and c, and not b and c). in our task, people had to do both: to       infer and to integrate. results showed that the use of negations and the       direction in the inference had an effect on the endorsed inferences, but the two       factors did not interact. the need to integrate premises did not block access to       the two “even if” situations in an inference task       
there are certain theoretical issues in conceptual change research       that are still puzzling researchers. first, there is no agreement on what kinds       of changes in belief and concept systems constitute conceptual change. second,       there is no consensus on what the mechanisms of conceptual change are. third,       there is no common understanding how to explain, model and describe in an exact       way these underlying mechanisms. in this paper, we offer a diagnostic analysis       these issues by reviewing current theories of conceptual change in a framework of       mechanistic explanations of cognitive phenomena, and present a possible sketch       for explanations of conceptual change
parallel distributed processing (pdp) models have been widely used       for modeling cognitive tasks where accuracy or reaction time were the dependent       performance measures. however, only few pdp models have attempted to model more       brain-related data like event related potentials (erps). in this paper, we take a       step towards using erp data for model fitting by proposing a pdp model, which can       successfully replicate various known erp effects. specifically, we introduce a       pdp-equivalent of the n400 erp measure and apply it to a simple pdp model of       early bilingual word acquisition as bilingual word acquisition tasks provide       several well-established n400 effects that can be used for model validation. we       then analyze the dynamics of the network to show why and how the network can       capture each of the targeted n400 effects. furthermore, we qualitatively compare       model-generated and empirical n400 peak values for l2 words.
language use is an important part of a negotiation. prior research       has shown that similarity in language use is conducive to reaching agreements.       this paper uses latent semantic analysis to explore how the similarity of       language use develops and changes over the time course of a three-party       negotiation. results support theories that suggest that a gradual alignment of       semantic representation increases the likelihood that parties will form a       coalition.
recent studies have shown that people use covariation information       to infer causal structure. however, there is little information about how people       derive causal directionality from covariation. the present study is designed to       provide further evidence about the role of covariation in causal structure       learning. in experiment 1, where covariation between two variables was       systematically manipulated, participants were asked to observe the states of       bacteria (present or absent) and to infer their causal relationship. we found       that judgments of causal structure varied as a function of covariation, and that       participants interpreted covariation according to necessity of causation. in       experiment 2, participants who received information about high causal strength       interpreted covariation according to sufficiency of causation. these results       demonstrate that prior knowledge modulates interpretation of covariation and       suggest that domain-general covariation information and domain-specific prior       knowledge of causal relations interact in causal structure learning.
in this paper we investigate the effect of power on prosocial       decision-making. while previous research has thoroughly investigated this       relation in western cultures, we focus our research on the role of power in an       understudied middle-eastern culture. existing literature suggest an inverse       relationship between feeling of power and prosocial behavior, where generally       people in high levels of power tend to act less sympathetically in their       decisions and demonstrate declined levels of perspective taking towards others.       our findings demonstrate that, unlike their western counterparts, iranian       participants show significantly higher levels of altruism when in a high-power       situation perceived as legitimate. on the other hand, under illegitimate power       conditions, participants primed with high-power act significantly less       compassionately in comparison to their low-power counterparts. we believe these       findings have great impact in studying social hierarchies and behavior in       cross-cultural settings.
past studies have indicated that intonation, in the sense of       fundamental frequency modulation, can only enhance serial recall to the extent       that it can induce a grouping effect, something that can also be induced by a       simple insertion of pauses. however, in a study of spoken serial recall of       nine-digit lists, we are able to show that recall is significantly better when       sequences of digits are marked by specific intonation contours than when they are       simply grouped by silent pauses in the signal. thus, we found that intonation       plays a role during the encoding phase, whereby items in group-final positions       draw particular benefit from intonation.  however, intonation does not appear to       play the same role in the retrieval phase, since when subjects are instructed to       imitate intonation during recall, performance shows mixed effects.
dual-process models of categorization posit dissociable implicit       and explicit category learning systems. evidence in favour of these accounts is       typically obtained by examining how categorization responses differ over time,       with differing category structures, and by changing task demands. if these two       categorization systems are activated concurrently (e.g., covis) then both       implicit and explicit representations can be examined over the course of learning       even when one system dominates category response selection. in the current study,       we used subjective measures of performance (i.e., confidence reports) to       continuously sample from a participant’s explicit representation of the       category structure while also examining changes in these reports over the course       of training. using category structures that motivate the acquisition of either       explicit or implicit representations, we observed differences in confidence       reports that did not correspond to changes in categorization accuracy. these       findings provide evidence for categorization systems that contain different       representations.
in a world of limited resources, scarcity and rivalry are central       challenges for decision makers. we examine choice behavior in competitive       probability learning environments that reinforce one of two strategies. the       optimality of a strategy is dependent on the behavior of a computerized opponent:       if the opponent mimics participant choices, probability matching is optimal; if       the opponent is indifferent, probability maximizing is optimal. we observed       accurate asymptotic strategy use in both conditions suggesting participants were       sensitive to the differences in opponent behavior. moreover, the results       emphasize that ‘irrational’ probability matching can be adaptive once       such competitive pressures are taken into account. the application of       reinforcement learning models to the data suggests that computational       conceptualizations of opponent behavior are critical to account for the observed       divergence in strategy adoption.
effects of trial history, or sequential effects, are typically       observed in perceptual, motor, and decision making tasks and explained by       subjects’ irrational sensitivity to local patterns in stimulus history. we       propose that in 2 alternative forced choice reaction time tasks (2afc),       sequential effects are a consequence a rational agent engaging in probability       learning but with an inappropriate world model for 2afc. we manipulate       subjects’ world model and show expected changes in sequential effects.       sequential effects are at least in part driven by subjects’ beliefs about       their environment.
joint attention has long been accepted as constituting a       privileged circumstance in which word learning prospers. consequently research       has investigated the role that maternal responsiveness to infant attention plays       in predicting language outcomes. however there has been a recent expansion in       research implicating similar predictive effects from individual differences in       infant behaviours. emerging from the foundations of such work comes an       interesting question: do the relative contributions of the mother and infant to       joint attention episodes impact upon language learning? in an attempt to address       this, two joint attention behaviours were assessed as predictors of vocabulary       attainment (as measured by ocdi production scores). these predictors were:       mothers encouraging attention to an object given their infant was already       attending to an object (maternal follow-in); and infants looking to an object       given their mothers encouragement of attention to an object (infant follow-in).       in a sample of 14-month old children (n=36) we compared the predictive power of       these maternal and infant follow-in variables on concurrent and later language       performance. results using growth curve analysis provided evidence that while       both maternal follow-in and infant follow-in variables contributed to production       scores, infant follow-in was a  stronger predictor. consequently it does appear       to matter whose final contribution establishes joint attention episodes. infants       who more often follow-in into their mothers’ encouragement of attention       have larger, and faster growing vocabularies between 14 and 18-months of age.
the results from a number of recent studies suggest that       ascriptions of intentionality are based on evaluative considerations:       specifically, that the likelihood of viewing a person’s actions as       intentional is greater when the outcome is bad than good (see knobe, 2006, 2010).       in this research we provide an alternative explanation for these findings, one       based on the idea that ascriptions of intentionality depend on causal structure.       as predicted by the causal structure view, we observed that actions leading to       bad outcomes are associated with negative social pressures (experiment 1), that       these negative pressures give rise to a specific kind of causal structure       (experiment 2), and that when these causal structures are pitted against the       badness of the outcome, intentionality judgments track with causal structure and       not badness (experiment 3). while the badness of an outcome may have an indirect       effect on judgments of intentionality, our results suggest that the factors that       affect judgments of intentionality most directly are non-evaluative and       objective.
recent research has begun to explore the role of diagrams as       cognitive tools. here i develop new conceptual and methodological tools for       exploring the sociality of cognition involving diagrams. first, i distinguish two       varieties of group-dependent cognition. second, extending nersessian’s       method of cognitive-historical analysis, i show how a suitably-informed       “literature review” of diagrams published in scientific articles       offers a window into the group-dependent cognition of scientists. i end by       sketching future avenues of inquiry, and how this approach may inform science       education.
coincidences are surprising events that can provide learners with       the opportunity to revise their theories about how the world works. in the       current research, we investigate whether infants are truly sensitive to       coincidences, detecting these events even when they cannot be predicted mere       probabilities. in addition, we explore whether this sensitivity is translated       into action, encouraging infants to engage in activities that enable them to       revise their theories. results from 2 experiments demonstrate that infants       display a sensitivity to coincidence similar to adult intuitions, and they       selectively explore objects that produce anomalous data that better supports an       alternative theory than their prior theory.
early word learning may be supported by a developmental feedback       loop: the kind of words a child learns early on support the development of       attentional biases, which in turn facilitate further word learning. in neural       network simulations and a longitudinal study of toddlers we investigated how the       emergence of an attentional bias to shape in word learning impacts vocabulary       growth with respect to different kinds of words. if this relationship is causal,       we should see that the emergence of a shape bias leads to an increase in the rate       of learning of shape-based words relative to other kinds of words. the networks       supported this prediction, showing an acceleration of shape- compared to       material-based word learning. however, in toddlers, shape- and material-based       words were learned similarly around the shape bias emergence. implications are       discussed for the developmental feedback loop account and causal relationships       between attentional bias development and vocabulary growth.
the relationship between structural (or syntactic) processing in       music and in language is not yet clear. evidence indicating that these two       processes are shared conflicts with other results suggesting that they are       largely distinct. these conflicting findings suggest that musical and linguistic       processing may share some, but not all, underlying processes, raising the       question of what exactly those shared processes might be. two experiments tested       the idea that one shared process is cognitive control by pairing manipulations of       musical structure with the stroop task, a standard test of cognitive control.       manipulations of harmonic expectancy, but not of timbral expectancy, interacted       with stroop interference effects, suggesting that cognitive control is at least       one specific process underlying shared syntactic processing in music and       language.
recent empirical evidence suggests that language-mediated eye gaze       is partly determined by level of formal literacy training. huettig, singh and       mishra (2011) showed that high-literate individuals' eye gaze was closely time       locked to phonological overlap between a spoken target word and items presented       in a visual display. in contrast, low-literate individuals' eye gaze was not       related to phonological overlap, but was instead strongly influenced by semantic       relationships between items. our present study tests the hypothesis that this       behavior is an emergent property of an increased ability to extract phonological       structure from the speech signal, as in the case of high-literates, with       low-literates more reliant on more coarse grained structure. this hypothesis was       tested using a neural network model, that integrates linguistic information       extracted from the speech signal with visual and semantic information within a       central resource. we demonstrate that contrasts in fixation behavior similar to       those observed between high and low literates emerge when models are trained on       speech signals of contrasting granularity.
research into human models of intuitive physics typically falls       into one of two camps, either claiming that intuitive physics is biased and not       representative of real physics, or claiming that it consists of a collection of       veridical physical laws. here we investigate the causes of this tension,       suggesting that prediction is based on real physics, but explanation is       susceptible to biases. we gave participants three tasks based on the same       physical principles: two prediction tasks and one task that required drawing the       future path of motion. we found distinct biases in all three tasks; however, the       two prediction tasks could be explained by consistent application of real       physical principles under uncertainty, while the drawing task produced many more       idiosyncratic biases. this suggests that different tests of intuitive physics are       capturing different types of knowledge about the world.
this study aims to replicate the irrelevant speech effect (ise) in       a local context and, more important, is the first to directly investigate if       musical information can reduce impairments imposed by the ise on a serial word       recall task. thirty-five undergraduates from the national university of singapore       performed serial recall on 10 word lists. the lists were presented under 5       auditory conditions, namely: music-only, combined (music with background speech),       scrambled music with background speech, background speech-only and white noise       conditions. the scrambled condition contained the same piece of music as the       combined condition except that it was re-arranged in a random fashion; the       mission of this condition was to specifically provide a comparison basis to test       if “musical structure” per se actually attenuates the ise. a       significant main effect of music conditions emerged. ise was successfully       replicated, where a significantly lower percentage of correct words was recalled       in the background speech-only condition compared to all other conditions. ise was       also successfully attenuated, but the present data suggest that musical structure       per se was not (at least not entirely) responsible for the attenuation, since the       scrambled condition had superior performance than both the combined and       background speech-only conditions.  here, we propose and discuss several novel       theoretical models involving changing acoustical features, selective attention,       and arousal to account for the present findings.
reestablishing feelings of control in the face of uncertainty is a       fundamental motive for human behavior. we propose that rituals (i.e., socially       stipulated, causally opaque practices) provide a means for coping with the       aversive feelings associated with randomness due to the perception of a       connection between ritual action and a desired outcome. two experiments were       conducted (one in brazil [$n=40$] and another in the u.s. [$n=94$]) to evaluate       how the perceived efficacy of rituals is affected by feelings of randomness. in a       between-subjects design, the scramble sentence task was used as a priming       procedure in three conditions (i.e., randomness, negativity, and neutral) and       participants were then asked to rate the efficacy of rituals used for       problem-solving purposes. the results demonstrate that priming randomness       increased participants’ perception of ritual efficacy relative to       negativity and neutral conditions. implications for increasing our understanding       of the relationship between perceived control and ritualistic behavior are       discussed.
communication systems reliably self-organize in populations of       interacting agents under certain conditions. the various fields which model this       - game theory, cognitive science and evolutionary linguistics - make different       assumptions about the learning and behavioral processes which are responsible. we       created an exemplar-based framework to directly compare these approaches by       reproducing previously published models. results show that a number of mechanisms       are shared by the systems which can construct optimal communication. three       general factors are then proposed to underlie any self-organizing learned system.       
the present study set out to investigate the influence of two       metatextual features-presentation format and source expertise-on lay       readers’ explanation of conflicts in scientific information. secondary       school students read partly conflicting information about a medical topic, which       was either presented in one single document or in four different documents, and       which was purportedly authored by lay or expert sources. results show that       readers deemed deficits in source expertise (source explanations) more likely to       account for conflicts in information written by lay authors than for conflicts       reported by experts. in addition, conflicts presented by experts and conflicts in       multiple documents were explained more strongly by referring to the nature of       knowledge and knowledge production (epistemic explanations). our findings       demonstrate that readers are sensitive to situational variations when considering       the most likely explanations for scientific conflicts. implications for       readers’ adequate understanding and subjective resolution of scientific       controversies are discussed.
speakers of morphologically-rich language commonly face what has       been called the paradigm cell filling problem (ackerman et al. 2009): they know       some form of a word but it is inappropriate to the current context, leading them       to derive a form of that word they have never encountered (e.g., they know the       singular form of a noun, and now need to produce the plural). we suggest that in       performing this task speakers perseverate on articulatory gestures comprising the       form they know, and that gestures vary in the extent to which speakers       perseverate on them. this proposal explains the parallels between findings in       loanword adaptation, speech errors, and acquisition of phonology. new       experimental data from a miniature artificial language are also presented
we present a neural mechanism for interpreting and executing       visually presented commands.  these are simple verb-noun commands (such as write       three) and can also include conditionals ([if] see seven, [then] write three).        we apply this to a simplified version of our large-scale functional brain model       “spaun”, where input is a 28x28 pixel visual stimulus, with a       different pattern for each word.  output controls a simulated arm, giving       hand-written answers.  cortical areas for categorizing, storing, and interpreting       information are controlled by the basal ganglia (action selection) and thalamus       (routing).  the final model has ~100,000 lif spiking neurons.  we show that the       model is extremely robust to neural damage (40% of neurons can be destroyed       before performance drops significantly).  performance also drops for visual       display times less than 250ms.  importantly, the system also scales to large       vocabularies (~100,000 nouns and verbs) without requiring an exponentially large       number of neurons.
this article argues that investigating the conceptual structure       underlying the use of the pluperfect and the future perfect reveals a new complex       type of nested dual mental time travel: mental time travel into posteriority       embedded into mental time travel into “anteriority in the past”       (underlying the pluperfect) versus mental time travel into posteriority embedded       into mental time travel into “anteriority in the future” (underlying       the future perfect). additionally this article also offers the following novel       notions for temporal cognition: a mental time line where past/anteriority and       future/posteriority have become nondispersible; dual temporal direct viewings at       the present moment; and looking into the future from the past (rather than the       more typical looking into the future from the present moment). implications for       cognitive modeling are discussed.
gender differences are not widely studied in the categorization       literature and the studies that did focus on gender differences generally       investigated processing differences or differences in the use of particular       categorization answers (absolute versus  continuous). in the following study we       looked at differences in the likelihood that men or women consider an item to be       part of a category. the objective of the study was twofold: we wanted to       introduce a model that is able to determine whether there are meaningful       differences in categorization between groups and that is able to identify the       sources of these differences. secondly with this model we wanted to show that       there were meaningful categorization differences between men and women: these       differences are located at the level of the  representation and/or the criterion.       
whether categorical perception of color is lateralized in the left       cerebral hemisphere (e.g., gilbert, regier, kay, & ivry, 2006) or not (e.g.,       witzel & gegenfurtner, 2011) is still controversial. this ongoing debate,       however, has been studied with visual search tasks, which seemed to produce       residual laterality effects. the present study assessed whether a delayed       discrimination task with divided visual field method, rather than visual search       tasks, yields lateralized or bilateral categorical perception of color. the       results showed an advantage for between-category discrimination relative to       within-category discrimination. such an advantage, importantly, was obtained in       the left visual field as well as in the right visual field. these results suggest       categorical perception of color is bilateral and not lateralized. combining       recent studies with visual search tasks (e.g., witzel & gegenfurtner, 2011), our       results would provide further evidence for bilateral categorical perception, and       thus throw doubt on the laterality effects of categorical perception.
studies on the effects of pronunciation variants on spoken word       recognition have seemingly contradictory results – some find support for a       lexical representation that contains a frequent variant, others, an infrequent       (but idealized) variant. we argue that this paradox is resolved by appealing to       the phonetics of the overall word. in two phoneme categorization studies, we       examined the categorization of the initial sounds of words that contain either       tap or [t]. listeners identified the initial sound of items along a       voiced-voiceless continuum (e,g, bottom–pottom, produced with word-medial       [t] or tap). no preference for word-forming responses for either variant was       found.  but, a bias toward voiced responses for words with [t] was found. we       suggest this reflects a categorization bias dependent on speaking style, and       claim that the difference in responses to words with different variants is best       attributed to the phonetic composition of the word, not to a particular       pronunciation variant.
the benefits of collaborative activities have been demonstrated in       many domains, but there remain mixed results across several others as to whether       collaborative groups can achieve greater performance than individuals, and can       achieve greater performance than nominal group comparisons. here we develop a       task that is especially suited to testing collaborative gains. in a collaborative       crossword game, two individuals solved puzzle questions either alone or       collaboratively through discussion. when talking, participants solved more puzzle       questions, solved them more quickly and accurately, and in general seemed to       recall the words from collaborative contexts better than from matched independent       contexts. by extracting the audio of their interaction, we also demonstrate       interesting relationships between spoken interaction and performance on the       collaborative tasks. this task environment further substantiates the notion that,       in the context of knowledge retrieval, two heads are better than one.
a novel computational cognitive model explains human procedural       error in terms of declarative memory processes. this is an early version of a       process model intended to predict and explain multiple classes of procedural       error a priori. we begin with postcompletion error (pce),  a type of systematic       procedural error that people are prone to commit when there is one step to       perform after they have accomplished their main task goal. participants in an       experiment demonstrated increased pce rates following an interruption in a       realistic form-filling task. the model explains pce as a consequence of two       declarative retrieval processes, spreading activation and base-level activation,       competing with each other because of features of task and working memory       structure. our intention is to generalize the model to other classes of       procedural error in complex task environments.
implicit transfer in sequential learning can occur with some       spatio-temporal structures but not with others. here, we investigated whether the       consistent mirror-reversal of visuomotor sequences would lead to implicit       transfer. a "set" comprised three sequential button presses and seven consecutive       sets comprised a "hyperset." participants learned hypersets by trial and error       with their right hand. then, they learned another hyperset, in which each set was       vertically mirrored, horizontally mirrored, or randomly generated. even when the       participants did not notice the mirrored rule, the mirrored hypersets led to       implicit transfer in terms of accuracy for both vertical and horizontal       reversals. furthermore, the vertical reserval also led to implicit transfer of       performance speed. taken together, the present results suggest that people can       implicitly apply their learned representations to the mirrored visuomotor       sequences. 
the standard approach to bayesian models of cognition (also known       as rational models) requires researchers to make strong assumptions about       people’s prior beliefs. for example, it is often assumed that       people’s subjective knowledge is best represented by “true”       environmental data. we show that an integrative bayesian approach—combining       bayesian cognitive models with bayesian data analysis—allows us to relax       this assumption. we demonstrate how this approach can be used to estimate       people’s subjective prior beliefs based on their responses in a prediction       task.
this study aims to develop a japanese version of the remote       associates test required to decompose semantic chunks for use not only in       behavioral studies but also in brain researches. further, this study attempted to       reveal the relationship between the process of solving insight problems and brain       activities. results of the behavioral data show that the solution time was       significantly longer in the chunked than in the non-chunked condition. the       imaging data identified the following brain activities. first, the right and left       cingulate gyri, related to conflict monitoring, were more activated during the       process of searching for a target in the chunked than in the non-chunked       condition. second, the left posterior cingulate gyrus was more activated when the       participants could find a target by overcoming constraints as semantic chunks       related to emotional process.
the use of a particular attentional paradigm, the paradigm of       sidedness (ottoboni, tessari, cubelli & umiltà, 2005) has highlighted as       professional volleyball players differ from non-players in the ability to encode       specific spatial indexes. the presentation of images of hands of potential       adversaries incorporates meanings related to sport that make volleyball athletes       sensitive to directional spatial characteristics previously unobserved. what       appears to be crucial in the generation of such effect is the ability to predict       the direction of an action.
research in relational learning suggests that simple training       instances may lead to better generalization than complex training instances. we       examined whether this “simple advantage” extends to category learning       in adults with simplified and traditional (more complex) chinese writing scripts.       in experiment 1, participants learned chinese characters and their english       translations, performed a memorization test, and were asked to generalize their       learning to the corresponding characters written in the other script. in       experiment 2, we removed the training phase and modified the tests to examine       transfer based purely on perceptual similarities between simplified and       traditional characters. we found the simple advantage in both experiments.       training with simplified characters produced better generalization than training       with traditional characters, both when generalization relied on recognition       memory and on pure perceptual similarities. this finding advances our       understanding of how features of a learning opportunity interact with       domain-general learning mechanisms to prepare the mind for transfer.
how is semantic memory structured and searched? recalling items       from semantic categories is a classic assay of semantic memory, and recall       dynamics tend to exhibit semantic and temporal clustering, as if memory items are       organized and retrieved in clusters. recent analyses show this clustering to be       approximately scale-free in terms of distributions of inter-retrieval intervals       (iris). this finding is replicated and extended in the present study by asking       participants to type as many animals as they can recall from semantic memory. to       begin to explain these results, the organization of semantic memory is modeled as       a network based on wikipedia entries for nearly 6,000 animals. the wikipedia       animal network is found to be scale-free in terms of its degree distribution, and       aspects of the network are found to correlate with aspects of recall. semantic       similarity based on wikipedia entries is found to compare favorably with a       measure based on latent semantic analysis. it is concluded that semantic memory       processes can be usefully theorized as searches over scale-free networks.
bayesian inference has been shown to be an efficient mechanism for       describing models of learning; however, concerns over a lack of constraint in       bayesian models (e.g., jones & love, 2011) has limited their influence as being a       description of the ‘real’ processes of  human cognition. in this       paper, we review some of these concerns and argue that cognitive architectures       can address these concerns by constraining the hypothesis space of bayesian       models and providing a biologically-plausible mechanism for setting priors and       performing inference. this is done in the context of the act-r functional       cognitive architecture (anderson & lebiere, 1998), whose sub-symbolic information       processing is essentially bayesian. to that end, our focus in this paper is on an       updated associative learning mechanism for act-r that implements the constraints       of hebbian-inspired learning in a bayesian-compatible framework.
the relationship between the notion of *information* in       information theory, and the notion of *information processing* in       cognitive science, has long been controversial. but as the       present paper shows, part of the disagreement arises from       conflating different formulations of measurement. clarifying       distinctions reveals it is the context-free nature of shannon's       information average that is particular problematic from the       cognitive point of view. context-sensitive evaluation is then       shown to be a way of addressing the problems that arise.       
we investigated whether emotions are activated during       comprehension of emotion words. in the first part of the study, an experiment was       conducted in which participants read sentence pairs each describing an emotional       state and then engaged in a judgment task. sentences were paired to either match       or mismatch in emotion (happy, sad, or angry). we predicted that the sentences       that mismatch in emotion produced longer reaction times than those where the       emotion was the same, and that shifts between negative emotions had less of an       impact. in the second part of the study, we calculated the frequency of       first-order co-occurrences of nouns and adjectives related to happy, sad, and       angry emotional states. this analysis demonstrated emotion words are more often       accompanied by similar emotion words.  match and mismatch of emotion explained       rts as did statistical linguistic frequencies of the words. the combination of       these two studies contributes to a growing body of research that supports the       importance of both symbolic and perceptual processing of emotion.
several studies have demonstrated that language encodes       geographical information. that is, the relative longitude and latitude of city       locations can be extracted from language. whether people actually rely on these       linguistic features is less clear. recent studies have suggested that language       statistics plays a role in geographical estimates, but these studies rely on map       drawings, a fundamentally perceptual task. the current study investigated the       extent to which people rely on map representations and statistical linguistic       frequencies by using a linguistic task. participants saw u.s. city pairs in their       iconic positions (a more northern city is presented above a more southern city,       or a more western city is presented to the left of a more eastern city), and in       their reverse-iconic positions (a more southern city is presented above a more       northern city, or a more eastern city is presented to the left of a more western       city). for iconic city pairs both in the east – west (seattle –       boston) and north – south (memphis – miami) configurations, rts were       determined by the iconicity. no effect was obtained for statistical linguistic       frequencies. however, when city pairs were presented in a reverse-iconic       configuration, for both horizontal (boston – seattle) and vertical (miami       – memphis) orientations, both perceptual and linguistic factors explained       rts. these findings support the idea that cognition relies on a shallow       heuristic, a linguistic system, and a fine-grained and more precise perceptual       simulation system.
the meaning of spatial relations have been intensively studied in       cognitive science research. a spatial template is one of the typical       representations of spatial relations, which maps a position of a       located object to its acceptability for the corresponding spatial       term. spatial templates have been investigated for several       orthogonal spatial relations. however, diagonal spatial relations       have attracted less attention. the present study aims at empirically       determining the spatial template for a japanese diagonal spatial term,       "migiue (upper right)". the data was collected with various       geometrical conditions changing the size of objects and the aspect       ratio of the background. the analysis of the data revealed that the       reference axis for "migiue (upper right)" was the direction of 45 degrees,       and the acceptability of the diagonal relation could be affected by       the acceptable regions of the adjacent orthogonal relations.       
in this paper, we present two experiments that investigate how       intonation can constrain pragmatic inference. while prior research has shown that       intonation can increase the likelihood of an inference being made, less is known       about how it affects the mechanisms involved in processing of inferences.   in       the first experiment, listeners had more direct mouse paths towards target       responses for stronger interpretations after hearing utterances with referents       with pitch accents than without. in the second experiment, we replicate the       finding of the first study and found more direct mouse paths towards weaker       interpretations after hearing de-accented referents   our findings suggest that       intonation constrains the online processing of pragmatic inference by increasing       the availability of stronger interpretations. 
when we imagine a train snaking through a desert, does information       about the train’s speed make it into our visual mental image?  in this       paper, we make use of the motion aftereffect illusion (mae) to test whether the       speed of imagined visual motion modulates transfer of adaptation to a subsequent       visual motion discrimination task.  we compared the effects of viewing slow,       medium, and fast motion on the magnitude of the mae (experiment 1) with the       effects of simply imagining the same motion stimuli (experiment 2). in experiment       1 we found that increasing the speed of real visual motion from slow to medium       produced a corresponding increase in the magnitude of the mae, but increasing       speed from medium to fast did not.  likewise, imagining slow motion produced a       smaller mae than did imagining medium motion, but the effect leveled of between       medium and fast motion.  these findings suggest that our mental imagery of motion       is specific to the speed of the moving objects, and highlight areas of overlap       between mental imagery and visual perception. 
context effects - preference changes depending on the availability       of other options - have wide ranging implications across applied and theoretical       domains, and have driven the development of new dynamic models of multi-attribute       and multi-alternative choice. we propose the multi-attribute linear ballistic       accumulator (mlba), a new dynamic model that provides a quantitative account of       the co-occurrence of three context effects - attraction, similarity, and       compromise - not only in traditional paradigms involving choices among hedonic       stimuli but also of recent demonstrations of these effects with non-hedonic       stimuli. the mlba model has analytical solutions making it computationally easier       to apply than previous dynamic models.
in two experiments we examined the effects of training on auditory       perception bias (experiment 1), the relationship between auditory perception bias       and global-local processing (experiment 2), as well as the relationship between       global-local auditory processing, empathy and self-construal (experiment 2). the       present findings are discussed in relation to their implications for research in       auditory perception and the perception of others’ emotional states.
keeping track of things as they move in space and time is a task       common to scientists, marketers, spies, coaches, and more. visualizations of       complex information aid drawing inferences and conclusions but there are many       ways to represent data. here we show that the kinds of inferences people draw       depend on the kind of visualization, boxes in tables or lines in graphs.  lines       link and boxes contain; they both direct attention and create meaning.
in this paper, we empirically investigate whether people       understand irony from computers in order to test the recent argument for an       egocentric tendency in irony comprehension. in the experiment, participants took       a timed math test comprising 10 questions of 3-digit by 2-digit multiplication.       after that, they received a feedback comment on their performance (including       potentially ironic sentences) from either an intelligent evaluation system with       an ai engine (ai condition), a nonintelligent automatic evaluation system (auto       condition), or a       human judge connected via the network (human condition). the result was that the       participants in the ai and auto conditions understood the comment as ironic as       those in the human condition, and the participants in the ai condition perceived       more sarcasm than other participants. because people know that computers cannot       think just as humans do, these results can be regarded as evidence for the       egocentric tendency in irony comprehension, indicating that participants       understood irony egocentrically fromtheir own perspective without taking into       account the mental state of the ironic speaker. these findings are also       consistent with the “media equation” theory, from which we can       suggest implications for the media equation, anthropomorphism, and       computer-mediated communication of irony.
this study extends the learning and use of affordances on robots       on two fronts. first, we use the very same affordance learning framework that was       used for learning the affordances of inanimate things to learn social       affordances, that is affordances whose existence requires the presence of humans.       second, we use the learned affordances for making multi-step plans. specifically,       an icub humanoid platform is equipped with a perceptual system to sense objects       placed on a table, as well as the presence and state of humans in the       environment, and a behavioral repertoire that consisted of simple object       manipulations as well as voice behaviors that are uttered simple verbs. after       interacting with objects and humans, the robot learns a set of affordances with       which it can make multistep plans towards achieving a demonstrated goal.
by one account of early word learning, children become proficient       word learners as a result of environmental regularities: learning words tunes the       child to the regularities offered by the language being learned, orienting       attention to those regularities. we test one core claim of this account, that       count nouns should cue attention to the shape of the objects. using a visual       search task we present evidence that hearing the name of the object narrows       children’s attention to the objects in the array that have the same shape.       future steps and the implications of these results are discussed.
mathematics anxiety negatively affects performance in simple       arithmetic tasks. the experiment reported here explored the role of interactivity       in defusing the impact of math anxiety on mental arithmetic. participants were       invited to complete additions presented on paper without using their hands or any       artefact; in a second, interactive, condition, the same problems were presented       in the form of a set of manipulable tokens. math anxiety was significantly       correlated with mental arithmetic performance only in the static condition. the       results of a mediation analysis indicated that the effect of math anxiety on       mental arithmetic was mediated by working memory capacity in the static       condition; in the interactive condition, math anxiety and working memory did not       significantly correlate with performance. interactivity encouraged the coupling       of internal and external resources to create a cognitive system that augmented       and transformed working memory capacity, diffusing the resource drain caused by       math anxiety.
we investigated whether “embodiment” of objects used       in a problem-solving task (i.e., whether they have a bodily shape) would have a       detrimental effect on learning to solve that problem through practice or through       studying video-based modeling examples. a 2x2 design with factors training       (practice/example study) and embodiment (present/absent) was used (n = 80).       results showed a large main effect of training on effort investment in learning       and on retention test performance, with example study leading to higher scores       with lower investment of effort during the learning phase than practice.       numerically, embodiment seemed to have an effect, with participants       practicing/studying the task with embodied objects (plastic animals) performing       worse on retention than participants practicing/ studying with non-embodied       objects (discs), but this did not reach statistical significance. a new study       with more power and an additional control condition is currently being conducted       and results are expected to be available well before the conference.
an experiment examined the effect of ‘pure’       recognition — in the absence of concomitant evaluation — on       inferences. in the first stage of the experiment, participants indicated whether       they recognized a number of italian and us cities. in the second stage, they       decided which of two cities had the larger       population. crucially, names of the cities were not available in the second       stage, but participants could find out whether they had recognized them (yes/no)       in the first stage of the experiment (i.e., pure recognition). additional       predictive cues (e.g., presence/absence of a university) were also available.       participants used the recognition cue about 50% of the time, rarely examined it       first, and used it differently as a function of whether recognition information       was binary or continuous. furthermore, participants used the recognition cue more       often if they recognized more items, irrespective of its predictive validity.       implications for theoretical frameworks that view inference       as driven by discrete heuristics or processes of evidence–accumulation are       briefly discussed.
higher working memory capacity (wmc) supports performance on a       wide variety of complex cognitive and academic activities (barret, tugade, &       engle, 2004). however, a growing body of research demonstrates that higher wmc       can have disadvantages—leading individuals to employ complex performance       strategies that are less optimal for a given task (cf. decaro & beilock, 2010).       we examine this possibility in the domain of insight problem solving.       participants (n=84) completed matchstick arithmetic problems thought to either       rely on controlled search and retrieval processes (non-insight problems) or       diverging from known mathematical constraints (insight problems). consistent with       a large body of research on wmc, higher wmc was associated with higher       non-insight problem accuracy. however, higher wmc led to significantly worse       insight problem-solving. although higher wmc supports complex problem-solving       strategies, relying on these may lead individuals to miss associatively-driven       solutions that are important for insight.
visual information contributes fundamentally to the process of       object categorization. the present study investigated whether the degree of       activation of visual information in this process is dependent on the situational       relevance of this information. we used the proactive interference (pi) paradigm.       in two experiments, we manipulated the information by which objects could be       retrieved from memory: by both semantic and shape information or by shape       information only. the pattern of pi-release showed that if objects could be       stored and retrieved both by semantic and shape information, then shape       information was overruled by semantic information. if, however, semantic       information could not be (satisfactorily) used to store and retrieve objects,       then objects were stored in memory in terms of their shape.
we report three studies examining mechanism of property-sensitive       induction. first, we demonstrate that, contrary to a common assumption, property       does not influence retrieval of knowledge about premise categories. second, we       introduce property-driven explanations as a possible source of property effects       and provide first evidence for this proposal.
an essential first step in analogy is retrieval of a source       analogue appropriate for the target situation.  in this paper, we focus on the       phenomenon of interactive analogical retrieval (iar) wherein the source analogues       are obtained through interaction with online information environments. we first       provide a descriptive account of iar based on two in situ studies. we then       describe an information-processing model (called prism) that provides an       explanatory account of iar. we conclude with a discussion of some of the       theoretical and technological implications of this work.
this paper presents a hybrid cognitive model engaged in ex-       periments demonstrating a successful mechanism for applying       top-down contextual bias to a neural speech recognition sys-       tem to improve its performance. the hybrid model includes       a model of social dialogue moves, which it uses to selectively       bias word recognition probabilities at a low level in the neu-       ral speech recognition system. the model demonstrates how       symbolic and neurologically inspired components can success-       fully exchange information and mutually influence their pro-       cessing. furthermore, the biasing mechanism is grounded in       brain mechanisms of perceptual decision making.
deaf individuals have difficulties in comprehending written text,       as well as oral language. as a consequence, learning from text is compromised in       deaf individuals.        we hypothesized that a transposition of the italian sign language to its written       counterpart could enhance signing deaf individuals’ comprehension and       learning from text.        we confirmed our prediction for comprehension and learning for technical texts in       experiment 1 and for narrative texts in experiment 2; signing deaf       individuals’ text comprehension and learning therefore benefit from a       written language whose structure reflects the structure of their visual-spatial       sign language.        we speculate that, for signing deaf individuals, practice in reading written sign       language texts might positively affect the ability to comprehend the written oral       language texts.
this article reports on an experiment in which artificial       languages with whistle words for novel objects are culturally transmitted in the       laboratory. the aim of this study is to investigate the origins and evolution of       combinatorial structure in speech. participants learned the whistled language and       reproduced the sounds with the use of a slide whistle. their reproductions were       used as input for the next participant. cultural transmission caused the whistled       systems to become more learnable and more structured. in addition, two conditions       were studied: one in which the use of iconic form-meaning mappings was possible       and one in which the use of iconic map- pings was experimentally made impossible,       so that we could investigate the influence of iconicity on the emergence of       structure.
this study explored the acceleration of student vocabulary growth       and reading comprehension proficiency through a multi-part instructional strategy       for engendering the inductive, semantic word-family-oriented acquisition of       vocabulary from context, a difficult task for elementary students. implemented on       a schoolwide basis for an academic year in grades 3-4-5, the intervention was a       four-part enhancement to a traditional basal reading program that constructed and       used semantic word families for designated vocabulary words within stories.       results from hlm statistical modeling using student minority status and       free/reduced lunch as covariates showed that experimental students in grades       3-4-5 obtained significantly higher achievement on both itbs vocabulary and itbs       reading comprehension subtests. implications for research and practice are       discussed.
it has been suggested that a referent’s accessibility is       affected by the degree to which it is in the speaker’s attention. assuming       that less accessible referents are less likely to be pronominalized, this       predicts that speakers under cognitive load use more elaborate referring       expressions. however, speakers under load may also have difficulty taking into       account their addressee’s perspective, which may either lead to more use of       the speaker’s own discourse model or to more economic expressions. to tease       these effects apart, we conducted a story completion experiment in which       cognitive load was manipulated by the presence or absence of a secondary task for       the speaker. in addition, we dissociated the speaker’s and the       addressee’s perspectives. our results do not provide evidence for the       hypothesis that cognitive load reduces the accessibility of referents in the       speaker’s own discourse model, suggesting that speaker attention does not       determine accessibility.
we investigate the amount of speech and (co-speech) gestures       addressed to infants at 1;1 years of age in rural and urban mozambique, and       correlate these amounts with vocabulary size measured at 1;5 and 2;1. we found       that urban infants are exposed to more than three times as much speech and       co-speech gestures than rural infants. the results show that the amounts of       co-speech gestures and speech predict later vocabulary development in the urban       community, but not in the rural community. the results further show that rural       infants are delayed in their vocabulary development, which may in part be       explained by a transition in the socialization style rural infants experience       between the age of 1;1 and 1;5. 
probability judgments about logical propositions have raised       substantial doubts about human rationality. here we explore the idea that       people’s probability judgments often may not refer to the relative       frequency of a set, but instead to the probability of an explanatory logical       pattern given the data. this idea has been formalized by bayesian logic (bl),       predicting a system of frequency-based logical inclusion fallacies. the studies       presented concentrate on comparing probability judgments about sentences       logically relating two attributes of a class or an individual (humans, animals,       artifacts). although bl cannot model probabilities of individual predications       directly, it can do so if one assumes that inferences are made about unknown       individuals based on imagined samples. the results for general as well as       individual predication show a high number of systematic inclusion fallacies in       line with bl. nevertheless, some deviations were found. in the general       discussion, a polycausal approach to inclusion fallacies is advocated.
the extent to which people learning categories generalize should       depend in part on their beliefs about how the instances were sampled. bayesian       models of sampling have been successful in predicting that generalization can       decrease as more instances of a category are encountered. this has only been       shown in tasks were instances are all from the same category, but contrasts with       the predictions from most standard models of categorization that predict when       multiple categories exist, people are more likely to generalize to categories       that have more instances when distances between categories is controlled. in this       current work we show that in both one- and two-category scenarios, people adjust       their generalization behavior based on cover story and number of instances. these       patterns of generalization at an individual level for both one- and two-category       scenarios were well accounted for by a bayesian model that relies on a mixture of       sampling assumptions.
young children’s collaboration is a topic of great interest,       yet what causes children to initiate collaboration in some circumstances but not       others is unclear.  in this research, we analyzed preschoolers’       collaboration as an information gathering activity in a toy assembly activity.        we independently assessed children’s competency at a similar building task       and, using a separate group of children, the difficulty of each step of the       activity.  we hypothesized that children would request collaborative assistance       when they needed assistance (that is, when they were less competent and/or the       task was more difficult), but act independently when capable.  the results       confirmed that preschoolers were more likely to request collaborative assistance       as the difficulty of the activity increased and more so if they were initially       less competent.  the results suggest that preschoolers’ collaboration may       be profitably viewed as an information gathering activity.
new theories of cognition posit the existence of an intimate link       between higher cognitive processes and the sensorimotor areas of the brain. in a       reaction time-based translation task, second language (l2) speakers responded to       action verbs using a microphone or a response pad. a significant interaction       among response modality, verb type, and proficiency indicated that more       proficient l2 speakers took significantly longer to respond with their hands to       previously seen hand-related verbs, but not mouth-related ones. conversely,       responding using a microphone led to slower latencies in the case of mouth-verbs,       but not hand-verbs. amidst virtually exclusively monolingual research on embodied       cognition, the current study provides evidence that reading l2 action verbs       selectively interferes with subsequently performed manual or verbal responses,       suggesting that semantic representations of these verbs are distributed over       neural substrates underlying action execution. the role of proficiency and       experience in language comprehension is discussed.
when estimating the number of dots in a set, adults show bias and       variability that scale with numerosity. increasing variance in estimation is       thought to reflect constant weber noise on perceptual magnitude representations,       while the increasing bias reflects miscalibrated mappings of number words onto       magnitudes. here we argue that response variability in numerical estimation       increases with numerosity in part due to uncertainty and slow drift in the       mapping of numbers onto magnitudes.  we show that individuals'       number-to-magnitude mapping functions drift slowly over the course of the       experiment, with a shared-variance half-life of over 100 trials ($\sim 10$ min).       we thus propose a model that treats the word-to-magnitude mapping function as a       major source of estimation variability, and that accounts for cross-subject       differences in estimation bias and variability, as well as changes to estimation       performance within a given subject over time. in doing so, we reconcile the       existing literature on the sources of estimation variability, and provide        evidence that uncertainty in the word-to-magnitude mapping function is a key       limiting factor in estimation performance.       
there is controversy concerning the question of whether meaning       can be extracted from a parafoveal word during reading and whether this might       occur in an overlapping fashion with the lexical processing of the       currently-fixated word. we suggest that previous attempts to investigate this       have been bedevilled by problems associated with the use of priming methodology.        instead, we used an eye movement contingent change technique and manipulated the       plausibility of the parafoveal preview, resulting in it being either valid, a       plausible alternative, anomalous, or an illegal letter string. the results showed       (a) a meaning-based parafoveal-on-foveal effect, (b) preview benefits driven by       both orthographic and semantic influences, and (c) continuing disruption       associated with orthographically dissimilar previews. we suggest that this       pattern is most consistent with models of eye movement control that allow for       distributed attention during reading.
perspective plays a large role in how we think about space. does       perspective also influence how we think about abstract concepts, such as       time—which is closely associated with how we think about space? linguistic       patterns suggest that speakers talk about temporal sequences from two       perspectives: field-based and ego perspective (moore, 2011). however, the       psychological reality of these mappings beyond their use in language is unclear.       the present study examines whether sequential reasoning recruits the sagittal       axis differently, depending on the perspective adopted. we manipulated       perspective by using pronouns meant to evoke a field-based or ego perspective       (“her” vs “your”, respectively). participants made       earlier-than or later-than judgments about event sequences using a mouse in front       of or behind their body. we observed an interaction between pronoun, temporal       reference, and response location. participants map space onto time differently       depending on the frame of reference from which temporal sequences are       interpreted. 
extensive research effort has been invested in building       neurocomputational models for face and object recognition. however, the       relationship between the recognition model and the development of the visual       system is rarely considered. research on the development of contrast sensitivity       shows that human infants can only perceive low spatial frequency information from       visual stimuli, but their acuity improves gradually with age. also, the right       hemisphere (rh) develops earlier than the left hemisphere (lh), and is dominant       in infants. here we show that these constraints, coupled with a desire on the       part of the infant to individuate its caretakers and family, leads naturally to       the right hemisphere bias for face processing. we propose a developmental model       for face and object recognition using a modular neural network based on dailey       and cottrell (1999). this neural network represents the two hemispheres using two       modules, with a competitive relationship between them mediated by a gating       mechanism. the strong rh and low spatial frequency bias for face recognition       emerges naturally in the model from the interaction of the slow development of       acuity and the early dominance of the right hemisphere. remarkably, this strong       asymmetry does not appear to hold for the other object categories that we       tried.
manipulation of environmental constraints has been shown to       influence the relative amounts of voluntary and involuntary control employed by a       person to complete a task, as well as the resulting structure of performance       variability. generally, the voluntary control required when no constraints are       present leads to self-similar changes in performance, some constraint provides       involuntary control that leads to random fluctuations in performance, and       constraint which provides feedback about performance accuracy can result in       anti-persistent variability. the current study investigated whether providing two       groups of individuals with different intentions for the same task would produce       changes in voluntary and involuntary control similar to that observed following       the manipulation of task constraints. results indicated that a difference in       intention does result in divergent uses of voluntary and involuntary control and       distinctly different structures in performance variability.
in inductive learning, the order in which concept instances are       presented plays an important role in learning performance. theories predict that       interleaving instances of different con- cepts is especially beneficial if the       concepts are highly sim- ilar to each other, whereas blocking instances belonging       to the same concept provides an advantage for learning low- similarity concept       structures. this leaves open the question of the relative influence of similarity       on interleaved versus blocked presentation. to answer this question, we pit       within- and between-category similarity effects against each other in a rich       categorization task called physical bongard problems. we manipulate the       similarity of instances shown temporally close to each other with blocked and       interleaved presentation. the results indicate a stronger effect of similarity on       interleaving than on blocking. they further show a large benefit of com- paring       similar between-category instances on concept learning tasks where the feature       dimensions are not known in advance but have to be constructed.
although bilingual first language acquisition research has       increased considerably over the past few decades, there is still much controversy       regarding the rate of development, i.e. the question whether bilinguals lag       behind their monolingual peers in various aspects of language. some studies have       found similar rates of development, whereas others have found that bilingual       children lag behind their monolingual peers. the current study contributes to       this discussion of (dis)similar rates of development by investigating bilingual       children’s acquisition of german complex sentence constructions involving       adverbial clauses (acs). our findings are consistent with usage-based approaches       to language acquisition, which predict that bilingual acquisition should proceed       slower due to learners having less exposure, on average, to each language.
the bridge dilemma (pushing a heavy man from a bridge in front of       a train that would otherwise kill five persons) and the switch dilemma       (redirecting a train that would otherwise kill five persons onto another track       where it kills one person) are presumably the two best-known moral dilemmas in       philosophy and psychology. in this paper we claim that people’s intuitions       about what to do in bridge are robust, while intuitions about switch can be       influenced rather easily.  in doing so, we strongly disagree with broeders and       colleagues (2011) who recently argued for exactly the opposite claim. we discuss       their interpretation of previous findings that were supposed to motivate their       claim, present findings from previous studies that strongly support my claim, and       report on failed attempts to replicate and present an experiment in which       participants were willing to revise their judgment for switch but not for bridge.       
learning-by-invention is an approach to mathematical       instruction where small groups explore possible methods of       solution before learning the “right answer” (e.g., schwartz &       martin, 2004; kapur & bielaczyc, 2011). in a series of studies       we have been investigating the effects of group composition       in terms of math ability on learning by invention. an initial       result showed that groups consisting of a mix of both high and       low math ability students generated a broader range of       solution attempts when asked to invent a formula for standard       deviation compared to more homogeneous math ability       groups. moreover, this wider range of solution alternatives       predicted better performance on quizzes following a lesson on       the topic. subsequent work is suggesting that who emerges as       the leader of the group matters. ongoing analyses are also       exploring which features of the collaborative discourse are       critical for students to take advantage of the affordances of       learning by invention.
in this paper we develop an idea first mooted by wilkinson, ball,       and cooper (2010), which is that the dichotomy between theory-based and       simulation-based reasoning in the context of mental state understanding is       synonymous with the distinction between intuitive and reflective thinking in       dual-process accounts of human reasoning (e.g., evans, 2010). to support this       proposal we draw upon a range of concepts and findings deriving from both       mainstream reasoning research and from studies of social cognition. we also       consider the implications of our proposal for the formulation of an integrative       approach to understanding reasoning in all of its many manifestations, whether       undertaken for the attainment of socially-oriented goals or for the purposes of       learning and discovery. 
we investigate the effects of explaining anomalies (i.e.,       observations that conflict with current beliefs) on belief       revision, and in particular how explaining contributes to the       rejection of incorrect hypotheses, the generation of       alternative hypotheses, and the selection of a hypothesis       that can account for anomalous observations. participants       learned how to rank students across courses using       statistical concepts of deviation, and did so while either       explaining sample rankings or writing their thoughts during       study. we additionally varied whether or not candidate       hypotheses about the basis for ranking were presented to       participants prior to learning, and the number of sample       rankings that violated intuitive misconceptions about       ranking. measures of learning and coded responses suggest       that prompting people to explain can increase the rate at       which they entertain both correct and incorrect hypotheses,       but that explaining promotes the selection of a hypothesis       that can account for anomalous observations.
it is sometimes argued that implementation of an overall       similarity classification is less effortful than implemen- tation of a       single-dimension classification. one piece of evidence taken to be in support of       this argument is that highly impulsive individuals appear to be more likely to       sort on the basis of overall similarity than individuals with low impulsivity       (ward, 1983); presumably, higher impulsivity results in lower effort. in the       current arti- cle, we identify some limitations in ward’s procedure and,       using a more standard measure of impulsivity and a less ambiguous measure of       overall similarity classifica- tion, re-investigate the relationship between       impulsivity and overall similarity classification. using a match-to- standard       procedure, the current experiment finds that overall similarity classification is       less prevalent in highly impulsive individuals. the implications of this result,       which is opposite to that reported by ward (1983), are discussed.
research on the mental representation of numbers has focused on a       horizontally aligned mental number line, but more and more findings have begun to       implicate a vertical orientation as well. we investigate the relationship between       these two orientations when people generate random numbers. in the horizontal       condition, people generated larger numbers when they looked right as opposed to       left. in the vertical condition, people generated larger numbers when they looked       up as opposed to down. we present two main results based on analyses that compare       the two spatial orientations. first, we show that the vertical effect was       stronger than the horizontal one. second, we show a weak correlation between the       vertical and the horizontal effect, potentially suggesting a shared underlying       mechanism.
the imitation of successful peers is often heralded as an       intelligent shortcut to reduce individual learning costs. using computer       simulations, we demonstrate that this advice can be ill-founded and harmful in a       cognitive inference task involving continuous learning. in particular,       success-based imitators perform worse than both learners who integrate the       learning experience of all group members and isolated learners. we report on       sensitivity analyses for this phenomenon and offer explanatory mechanisms.
we investigated both subjective and objective differences in       viewing non-social versus social scenes. specifically, we examined four related       questions: 1) do participants prefer non-social or social scenes? 2) are there       differences in subjective exploration of non-social and social scenes? 3) are       there differences in objective exploration of these scenes? 4) does a non-social       trait – connection to nature – influence the extent of non-social       scene exploration? experiment 1 found, surprisingly, that participants prefer       non-social over social scenes, and correspondingly, they reported exploring these       scenes more. experiment 2 used eye-tracking to test the validity of this       introspection and confirmed that participants explore non-social scenes more than       social scenes. we also discovered that connection to nature selectively modulates       exploration of non-social scenes, demonstrating a critical interaction between       observer and scene characteristics in the deployment of spatial attention. 
this study looked at whether toddlers posit the existence of       unobserved causes when events occur probabilistically.  older (18-24 months) and       younger (12-17 months) children were introduced to novel events.  an experimenter       pressed a red handle and a lollipop emerged from a box; she then pressed a green       handle and a cake emerged. these events were repeated three times. on the fourth       trial, the experimenter switched either the order or relationship between events.        in the deterministic condition, the experimenter pressed the green handle first       and the red handle second; in the probabilistic condition, the red handle       produced the cake and the green handle produced the lollipop. on the test trial,       the experimenter pressed the red handle and a hand emerged, holding the lollipop.        the older toddlers looked longer at the hand in the deterministic than the       probabilistic condition, suggesting they inferred a hidden cause when the events       occurred probabilistically.
this study aimed to explore the relationship between       children’s sharing behavior and theory of mind (tom) understanding.       seventy-four 2 to 4 years old chinese children participated in 3 tasks using toys       that could be shared with a puppet that was animated by a female experimenter. on       each task, the puppet expressed her desire for the items using a series of cues       that progressively became more communicative. children’s tom understanding       was assessed with the scale of tom tasks (wellman, fang, liu, zhu, & liu, 2006).       there were two main findings: (1) younger children relied on more explicit       communicative cues to share resources with the puppet, while older children       shared more spontaneously and (2) children’s sharing behavior was       positively correlated to their tom scores, independent of age. findings suggest       that preschoolers’ sharing behavior is enhanced by their tom understanding       and explicit communicative cues provided by a social partner.
the analogy of space to human cognition has a long-standing       tradition. our study aims to elaborate on the validity of this analogy for search       in memory. using the search of associative memory framework (sam) we show that       people are able to dynamically recruit independent memory representations in the       recall of country names. by instructing participants to use specific recall cues       we also show that despite a strong effect on the retrieval sequence, total recall       from memory remains unaffected. whereas these findings strongly support a higher       dimensionality to memory than often assumed, the simultaneous finding of severe       retrieval time costs for non-default representations suggests that the use of       particular retrieval structures may be adaptive. in sum, our results support       local-to-global memory search strategies similar to foraging strategies in space,       but further suggest that memory is not constrained to one local representation,       but may indeed support many. 
quantitative analyses and the analyses of a questionnaire were       conducted to examine the relations between participants’ communicative       activities and their interactional attitudes in conversations both in their       native and second languages. the two categories of conversations revealed       different gaze patterns that reflected the differences in difficulties they had       with communication and grounding patterns. the participants were less conscious       of their own gazes in conversation in their second language than those in their       native language probably because of the difficulties and mental pressure they       felt.
yeates, jones, wills, aitken, mclaren and mclaren (2012) devised a       serial reaction time (srt) task that provided evidence for human learning without       awareness. adapting the srt paradigm usually employed to investigate implicit       learning, participants responded to two simple white circle fills on either side       of a screen. instead of these following a sequence that participants were unaware       of (e.g. willingham, nissen & bullemer, 1989) this task involved a separate       stimulus, which was sometimes predictive of one of the circle fills. a square in       the center of the screen would fill with one of eight colors before each circle       fill: one of these colors predicted a right circle fill and the other a left on       80% of trials on which those colors occurred. when pressing the key that followed       the consistent response trained with these two colors, participants were both       faster and more accurate than when responding to either the inconsistent response       or control colors. participants demonstrated a lack of contingency awareness,       performing at chance in identifying the predictive colors and on a suitably       sensitive prediction task. on reanalyzing this result, this paper shows that it       was confounded with a sequential artifact produced by the experimental design       itself. pilot studies demonstrated weak learning of color contingencies when the       artifact was removed, thus we sought to improve learning by both increasing the       amount of training and placing the predictive color cue on the circle fills.       without the sequential artifact, we can produce the same result, although we       concede the effect is less robust than we first indicated. thus, we are able to       reiterate our original conclusion: that this task can demonstrate learning of       color contingencies in the absence of awareness and can be used to investigate       implicit learning in humans.
people's representations of most and arguably all linguistic and       non-linguistic categories are probabilistic. however, in linguistic theory,       quantifier meanings have traditionally been defined set-theoretically in terms of       categorical evaluation functions. in 4 ``adaptation'' experiments, we provide       evidence for the alternative hypothesis that quantifiers are represented as       probability distributions over scales (e.g., zadeh, 1965). we manipulate exposure       to different distributions of ``some'' and ``many'' and find that listeners adapt       to those distributions, as predicted. our results suggest that the interpretation       of quantifiers is best modeled as a process involving rich, probabilistic       representations.
two category-learning experiments were conducted to examine the       role of category structure and learning regime in category learning. we       particularly focused on effects of these factors on selective attention, which       was measured by eye-tracking methods. results show that even though supervision       was weaker than in previous studies, attention optimization and cost of attention       were observed during category learning (experiment 1). moreover, there were       faster learning and stronger attention optimization when statistically denser       categories were learned (experiment 2). at the same time, there were weaker costs       of selective attention when learning denser categories than when learning sparser       categories.  results are discussed in relation to theories of category       learning.
we combine video recording and laser range tracking to analyse the       geometrical structure of groups of walking pedestrians socially       interacting. by recording their relative position and observing their social       interaction for a large enough time span we can analyse the stability and       universality of their spatial structure.       we find that while 2-pedestrian and 3-pedestrian groups have a relatively ``time       stable'' and ``universal'' geometrical structure (an abreast formation for pairs,       and a ``v'' formation for triads, with the central pedestrian walking slightly       behind), no such structure emerges for larger groups. nevertheless,       these larger groups result to be composed of time stable two or three people        sub-groups with the same ``universal'' geometrical structure of isolated pairs       and triads.
employing the dynamical systems framework, we study the       effects of intrinsic motivation on the dynamics of the learning       processes. the intrinsic motivation here is the one’s desire       to learn not because it may cause some benefits in future, but       due to the inherent joy obtained by the very process of learning.       we study a simple example of a single agent adapting       to unknown environment; the agent is biased by the desire to       select the actions she has little information about. we show       that intrinsic motivation may cause the instability of the learning       process that is stable in the case of rational agent. therefore,       we suggest that the effects of human intrinsic motivation       in particular and the irrationality in general may be of exceptional       importance in complex sociopsychological systems and       deserve much attention in the formal models of such systems.
studies of statistical learning have documented a remarkable       sensitivity to structural regularities in both infants and adults. however, most       studies of statistical learning have assumed a single underlying causal structure       with uniform variance. in previous work in which two structures are presented       successively, a primacy effect has been reported in which only the first       structure is acquired. the present study explores the conditions under which such       primacy effects are observed and learners are capable of acquiring both       structures. we argue that learners can detect multiple structures by monitoring       the consistency of the input.
recent theoretical discussion of dyadic coordination has focused       on issues of synchronization, entrainment, alignment, and convergence. all of       these terms refer to matching of specific behavioral and linguistic events, such       that members of a dyad coordinate by “doing the same thing.”       communicative behaviors tend to be highly variable, like most human behaviors.       these tendencies suggest the possibility of complexity matching: statistical       measures of behavioral complexity may converge in certain types of dyadic       interaction. in the present study, acoustic speech signals of interlocutors were       measured in two conversational conditions, one argumentative and the other       affiliative. signal complexity was measured in terms of heavy tails and power       laws in the distributional and temporal properties of acoustic event series,       respectively. parameters of statistical functions were found to vary by       conversation type, as did their matching between interlocutors. results       demonstrate a new way to quantify the coordination of interlocutors in terms of       complexity matching.
measuring individual differences in susceptibility to decision       biases has received increased attention in recent years, yet some methodological       questions may hinder us from validly assessing the effects of cognitive       heuristics. surveys consisting of measures of several biases often aim to compare       rate of occurrence of these biases and to compile a composite index from these       measures. unfortunately, the probability that the participant chooses the       normative answer on the test questions often varies between and within studies,       thus confounding the results. another complication in the surveys used is that       some incorrect answers are not necessarily the result of the studied bias. in our       work, we tried to overcome these methodological challenges in a new survey of 15       cognitive biases. the results of 1127 participants provided insight into several       methodological and theoretical questions about measuring individual differences       in heuristic decisions.
a recent study (brady et al., 2008) claims that the capacity and       fidelity of long-term visual recognition memory has been underestimated. after       viewing a massive number of images for nearly six hours participants were highly       accurate at identifying a previously seen image in a two-alternative forced       choice task even when the foil was extremely similar to the target. in present       study we hypothesised that this impressive memory performance might be specific       to the test format. to investigate the effect of test format on recognition       accuracy we showed participants 1700 images for 2.5 hours and then tested them in       a forced choice task and a yes/no task, where participants judged only one image       at a time. we found that accuracy was relatively high in both test conditions;       however, the performance was lower in the yes/no task (75% vs. 86%). a follow-up       study exploring delayed testing effects will also be described.
in two experiments, participants were instructed to set aside       their complete knowledge of a statistical population parameter and to take the       perspective of an agent whose knowledge was limited to a random sample.       participants rated the appropriateness of the agent's conclusion about the       adequacy of the sample size (which, objectively, was more than adequate), along       with the agent's intelligence. whereas previous work suggests that unbelievable       statistical conclusions impact reasoning by provoking critical thought which       enhances the detection of research flaws, the present studies presented       participants an unflawed scenario designed to assess effects of believability on       bias. the results included the finding that participants' complete knowledge       indeed biased their perceptions not only of the adequacy of the sample size, but       also of the rationality of the agent drawing the conclusion from the sample. the       findings were interpreted in the context of research on belief bias, social       attribution, and theory of mind. 
there is an ongoing debate on whether semantic interference       effects in language production reflect competitive lexical selection or       post-lexical response exclusion mechanisms driven by the response-relevant status       of distractor words.        to disentangle categorical relatedness and task-defined response relevance       effects, we combined the picture-word interference task with the conditional       naming paradigm in an orthogonal design. participants were instructed to name       objects typically located in or on the water (e.g. canoe) and refrain from naming       objects typically located outside the water (e.g. bike), and vice versa. semantic       relatedness and response relevance of distractors were manipulated independently.       linear mixed model analyses were conducted with semantic similarity ratings of       target-distractor as continuous predictor.         the pattern of results revealed that semantic similarity beyond categorical       relations is critical for interference effects to be observed, and not response       relevance. these findings provide support for the assumption that lexical       selection is competitive and that semantic interference effects in the pwi       paradigm reflect this competition.       
systems contain normal noises even in a stable state, but larger       noises in an uncontrollable state. in this study, we investigated different       responses between experts and novices in controllability judgment. a half       participant was required to discriminate variance magnitude of two sound tone       sequences (standard vs. comparison). the sequence consisted of 16 tones whose       pitch contained gaussian noises. they continued to train the variance       discrimination task up to a criterion level, and were regarded as experts. then,       the experts and novices participated in the controllability judgment task (i.e. a       kind of the risk judgment task) with use of similar stimuli in the discrimination       task. they were allowed to continue to judge for gain whether they were in an       uncontrollably higher risk state with larger variances. they could stop the trial       to make smaller costs. our results showed experts in the discrimination task       increased avoidance responses more than novices.
visual short-term memory (vstm) is a limited information store       that supports many higher-order cognitive processes. here we examined how two       challenges to vstm, sleep deprivation (sd) and maintenance duration, interact to       affect the number and precision of stored items. participants were studied twice,       once after a normal night of sleep and once following a night of total sd. for       each trial, participants remembered the location and color of three squares over       a variable delay (1 or 10 seconds), reporting the color of the cued item using a       color wheel. the probability of reporting the target item, the precision of       report, and the probability of reporting a distractor item were determined using       mixture modeling. sd reduced the number of integrated representations that could       be reported, an effect compounded by delay. in contrast, sd had no effect on vstm       precision. these results suggest all-or-none memory failures, not gradual       degradation, during sd.
this study aims to further our understanding of the social and       cognitive processes underlying conceptual change learning through argumentative       discourse. we tested the effect of competitive (vs. collaborative) argumentative       discourse style and belief of interaction with a human peer (vs. a computerized       peer agent) on learning the concept of diffusion through interaction with a       disagreeing peer. peer confederate’s verbal behavior was tightly controlled       to evoke argumentative discourse, holding content exposure constant but differing       in rhetoric style. students in the collaborative discourse style condition       performed better. moreover even though previous studies have reported that the       belief of interaction with a human peer benefits learning in consensual settings,       the opposite was found for a settings in which the partner critiques the       learner’s own solutions: students performed better when they believed they       interacted with a computer agent (vs. with a human peer). implications for theory       as well as task design are discussed.
with the first experiment of our study we have empirically tested       the hypothesis that in adult and in adolescent subjects there is a consistency of       the spatial representation of emotion terms. we explore the stability of the       association between valence and verticality through modulation effect of the       valence priming on spatial arrangement of emotion terms. in the second part of       our study we focused on spatial representation of emotions by preschoolers when       tested explicitly and implicitly with a task of spatial recall. it was found that       the arrangement of emoticons on vertical and horizontal line by preschool       children varied significantly as a function of the valence of emotions. the       results from our third experiment suggest that the effect of the valence of       nonverbal stimuli on the spatial recall was only evident when they were with a       negative value and when placed at more central positions near to the horizontal       line.
the relationship between word frequency (wf), measured on a       continuous scale, and recognition memory was examined in a single item       recognition task. the aim was to more clearly map the relationship between word       frequency and memory performance. in marked contrastcontrary to standard findings       of a linear relationship when between wf and recognition,is treated as discrete,       we observed a curvilinear pattern. specifically, discriminability (d’) is       higher at both the low and very high ends of the wf continuum. in addition, we       observe shifts in bias (c) with a conservative bias for very high frequency (hf)       words between wf and memory performance. variations of a bayesian signal       detection model were then applied to the data in order to better understand the       influences wf on measures of d’ and c. the models examined contrast the       current explanations of the wf effect in recognition where c does not influence       performance with a model where c is free vary as a function of wf.of a linear       relationship between wf and discriminability (d’) in recognition memory,       with the curvilinear pattern for both d’ and bias (c) with the curvilinear       patterns observed in the current data set.  implications for models of       recognition memory are discussed.
cross-situational learning and mutual exclusivity are strategies       proposed to explain the learning of word-meaning mappings. in this paper, seven       possible strategies are explored and compared to the results of an artificial       word learning experiment. the fixed order of trials in the experiment allows for       an exposure-by-exposure approach to explore the individual learning process of       words. the experiment shows that adult learners do indeed integrate knowledge       from previous exposures, however they have difficulty in keeping track of       cross-situational information for learning all twelve word-meaning mappings,       although some learners can. the performance of 78 participants is compared to       simulations in which various combinations of strategies were modeled. the results       suggest that a random strategy with mutual exclusivity as its sole learning       mechanism could explain the performance in the experiment. in this strategy, the       learner selects an object at random from the context, provided that this object       has not received a label yet.       
the aim of this study was to explore the effect of semantic       congruence and spatial orientation on verification time of modus ponens (mp) and       modus tollens (mt) conclusions. factorial experiment (2x2x2) with repeated       measures was carried out. conditionals expressed the vertical relation of two       objects in congruent (if cellar is down, then attic is up) or incongruent manner       (if attic is down, then cellar is up). eight pairs of words with clear vertical       relation were used. order of vertical relations in the conditional was also       manipulated. conditionals were in the form of “if p down, then q up”,       or “if p up, then q down”. participants (n=48) had to verify the       presented conclusions in 64 tasks as quickly as possible. significant effects for       valid mp conclusions were obtained. conclusions containing “down-up”       order of relations in conditional premise were processed faster. congruent       spatial relations also facilitated faster answers.
in a range of contexts, pairs of interacting individuals arrive at       collective decisions by comparing their confidence in their judgements. this       tendency to evaluate the reliability of information by the confidence with which       it is expressed has been termed the ‘confidence heuristic’. in this       study, we tested two fast and frugal ways of implementing the confidence       heuristic in the absence of interaction: either directly, by opting for the       judgement made with higher confidence, or indirectly, by opting for the faster       judgement, the latter exploiting a widely known inverse correlation between       confidence and reaction time. we found that the success of these heuristics       depends on how similar individuals are in terms of their abilities and, more       importantly, that for dissimilar individuals such heuristics are dramatically       inferior to interaction. interaction allows individuals to alleviate – but       not fully resolve – their differences in ability.
the excellent temporal resolution of event-related potentials       (erps) makes it an ideal technique to test the timing of events within cognitive       models which may not be distinguishable using behavioural data. here a model of       an erp component is presented which tests features of the act-r cognitive       architecture. the p300 is an event-related potential that is associated with       attending to incoming stimuli and subsequent memory processing. it is commonly       elicited using an oddball task in which a series of stimuli are presented       comprising infrequent target stimuli against a background of frequent standard       stimuli. it is influenced by the probability of a target in a sequence of       stimuli. an act-r model was developed of the oddball task. p300 amplitude was       correlated with the activation of the memory of the target stimuli, providing a       good account of the component. the implications of these findings for the act-r       architecture are discussed.
recently, researchers in usage-based linguistics have argued that       language should be thought of as a domain-general processing faculty operating on       rich memory representations of particular experiences with language. if true,       this would imply that context-dependent memory effects ought to be detectable       across the language-nonlanguage boundary. specifically, it would imply that that       by manipulating nonlinguistic environmental context, it should be possible to       influence people's linguistic production. this study reports three experiments       testing whether environmental background color, music, or sound can influence       participants' choice of active or passive voice in a picture-description task.       results suggest that the effect, if present, is not as clear-cut as has been       argued by some language theorists, but there are promising signs that language       production may indeed be susceptible to associative influence from the       nonlinguistic environment. 
how does language shape thought? in particular, do       cross-linguistic differences in how explanations are requested affect how       explanations are evaluated by speakers of different languages? to address this       question we contrasted english with turkish, which has three distinct words that       correspond to “why?” in english. through two corpus studies and an       experimental study, we established that turkish “why” questions tend       to appear in different contexts and elicit different kinds of explanations: the       “why” questions vary in the frequency with which they refer to agents       and elicit teleological explanations. in an experimental study investigating       whether this cross-linguistic difference affects how explanations are evaluated,       we found that while english speakers displayed an overall preference for       mechanistic explanations in evaluating the stimuli, turkish speakers provided       similar satisfaction ratings for mechanistic and teleological explanations. our       findings have implications for the cognitive science of explanation and for       debates about language and thought.
we tested the hypothesis that the orthographic representations       (‘spellings’) of second language (l2) words affect experienced l2       speakers’ pronunciation.        in italian, double consonant letters represent geminate (long) consonants. we       predicted that italian speakers of english would pronounce english words with       longer consonants if spelled with double letter, e.g. a longer [t] in kitty than       city. three groups of italian speakers of english performed different word       production tasks with different stimuli: acoustic, acoustic and orthographic, or       orthographic. the target voiceless stop consonants were presented inside 9 word       pairs, spelled with one or two letters. acoustic and auditory analyses revealed       that the target consonants were longer in words spelled with double than with       singleton letters, regardless of task.        we argue that l2 speakers decode l2 orthographic representations using l1       orthography-phonology correspondences. this affects their pronunciation, even       leading to the establishment of a phonological contrast (singleton-geminate) that       is unattested in the target language.
collaborative remembering is a joint activity that involves the       establishment and reinforcement of a common ground. in this study, we investigate       some ways in which collaborative remembering involves interactive coordination of       non-verbal behaviors. our data consist of video recordings of small groups of       people that are reconstructing holiday memories together. for each 500 ms, these       videos have been annotated in terms of the participants' bodily behavior and       posture, including variables such as manual gesture, shoulder shrugs, leaning       direction and gaze. we compared instances of 'simultaneous alignment' (two or       more people concurrently performing the same behavior) and 'sequential alignment'       (two people performing the same behavior in short temporal succession) to chance       baselines, and found that the latter is more common that the former. our analysis       furthermore suggests that the degree to which participants coordinate their       behaviors is stable across the course of the conversation (i.e.,       time-independent), but connected with specific activities within the larger       discourse of collaborative remembering.       
twenty 3.5- to 4-year-olds participated in a study to investigate       children’s understanding of the representative and communicative nature of       iconic gestures. two toys, one of them with a sticker attached, were presented to       the child. it was not possible to request the toy with the sticker by asking       (experimenter wore headphones) or pointing (toys were too close together), but       they could show the experimenter which toy they wanted by performing the correct       gesture. children had to generate the correct iconic gestures themselves as the       gestures were not modeled during test trials. on 70% of the trials children       performed a correct gesture (p = .045), instead of only producing other response       types (no response, verbal request, wrong gesture, pointing). this study shows       that children understand that iconic gestures can represent objects, and also       that they can use iconic gestures to communicate.
recent work in experimental semiotics has started to investigate       the cognitive processes supporting the emergence of human communicative systems.       we present a computational model of the cognitive processes involved in       establishing a novel referential communicative system, as operationalized with       the tacit communication game (tcg). this experimental paradigm has been used to       study the socio-cognitive underpinnings of human communication. we model how       players of the tcg can successfully generate and understand communicative       behavior in a novel, visuospatial domain using structure mapping theory (smt).        many of the processes necessary to communicate in this game are forms of       analogical reasoning that are captured by smt (e.g. abstraction and analogical       transfer). yet, we also identify cognitive processes—not yet formalized       under smt—that are necessary for the genesis of new communicative systems.       this is an important first step in formally characterizing this creative       socio-cognitive ability.
empirical evidence has accrued suggesting that we are able to       evaluate our own thoughts and actions by means of metacognitive judgements. we       are interested in how these are formed and what evidence they are based on. it       has often been assumed that decision time is a frugal cue for confidence       judgements: the longer it takes us to form a decision, the less certain we are.       it could be, however, that this association is just a by-product of the       underlying mechanisms, one of which could be variability in the accumulation of       evidence. in our experiment, participants had to judge whether the average colour       of an array of eight coloured shapes was either red or blue. we critically       manipulated the variability of information in this multi-element array. our       results suggest that for conditions with matched difficulty, variability had a       significant influence on confidence with more variable arrays leading to less       confident judgements.
this paper explores two current issues in human conditioning: it       addresses whether human pavlovian conditioning is the product of a single       propositional system (mitchell, de houwer, & lovibond, 2009) or dual-systems; one       propositional in nature and dependent on logical reasoning, the other functional,       link-based, and dependent on statistical contingency (mclaren, green, &       mackintosh, 1994). additionally, the current experiment provides insight into the       processes underlying both a-b-a and a-b-c contextual renewal in humans; a process       that is often explained using functional (bouton, 2004; pearce, 2002) or       propositional (havermans, keuker, lataster, & jansen, 2005) accounts.       participants were exposed to an electrodermal contextual renewal paradigm in a       bi-conditional design, whilst measures of both conscious expectancy and autonomic       skin response were collected. our results demonstrated that, despite successful       acquisition and extinction for both measures, contextual renewal was only       observed for conscious expectancy in the a-b-a renewal condition.
existing studies on causal structure learning are largely       restricted to single-shot interventions, usually in constrained or deterministic       scenarios. however, real world causal learning is generally noisy, incremental       and constrained only by prior beliefs. here we describe experiments where       participants were incentivised to infer the causal structure of probabilistic       models through the free selection of multiple interventions. participants’       sequences of intervention choices and on-line structure judgements were measured       against those of an efficient bayesian learner, which integrates information       perfectly and intervenes to maximise expected utility. successful participants       were systematic and learned effectively, but chose markedly different       intervention sequences to those of a bayesian learner. overall, we find evidence       suggesting that causal structure learning is achieved by iteration of simple       action-selection and causal-attribution mechanisms.
individuals experience a redundancy gain when they respond faster       to two signals than one. this benefit can derive from statistical facilitation of       independent decisions (raab 1962) or from the co-activation of signals before a       decision (miller, 1982). here we applied these tests to the redundancy gain that       occurs when pairs of participants work together to detect targets. we also       compared gains when each partner was responsible for one of two targets versus a       different spatial region. the results showed pairs were more efficient than       individuals, and that this gain was greater when the task was divided by target       identity versus by space. we also found that the collaborative redundancy gain       could be characterized as co-activation, meaning that the benefit of       collaboration exceeded that predicted by statistical facilitation. these results       serve as a proof of concept that models developed to understand information       processing in individuals can help characterize collaborative performances.
reading complex graphs has been shown to be difficult for diverse       groups of participants from different backgrounds and different levels of       expertise in the task domain. this study investigated the impact of temporal and       spatial task aspects for reducing complexity and increasing performance for a       surgical task with medical students.         85 premedical and medical students solved an anatomy test on the gallbladder, a       test on the steps of the procedure of removing the gallbladder, and a test       combining both in a web-based survey. for all 3 tasks, performance increases with       years in college. more interestingly, medical students performed best for the       combined task and worst for the anatomy task.        this implies students could use temporal and spatial relationships to overcome       knowledge gaps to solve the complex task. having an idea what to do first and       where to do it, helped students to reconstruct a complex surgical task.       
	some of our generic knowledge is based upon what we consider to       be normal instances of kinds of things.  we expect a normal dog to be       four-legged; if it is not four-legged, we assume that something is wrong with       this particular dog, or that it is incomplete as a kind of thing dog.  prasada &       dillingham (2009) showed that one reason we expect certain properties to be       present is because we understand them to be aspects of the kinds of things.  our       research offered an alternative hypothesis: these normative expectations are due       to these distinct properties being beneficial in some way.  four experiments       investigated this using statements that prompted responses for normative       expectations.  we found that while the beneficence of these properties does       underwrite normative expectations to an extent, the predominant understanding was       that these expectations were grounded in the aspectual quality of these       properties.
agents generalise abstract conceptual knowledge across different       contexts. for example, an individual negotiating a new computer program will draw       upon experience with similar programs, such as how to use a drop-down menu. what       are the rules governing such knowledge transfer? here we offer a formal bayesian       account of generalisation, in which observers update a hierarchical model that       incorporates knowledge about the statistical moments of the distribution from       which information is drawn. we use this model to predict performance on a       foraging task that involved hunting for hidden rewards in a virtual       two-dimensional grid environment. in this task, contextual cues signalled not       only the likely reward location (bivariate mean), but also the pattern (bivariate       dispersion). observers optimally integrated noisy cues about the probable reward       location with information from these cues. this model and data offer a formal       account of how humans learn abstract conceptual information. 
acquiring new skills is not a set-in-stone process and students       often take various paths to the goal; the acquisition of the required skill. to       assess this learning process, previous studies used hidden markov models to       separate the cognitive stages of a problem solving task similar to solving       algebraic equations (e.g. anderson et al., 2012; anderson, 2012). because of the       slow nature of fmri recordings, this method can only discriminate between       relatively long states in the process. this study extends the approach by       including eye movements as a predictor of state, in an attempt to increase       temporal resolution of the method. the results show that eye movements can be       used to trace the characteristics of the problem the subject is working on.       because tracking eye movements is a non-invasive measure that can be used outside       experimental settings, this can benefit the discovery of problems students       encounter while solving algebraic problems.
many controversies in cognitive science hinge around the divide       between the general and the particular. in language research, the declarative       procedural (dp) model proposes that procedural memory deals with the       generalizable aspects of grammar, while exceptions are handled by declarative       memories. extending the dp model, we believe that the existence in memory of a       semantic component which stores the prototypic information and an       ‘episodic’ component that stores both the exceptions to the       prototypes and the exceptionally common stimuli, could explain results on       polysemia research. we studied the representation of polysemous words. we tested       whether different senses of a polysemous word prime each other. although in       general there is no priming there are items showing positive priming and others       showing inhibition. we then used bimodal priming in order to understand the       effect of context in both types of items. our results support the idea that       lexical representation uses different memory systems.
languages partition the world in different ways—for example,       the categories named by spatial terms vary substantially across languages.  yet       beneath this linguistic variation there may lie universal cognitive tendencies.        khetarpal et al. (2010) found that speakers of dutch and english, despite       differences in their linguistic spatial systems, sorted spatial scenes       similarly—and more like the finer-grained language, dutch.  we asked       whether this preference for fine-grained sorting extends to two new languages:       máíhɨki, a language of peruvian amazonia, with a fine-grained       spatial system, and chichewa, a bantu language of southeast africa, with a       coarse-grained spatial system. despite the great range in spatial naming       represented across these languages—both in the granularity and the shape of       their spatial categories—we found that speakers of all four languages       sorted finely, and thus similarly to the finer-grained languages,       máíhɨki and dutch.  these results suggest that spatial cognition,       unlike spatial language, is universally fine-grained.
in order to navigate and make sense of one's surroundings, a       person must integrate pieces of information into larger wholes. on the flip side,       the person also must be able to differentiate among more detailed pieces of       information. adaptive functioning requires the coordination of both processes,       where one can flexibly switch from integrated higher-order patterns to       differentiated details and vice versa. what is the nature of this coordination?       through fractal and recurrence quantification analyses used in three visual tasks       (search, matching and classification), we provide evidence that this coordination       has properties of dynamical systems, modulated by task features. findings are       discussed in terms of organism-environment coupling; in which local-global visual       processing is conceptualized as a soft-assembled and self-organized system.
the current study examined whether language experience affects the       processing of visual information. spanish-english bilinguals and english       monolinguals completed a visual search task in which no overt linguistic       information was provided. participants were shown an image of a target (e.g., a       chair) and were asked to locate that object from an array of four images while       their eye-movements were tracked. english competitor trials contained an item       whose english name overlapped phonologically with the english name of the target       (e.g., chair-chain); spanish competitor trials contained an item whose spanish       name overlapped phonologically with the spanish name of the target (e.g.,       silla-silbato [chair-whistle]). whereas all participants looked more often at       english competitor items than at items that did not overlap phonologically with       the target, only the spanish-english bilinguals looked more often at spanish       competitor items. results suggest that speakers with different language       backgrounds vary in how they respond to non-linguistic, visual information.
previous research has well-documented that naïve learners       struggle when attempting to understand emergent phenomena. misconceptions often       arise as learners tend to apply patterns of cause-and-effect between entities to       explain these emergent processes. we posited that comprehending emergence       requires learners to construct a different conceptual model, namely a functional       schema, emphasizing functional relationships among entities and their       interactions that are central to how emergent phenomena arise. a promising       strategy to promote generation of such functional schema is contrasting examples.       this paper reported an intervention study with 86 middle school students       examining the effect of contrasting scenarios in helping learners generate a       functional-relationship-centered schema to understand global warming.       students’ correct and misconceived explanations in pretest-posttest       protocols were analyzed. results showed contrasting scenarios motivated learners       to develop the critical functional schema, which led to their eventual       understanding of the mechanism of global warming. implications on schema       construction on understanding emergent systems are discussed.
technology can be used to create student-centric learning in       diverse ways, including the use of social media platform(s) and interactive       simulations to teach inductive thinking, and games to facilitate self-directed       learning. but, teacher-centric teaching is important as student-centric learning       is; both aspects contribute to the student learning process, although the former       has hardly been considered explicitly. specifically, while technology develops       apace, that teachers might continue to prefer traditional teaching modes and       styles is an issue that should not be taken lightly, because teaching       performances can be compromised if these modes and styles were compelled to       evolve prematurely. i will particularly discuss the apprehensions that teachers       might have as a technology-based teaching culture rapidly emerges, and how the       dissonance between (non-)preferred modes of teaching and learning in this context       might be resolved, in order to promote a technology-enhanced education system       that ultimately benefits both teachers and students in a practical way.
pure alexia (pa) is characterised by abnormally strong length       effects in word reading times. it is often thought to result from damage to       visual processing. this visual damage was also found to cause impaired object       recognition performance (e.g., roberts et al., 2012), suggesting a general visual       deficit. many computational models of reading have successfully simulated       different forms of acquired dyslexia (e.g., coltheart et al., 2001; plaut et al.,       1996). however, an adequate computational account of pure alexia has yet to be       produced. we developed a large-scale and complete connectionist model with       asymmetric hemisphere processing to support both word and object recognition.       when damage was applied to the left visual processing layer in the model, the       model produced abnormal length effects and impaired object recognition similar to       those seen in pa patients. the results provide evidence to support the view of a       common visual processing in visual word recognition.
masked repetition has been suggested as the reliable paradigm       investigating the pre-lexical processing of english words. this suggestion has       the supportive evidence that masked repetition effects do not interact with word       frequency. chinese compound words are the combinations of two constituent       characters which have independent lexical properties. the lemma model argues that       the lemmas of constituents would increase masked repetition effects of       low-frequency compound word when the constituent characters have relative higher       frequency. to verify this argument, this study manipulated the frequency and the       morphological aspects of constituent characters. the critical results are the       increased masked repetition effect of low-frequency coordinative words which have       at least one high-frequency characters and the null interaction of masked       repetition effect and word frequency for the compound words having meaningless       constituents. the approaches to modify the current lemma model are discussed       according to these findings.
twenty-five children with developmental coordination disorder       (dcd) and 25 age- and gender-matched typically developing (td) children were       tested on writing-related visual motor tasks with a self-developed electronic       assessment tools: “writing start”. children with dcd were diagnosed       according to the dsm-iv diagnostic criteria. td children were recruited from       community. twenty figures with different complexities and sizes were used in the       tasks. error number, error time, and error pathway, each representing a deficit       in action, temporal and spatial motor control of writing movement, were compared       between groups. the error number was significantly larger in the dcd group than       that in the td group. the error time and error pathway were also longer in the       dcd group than that in the td group, especially when the figures were smaller and       more complicated. children with dcd indeed have difficulties in mastering visual       motor skills for writing.
the compromise effect and attraction effect are examples of       irrational choice in multi-attribute decision making. their underlying mechanisms       are assumed to be differences in the trade-off structure of each choice set.       recent research on the construal level theory showed that a high construal level       decreases the compromise effect, but increases the attraction effect. further,       studies on the dual process theory showed that the depletion of       participants’ cognitive resources increases the attraction effect, but       eliminates the compromise effect. it is therefore important to examine       compensatory (or uncompensatory) information search based on trade-off structure       in these context effects. we examined the influence of the construal level of       participants’ choices and the depletion of       participants’ cognitive resources for the above two context effects.       furthermore, we analyzed eye movements as a measure of the information search       process, to examine the relationship between the construal level theory and dual       process theory.       
berlyne, the canadian psychologist, famously conjectured that the       aesthetic preference for visual patterns is an inverted-u function of their       complexity. in my own research (chipman, 1977), i developed and studied a large       set of patterns, exploring what determined their judged complexity. these       included patterns with several types of well defined structure, as well as       randomly generated patterns. several experiments explored the judged aesthetic       quality of such patterns. judged aesthetic quality was not any simple function of       judged complexity. not surprisingly, there are significant individual differences       in aesthetic preference, including differences in preference for different types       of visual structure.
recent studies show that visual search is often not well       characterized as either a purely parallel or serial search strategy.       subsequently, the literature and computational models have evolved from       traditional parallel and serial descriptions to a continuum of search efficiency.       it has been demonstrated that search efficiency does not improve with       simultaneous delivery of target features in a conjunction-search task.       interestingly, search efficiency does improve when non-linguistic visual delivery       of target features appears incrementally and concurrently with the display onset,       but not prior to display onset. in our current experiment, we explore the       temporal constraints of the facilitatory effect found with concurrent incremental       information processing. the results explain that linguistic and non-linguistic       mediation of visual search, provided sufficient time to process, is chiefly due       to the incrementality of target feature delivery when search has begun. this       finding supports an interactive account of visual attention.
in schools today, students pursue individual academic subjects,       such as physics, mathematics, and biology. by compartmentalizing these subjects,       students may not be able to connect concepts from different disciplines       competently to explain universal phenomena that occur in everyday living. under       this view, it is essential to inculcate an overarching philosophy with which one       can capably unify all taught subjects. we first consider logical positivism as an       overarching philosophy, and the benefits and implications of teaching it to       students. we then illuminate the importance of inculcating broad-based       philosophical thinking in students, and discuss how this pedagogical approach       deepens students’ understanding in, and increases their interest towards,       the subject matter that they learn, as well as trains students’ abilities       to examine and interpret natural phenomena in logical ways.
it was previously proposed that the burst of creativity in the       middle/upper paleolithic following the appearance of anatomically modern humans       was due to the onset of contextual focus, the capacity to shift between an       associative mode of thought conducive to forging connections and breaking out of       a rut, and an analytic mode conducive to logical problem solving. hominids could       then generate ideas in an associative mode, and refine them in an analytic mode,       and process representations at multiple levels of detail, and from different       perspectives. this resulted in richer understandings of their world. it is       proposed that the foxp2 gene, which evolved at this time, is responsible for       onset of contextual focus. foxp2 thereby created an unprecedented need for       language to (a) keep track of representations for oneself, and (b) capitalize on       different perspectives of others. this explains why foxp2 is implicated in       language but not uniquely associated with it.
in chinese, character configuration and orthographic combination       are acknowledged to influence character recognition. also, it was widely accepted       that lexical access ability progresses as reading skills improved and vocabulary       increased. the present study aims to reveal the effects of configuration type and       radical properties by comparing different development stages of chinese learning.       a character decision task was used in which radical position-based frequency and       radical position regularities within two different configurations were       manipulated. 15 third-grade 27 sixth-grade schoolers, and 41 undergraduate       students were asked to identify whether the 120 pseudo-words conform to radical       position regularities. accuracy was recorded as measurement to examine the       effects of configuration and orthographic combination. the analysis revealed       different patterns of frequency effect and regularity effect between the two       configurations. furthermore, age variation was observed for both types of       configurations. in conclusion, orthographic and configuration knowledge are       acquired gradually and play distinct roles in chinese recognition.
previous research assumed the eye movement patterns change along       with the growth of word knowledge while children become skilled readers. in this       study, the effects of orthographic and configuration information on chinese       character recognition were investigated by comparing eye movement patterns from a       developmental perspective (15 third-grade 27 sixth-grade schoolers, and 41       undergraduates). eye movement patterns were recorded in a character decision task       by varying configuration type (left-right, up-down), radical position-based       frequencies (hh, hl, lh, ll), and radical position regularities (p, sn, wn). the       results showed that the two different configurations lead to different eye       movement patterns: (1) radical position regularity effect was only significant at       the left-right configuration for all age groups; (2) frequency effect and       development variation appeared for both two configuration types. these findings       highlight the importance of configuration knowledge and orthographic awareness       for learning chinese characters.
in our daily social interactions we can infer others people       intentions from the observation of their actions. in general, two brain systems,       the mentalizing and the mirror neuron system, have been implicated in       understanding other’s intentions. however, there is little knowledge       whether and how these two systems may cooperate in correctly understanding       communicative interactions. we used functional mri to establish how mirror and       mentalizing regions contribute to the implicit encoding of communicative       intentions, proposing that being directly involved during social interaction       would be mediated by both systems. in particular, we investigated the involvement       of those systems in distinguishing communicative from private intentions as well       as other directed (“third-person perspective”) from self-directed       (“second-person perspective”) intentions. categorical and functional       connectivity analyses showed that the mentalizing and the mirror neurons system       were simultaneously involved in processing communicative intentions in general       and more strongly coupled in self directed communicative actions. 
the present study explores how people learn about a causal system       by interacting with it. participants were given the task to identify the       operation of virtual '"computer chips" by setting the value of various components       and observing how those interventions influenced the setting of other components.       across conditions we manipulate the complexity of the causal system (i.e., number       of nodes and connections), the number of alternative hypotheses (i.e. possible       causal graphs) on each trial, and aspects of the "temporal stability" of the       learning environment (if repeated interventions were made on a single, stationary       system or if the system reset to different starting states following each       intervention). interventions were modeled by comparing them to an optimal       bayesian learner who chooses interventions to quickly reduce uncertainty about       the structure. our results suggest that naive internet-recruited subjects choose       highly informative interventions, but also deviate from the predictions of the       optimal model in certain ways.
children with specific language impairment (sli) lag behind peers       with typical language (tl) in vocabulary. we ask what impact this lag has on       shape bias (generalization based on shape in naming contexts [“here’s       a dax; find another dax”] but not classification contexts [“look at       this; find another like this”). smith (2000) argues that shape bias depends       on and drives vocabulary development; vocabulary is a basis for detecting       covariation between objects and names, and name learning accelerates once the       bias emerges. 51 three and four year-old children (16 sli, 16 matched tl, 19       additional tl) participated in naming and classification tasks, a paired visual       association (pva) task, and an assessment battery. the sli group was       significantly worse at pva and did not exhibit a shape bias. individual       differences revealed wide variation in both groups, and that shape choices in       naming were better predicted by pva than standardized assessments.
we investigated the temporal dynamics of response choice in a       decision-making task by examining the evolving implicit responses indicated by       hand movements made before an explicit response is selected. participants (n=31)       judged which of two cars would go faster when the underlying rule was plausible       or implausible and when two response choices differed with respect to one or two       causal variables. participants completed 300 trials in five blocks. we found an       interaction between trial type, block, and plausibility of rule. in earlier       trials in the implausible rule condition, there was greater deviation towards the       distracter response before selecting the correct response. participants given       implausible rules demonstrated less activation of competing representations over       time as they induced the underlying rules, particularly on trials in which       response choices differed on both causal variables. mouse trajectories did not       change across blocks for participants given the plausible rule, suggesting they       learned the rule early.
insightful problem solving is a vital part of human thinking, yet       very difficult to grasp. the “aha! experience” is often regarded as       the defining characteristic of insight. traditionally, insight has been       investigated by using a set of established “insight tasks”, assuming       that insight has taken place if these problems are solved. however, the debate       about which problems actually trigger insight is still not resolved, since there       is no clear behavioural marker for the occurrence of insight. in the present       work, we therefore aimed at testing the validity of three classical insight       problems by directly asking participants about their solution experiences. our       results suggest that participants solve insight problems also without any aha!       experience, casting doubt on the common approach of using a priori defined       insight problems. consequently, we advocate the use of direct insight ratings by       participants, determining for each problem individually whether it was solved       with insight or not.
previous research has examined the use of graphical overviews as a       way to structure students’ self-regulated, online learning. although       findings have suggested that graphical overviews can improve learning from online       content, there has been little direct evidence as to why this benefit may occur.       in this research, eye tracking and verbal protocols were gathered as 26       pre-service teachers used a graphical overview or keyword interface to choose       online resources for an educational task. fixation times and pupil diameter were       analyzed as measures of cognitive effort; results demonstrated that pupil       diameter was significantly lower when participants used the graphical as compared       to the keyword interface. protocol analysis was used to examine the depth of       processing during search and evaluation; results showed that participants using       the graphical overview engaged in deeper analysis of domain content. results       provide evidence for the importance of graphically-based cognitive offloading       during “searching to learn” tasks. 
cultural variation in families’ shared engagement                    this study examines whether indigenous-heritage mayan mothers and their       young children are more likely than middle-class european american mothers and       their children to engage by blending agendas in fluid collaboration while       exploring novel objects together.  fluid collaboration appears to be encouraged       in many indigenous communities of the americas, where children often collaborate       in ongoing family and community endeavors (rogoff, 2003; mozier & rogoff, 1993,       2003).  the present research submits audio signals of videotaped observations of       mothers and their children in home interactions to micro-analysis using       spectrographs, to compare the interactions of mayan and european american       families (gratier,  2003, 2013; malloch, 1999; trevarthen, 2008).  in the visual       representations of their vocalizations, we find evidence that the mayan families       more frequently use smooth collaboration whereas the middle-class european       american families appear to struggle more to establish a shared rhythm in their       interactions.       
action recognition is important for social interactions. because       little is known about the visual tuning properties of processes involved in       action recognition, we examined the visual tuning properties of action       recognition by means of a behavioral adaptation paradigm. participants were       adapted to images showing a person hitting or waving and subsequently categorized       test images showing an ambiguous action as either hitting or waving. we found the       perception of the test images to be significantly biased away from the adapted       action (action adaptation aftereffect (aaa)). subsequent experiments ruled out       that the aaa was not merely driven by the adaptation of local visual contrast or       the emotional content of the action. however adaptation to action words (e.g.       “hitting” or “waving”) did not induce an aaa. finally we       found evidence for the aaa being modulated by the social context in which an       action is embedded, suggesting high level influences on action recognition. 
considerable research has demonstrated so-called learned       categorical perception (cp) effects, where learning to classify a set of stimuli       leads to either compression (within-category stimuli judged to be more similar       and/or confusable than before learning) or expansion (between-category stimuli       judged to be less similar and/or confusable than before learning) or both. the       issue of why category learning causes one type of effect or the other has not       been systematically investigated, but previous research suggests that highly       discriminable stimuli may tend to produce compression while stimuli that are       difficult to discriminate may tend to produce expansion. we report a series of       studies testing the effect of stimulus discriminability on the type of learned cp       effect produced using both similarity and xab measures of the effects.       preliminary results suggest that different measures of categorical perception       reveal different effects, and that category structure may also be relevant.
birch & bloom (2007, psych. sc. 18, 382-386) suggest that adults'       reasoning about others’ mental states is influenced by their privileged       knowledge about reality. when asked where a person described in the story would       search for a missing object, subjects tend to judge with higher probability that       the person would search in a particular box, when they know that the object is       indeed in that box. however, the results of their experiment could be an effect       of unintended priming in the materials, i.e., the increased attention towards the       box might be also caused by reading about it in the task instructions. in a new       version of the experiment, we controlled for this factor by priming different       locations in the instructions. the results show that it is unlikely that priming       is the source of the birch and bloom's observations: only knowledge about reality       changes the strategies in reasoning about others’ actions.
the sensory consequences of intentional actions are perceived to       be attenuated compared to equivalent but externally generated stimuli. it is       thought that forward models in the sensorimotor system partially cancel       predictable reafferent sensory feedback in order to bias attention towards more       novel or unexpected stimuli. but does merely observing familiar actions also       trigger forward models with attendant sensory attenuation? previous studies       investigated this question in the auditory modality with conflicting results. we       conducted two attenuation experiments in a visual modality to conceptually       replicate and generalize previous findings (exp 1), and to control for       differences in temporal predictability and attention which may have confounded       previous studies (exp 2).        we found that movements initiated by humans (self or other) were attenuated       compared to computer movements, and self-initiated movements were the most       attenuated. adding go signals prior to movements counteracted attenuation.       perceived speed is thus influenced by agency as well as attention.
many previous studies showed that the causal information       externally given (hereafter external information) did not succeed in changing the       causal structure driven from the covariation data when the external information       and the covariation data were in conflict. we speculated that the salience of the       external information is crucial in causal inference. the external information did       not affect the causal inference when the external information and the covariation       data were simultaneously presented in experiment 1. however, when the external       information and the covariation data were sequentially presented and participants       were asked to report the causal structure and the strength each time in       experiments 2 and 3, participants were more likely to report the causal structure       of the external information when the covariation data were drawn from a different       causal structure. results of the three experiments showed that the external       information can override the covariation data under certain conditions.
learning new words involves consolidation. after one night's       sleep, not only is explicit knowledge about the novel words enhanced, but the new       words also now compete with similar-sounding existing words (dumay & gaskell,       2007) during word recognition. the present study assessed whether lexical       consolidation strips off surface details of newly learned words, producing more       abstract representations. we manipulated the speaker's voice between exposure and       test. participants learnt one set of novel competitors (such as 'shadowks' for       'shadow') seven days before the test, and another set immediately before the       test. each word was learnt in a male or a female voice, and was tested in either       the same or the other voice. cued recall and phoneme monitoring showed stronger       memory for the seven-day old items and, if anything, an enhanced voice effect       (i.e., better performance in the same voice condition) after seven days.       crucially, our most indirect measure of lexical competition showed that only the       seven-day old items (as expected) engaged in lexical competition, but only when       the input preserved the voice in which they had been encoded. these findings       indicate that consolidation does not make word representations more abstract:       voice specific details do not just survive lexical consolidation; they are       enhanced by it.
when individuals are presented with complex arrays at       non-canonical orientations (e.g., rotated text) they frequently physically rotate       to approximate the orientation of the stimulus (i.e., external normalization).       one view of this natural behavior is that individuals are offloading internal       cognitive demands (e.g., internal normalization) by adopting an external solution       (i.e., external normalization). we test this account here by combining a stimulus       rotation manipulation with a stimulus repetition manipulation. previous research       has demonstrated that stimulus repetition reduces the cost of stimulus rotation       on performance. in other words, repetition putatively reduces the       “internal” costs of stimulus rotation. thus, stimulus repetition       should reduce the frequency of external normalization. consistent with the       cognitive offloading account, repetition reduced the frequency of spontaneous       physical head rotations while individuals read rotated text. discussion focuses       on the implication of these results for understanding cognitive offloading and       the embodied and embedded nature of cognition.
in many domains of cognitive psychology, it is proposed that       people are equipped with a repertoire of strategies to solve the problems they       face. for instance, it is proposed that when people use multiple cues to make a       probabilistic inference about a criterion, they sometimes rely on simple       heuristics and sometimes apply more elaborate additive strategies. indeed, many       studies suggest that people’s inferences can be described by different       strategies in different situations. however, critics of this view suggest that       people do not apply different strategies but instead adjust one single strategy       to the characteristics of each situation. here we examine the strategies that       individuals use when available resources change. therefore, we continuously       change the cost of deliberation time. the behavior of participants at the       transition from fast and simple behavior to slow but optimal information       integration offers insight into whether people select different strategies or       continuously adjust one single strategy. 
language can be viewed as a set of cues that subtly modulate the       comprehender’s thought processes. for example, the literature suggests that       people perceive direct speech  as more vivid and perceptually engaging than       indirect speech. we sought to address how this alleged vividness is evident in       comprehenders’ mental representations in a series of experiments. our       results do not support the idea that, compared to indirect speech, direct speech       enhances the accessibility of information from the communicative or referential       situation during comprehension. neither do our results support the idea that the       hypothesized more vivid experience of direct speech is caused by switching from       the visual to the auditory modality. however, our results do show that direct       speech leads to a stronger mental representation of the exact wording of a       sentence than does indirect speech. these results show that language has a more       subtle influence on memory representations than was previously suggested. 
explanation is often cited as an effective learning tool, but much       work remains to determine the influence of explanations on different types of       material to be learned. evidence from category learning suggests that explanation       may drive the learner to identify underlying regularities that fit a general       pattern (williams & lombrozo, 2010). in a pilot study, we examined whether       explanation could be used to improve understanding of fraction magnitudes and       whether explanations of specific inequalities are more or less effective than       explanations of sets of inequalities. results revealed that generating single or       set explanations did not affect test or transfer accuracy, but individuals       indicated strong and consistent preferences for particular types of explanations       (i.e. conceptual, procedural, or rule-based). further studies are being conducted       to identify individual differences that may predict preferences for different       kinds of explanations and their effect on subsequent learning and       understanding.
many common words have spatial associations (e.g.,       “bird,” “snake,” “jump”, “crawl”)       that influence perception at congruent and incongruent locations. for example,       “bird” hinders identification of a square at the top of a display.       many researchers have attributed this spatial interference to location-specific       perceptual simulations: the word “bird” shifts attention upward and       evokes the perceptual representation of a bird, which impairs identification of       an unrelated visual target either by visually masking it or by engaging the       neural systems necessary for visual perception. however, we report that a large       sample of nouns (experiment 1) and verbs (experiment 2) of high and low       imageability (and visual strength) elicited equivalent spatial interference.       thus, perceptual simulation failed to explain the spatial interference effect.       experiment 3 instead supported an event coding explanation: target objects are       coded for their congruence with both the cue word and its implied location, and       conflicting codes interfere with responding. 
since the original experiments on choice blindness for faces       (johansson et al 2005), many studies have extended the phenomenon to other       domains but few have focused on attaining a deeper understanding of the       phenomenon itself. we here report on an experiment which closely follows the       original study (albeit in computerized form and with a singaporean population),       with additional elements aimed at explicating the causal structure and temporal       dynamics of the underlying processes.        contrary to intuition, we find that subjects who notice and immediately report a       “manipulation” trial still miss about half of subsequent manipulation       trials. detection is also found to be highly sensitive to the form and timing of       the opportunities to report. we also investigate the effects of choice       manipulation on attractiveness ratings, finding that manipulations do modulate       subsequent attractiveness ratings but that this effect falls below significance       after a 2-week interval.       
a growing literature suggests that readers generate predictions       about various aspects of incoming linguistic input. do expectations from context       map onto lower-level expectations, and if so, how? we propose that comprehenders       use internally generated predictions to explain the source of the input. in two       experiments, we tracked eye-movements as subjects read sentences that generated       strong (the boy saved the xxx) or weak (mary had the word “xxx”       tattooed …) expectations for nouns. across contexts, subjects encountered       target words (xxx) that had visual-form features that were either typical or       atypical of nouns. in strongly predictive contexts, first-fixation and gaze       duration measures were longer when the form of the target word was atypical with       respect to the predicted category. in the less-biased contexts, no effect of       word-form typicality occurred. these experiments provide eye-movement evidence       that linguistic context is used to generate perceptual expectations about       form-based properties of upcoming words during reading.
we used a simple artificial neural network model to begin the work       of understanding what principles underlie effective interventions for       developmental disorders of language and cognition, from the perspective of       neurocomputational mechanisms of development. the work aims to complement a       clinical perspective of the principles of effective intervention. our study       explored the effectiveness of different types of intervention modeled as items       added to the normal training set. we assessed whether best interventions were       specific to problem domains, specific to deficit types, and/or dependent on when       in development they take place.
models of word recognition assume that information about the       orthographic form of a word (morpheme) must be available before access to that       word's (morpheme's) meaning is possible. in prior work we have demonstrated that       semantic similarity influences even early morphological priming (feldman,       kostić, gvozdenović, o’connor, & martín, 2012; feldman &       martín, 2009).         in two experiments conducted in english, we used a forward-masked lexical       decision task to assess whether processing differs after exhaustively       decomposable (stem+affix; e.g., pastor-past) and partially decomposable       (stem+nonmorphemic string; e.g., pasta-past) primes in semantically dissimilar       prime-target pairs.         results using linear mixed effect models on inverse transformed (-1000/rt)       latency data with two separate pcs for the contributions of form (negative) and       for frequency (negative) and previous rt as a predictor, failed to show different       patterns of facilitation after exhaustively and partially decomposable primes;       both of which differed from unrelated controls. spelling did not interact with       prime type but poor spellers varied more across the session.        
prior research in learning with graphic organizers has revealed       that learners can make use of graphical overviews to increase their learning in       online environments, especially when these visual supports are provided before       learning. this research examined the extent to which the format of feedback in an       online learning environment impacts students’ processes and outcomes during       a self-regulated learning task. students wrote scientific essays that were       analyzed by a personalized learning service (the customized learning service for       conceptual knowledge: click). feedback on essay content was presented using       either a visual (node-link) representation or a (text-based) list view.       preliminary data reveal that learners presented with the visually-based feedback       engaged in more effective self-regulated learning processes (i.e., planning and       goal-setting) compared to learners provided with list-based feedback. results       demonstrate that the format of external feedback in self-regulated learning       environments play an important role in supporting students’ implementation       of effective self-regulated learning strategies.
language is a collaborative act: to successfully communicate,       speakers must generate semantically valid utterances that are sensitive to the       knowledge state of the listener. we asked whether parents’ spatial       descriptions are tuned to their children’s spatial knowledge. parent-child       pairs (n=16, m child age 4;1) viewed identical complex spatial arrays on separate       computer screens. parents were asked to describe target objects so that their       child could identify them on their own screen. children’s knowledge of       left/right was independently tested using a comprehension task. a hierarchical       statistical model of the experimentally elicited spatial language predicted that       the probability of parents using left/right was greater for children that       achieved higher comprehension scores, indicating successful communicative       adaptation. this result did not hold for parents of children with severe spatial       impairments (williams syndrome), suggesting that there is considerable variation       in how well parents tune their language to their children’s level of       spatial language and knowledge.
the interactivity framework (chi, 2009) proposes learners       experience greater learning benefits as they become more generative with learning       material. this research investigated the active-constructive-interactive       framework in the context of graphical organizers before a self-regulated, online       learning task. graphical displays were node-link diagrams, where nodes identified       important domain concepts and link labels described the relationship between       concepts. conditions examined: passive (in which nodes and links were provided);       active (in which nodes were provided and learners revealed link labels on       demand); and constructive (in which nodes were provided and learners generated       link labels). findings were consistent with the interactivity framework for       constructive learners, who integrated more concepts into posttest concept maps       and included more deep (relational/causal) statements in their posttest essays.       however, there were no significant differences for passive and active conditions.       results demonstrate that constructive activities may be necessary to support       deeper learning outcomes in activities used before self-directed learning       tasks.
constant entropy rate (cer) and uniform information density (uid)       are two hypotheses that have been put forward to explain a wide rage of       linguistic phenomena. however, the concrete definition of these hypotheses is       unclear for statistical research and a direct and in-depth evaluation of these       hypotheses from their definition is missing to our knowledge. here we consider       four operational definitions of uid: full uid (uid holding for any combination of       elements making the utterances), strong uid (uid holding for any utterance that       has non-zero probability) and initial uid (strong uid holding for utterances       beginning with a particular element). here we examine the logical dependencies       between these hypotheses. the comparison of the assumptions and predictions of       these hypothesis with hilberg's law and other statistical properties of real       human language indicates that cer and related hypotheses are qualitative       different from actual language and suggests that these hypotheses are incomplete       and must be revised.       
we investigated the origins of analogical ability in 7-month-old       infants, using the simplest and most basic relation – that of sameness and       difference between two things. experiment 1 showed infants were unable to detect       and generalize these relations from a single exemplar (as suggested in tyrrell et       al., 1991). experiment 2 used a habituation-dishabituation paradigm and found       that infants could generalize the same-different relation to novel objects with       six to nine training trials. experiment 3 demonstrated that labels influenced       performance:       labeling the relation enhanced performance, but labeling the individual objects       hindered performance. in addition, we varied infants’ prior experience with       the objects and found signatures of relational learning have continuity across       development. in summary, abstraction of relations can be facilitated by       comparison across exemplars, disrupted by the saliency of individual objects, and       manipulated by labeling. these findings are discussed in light of recent debates       about phylogenetic continuity in relational abilities.
spatial-numerical associations were initially studied using       chronometric methods to reveal the orientation of the mental number line (snarc       effect; dehaene, bossini, and giraux, 1993). recent evidence has shown that       unconstrained spatial movements can be valuable in the study of embodied number       representations (fischer and campens, 2009). we used the xbox kinect to record       arm movements in a parity judgment task. we replicated snarc in the horizontal       dimension and found a similar trend in the vertical dimension. movement       amplitudes were also affected by number magnitude. together, these results       generalize evidence for the mental number line to everyday behaviors and suggest       that natural user interfaces (nui) can be used to study embodied cognition.
research on human problem solving may be about to face a       conceptual change from individual to collaborative problem solving. many       challenging problems in the real world are solved by groups or teams. this is       increasingly recognized by the problem solving research community, which       traditionally has emphasized cognitive processes in individual problem solving.       in this paper we argue how approaches for investigating complex problem solving       can be conceptually extended towards collaborative problems solving. we will       present several current examples of how to measure collaborative processes in a       standardized way. one example is the inbox hd, a computer-based in-basket       simulation with collaborative elements. the second example is the scenario       product planning, implemented in the colps hd framework, which involves       chat-based human-to-agent communication.  we will elaborate on how these tools       can be used to emulate realistic collaborative processes in the standardized       setting of a psychological laboratory and indicate directions for future       developments.
children solve explicit false belief (fb) tasks around age 4 but       implicit tasks (e.g. helping) in infancy (e.g. buttelmann et al., 2009). nativist       accounts claim early conceptual competence, masked by performance factors (e.g.       leslie, 2005); sceptical accounts deny competence before age 4 (perner &       ruffmann, 2005). a recent two-system-theory (apperly & butterfill, 2009) provides       an alternative explanation: an early mindreading-system (1) tracks simple forms       of mental states and a later flexible capacity (2) allows cognitively demanding       inferences based on a fully-developed concept of belief. because system 1       operates on relational rather than propositional attitudes it has clear       flexibility-limits: it can represent fb’s about object location but not       fb’s about identity.         we contrasted 2.5-year-olds’ helping behavior in a 2 (identity/location) x       2 (false/true belief) design. results suggest limited performance in the identity       compared to the location task. implications of this finding are discussed and       follow-up studies will be presented.
while most studies in the spatial cognition literature focus on       pointing in a two-dimensional context, (i.e., directional estimates in       a horizontal plane), the mechanisms of pointing in 3d-space (i.e.,       direction estimates including up and down) are much less clearly       understood. based on a paradigm of vidal & berthoz, a virtual tube       system providing a highly controlled environment, we designed a study       comparing 3d pointing performance (i.e., pointing backward to the       starting point or pointing forward to the end point of the experienced       route) following active (drivers) vs. passive (passengers)       exploration. furthermore, we assessed the individual memory strategies       reflected in self-reports and related these to pointing performance       and reaction times.
 anomalous aspects of speech and voice, including pitch, fluency,       and voice quality, are reported to characterize many mental disorders. however,       it has proven difficult to quantify and explain this oddness of speech by       employing traditional statistics methods.        in this study we employ recurrence quantification analysis (rqa) to investigate       the temporal dynamics of voice in three mental disorders. we elicited monological       descriptions of short videos in patients with schizophrenia, depression and       asperger's, as well as in related matched controls. we applied rqa to fundamental       frequency, speech pause sequences and speech rate. the rqa indexes (trend and       entropy in particular) enable us to quantify and automatically discriminate       between populations with >85% of accuracy, highlighting distinctive voice       dynamics in each diagnoses. 
we investigate the linguistic co-construction of interpersonal       synergies. by applying a measure of coupling between complex systems to an       experimentally elicited corpus of joint decision dialogues, we show that       interlocutors’ linguistic behavior displays increasing signature of       multi-scale coupling, known as complexity matching, over the course of       interaction. furthermore, we show that stronger coupling corresponds with more       effective interaction, as measured by collective task performance.
when building a lexicon, young children must first learn       individual word-object mappings and subsequently extend these mappings to new       category instances. recent methodological advances demonstrate that processing       efficiency during the initial mapping process increases between 15 and 24       months-of-age. the current study investigates real-time processing during the       second word learning step, generalization. using a head-mounted eye-tracker,       18-month old children completed a novel noun generalization task with novel solid       objects. many participants generalized names for solid objects based on       similarity in shape rather than similarity in material. the addition of       eye-tracking data in the current study reveals children’s comparison of       test and exemplar objects both before and after novel name presentation.       integrating eye-tracking data with measures of vocabulary knowledge can elucidate       how vocabulary organization speeds the generalization decision. future work will       manipulate syntactic context to examine how children’s knowledge of count       and mass nouns further influences the generalization decision process.
how the brain deals with more than one language and whether we       need different or extra brain language sub-networks to support more than one       language is unanswered question. here, we investigate structural brain network       differences between early bilinguals and monolinguals. using diffusion-weighted       mri (dw-mri) tractography techniques and a network-based statistic (nbs)       procedure (zalesky et al., 2010), we found two structural sub-networks more       connected by white matter (wm) tracts in bilinguals than in monolingual;       confirming wm brain plasticity in bilinguals (luk et al., 2011; mohades et al.,       2012; schlegel et al., 2012). one of these sub-networks comprises left frontal       and parietal/temporal regions, while the other comprises left occipital and       parietal/temporal regions and also the right superior frontal gyrus. most of       these regions have been related to language processing and monitoring (abutalebi       and green, 2007); suggesting that bilinguals developed specialized language       sub-networks to deal with the two languages. additionally, a complex network       analysis showed that these sub-networks are more graph-efficient in bilinguals       than monolinguals and these increase seems to be at the expense of a decrease in       whole network graph-efficiency.
children must distinguish between statements and questions in       order to accurately acquire language, but it is unclear when or how they do it.        experiment 1 examined whether prosodic characteristics of infant-directed       questions and statements could differentiate them. statements and yes/no       questions differed on several dimensions, but statements and wh-questions did       not.  experiment 2 tested whether 11-13-month-olds could nevertheless distinguish       sentence types using lexical information. half the infants were familiarized to       statements, the remainder to questions. all infants were tested on new sentences       of both types.  sentences were resynthesized to have monotone pitch and matched       utterance-final vowel length, neutralizing any prosodic differences.   overall,       there was a significant novelty preference and no interaction of trial type with       familiarization type. thus, while prosody is insufficient for distinguishing       wh-questions from statements, by 11-months infants can use word order to       distinguish statements and questions. this ability could provide an important       foundation for acquiring syntactic knowledge.        
the aim of the present study was to determine the differential       contributions of the action observation network (aon) and the social neural       network (snn) to the experience of naturalness in observed dyadic social       interactions. to this end, we used short animation sequences displaying social       interactions between two virtual characters and systematically manipulated       kinematic features of the social dynamics. a group of 21 male participants rated       the “naturalness” of the observed scenes on a four-point scale while       undergoing fmri. using the ratings of each participant as a parametric modulation       of their general neural response to the stimuli, we found that an increase in       naturalness experience was associated with higher activations in the aon. the snn       was preferentially recruited with a decrease in naturalness experience. this       indicates that understanding familiar interactions involves an automatic       kinematic processing of intentionality, while interactions perceived as       artificial require higher-level inferential processing.
individuals who continually track an object that suddenly vanishes       indicate perceived vanishing points displaced beyond the actual vanishing point       (i.e., forward displacement: fd) (hubbard, 1995). jordan, coey, and tsippaaoutis       (2009 ) demonstrated that fd increases with implied friction (i.e., low to high       friction) if one controls stimulus movements. metcalfe and greene (2007) showed       that manipulations of stimulus control affected judgments of agency.  the present       experiment examined the extent to which implied friction and conceptual factors       (reed & vinson, 1996) affect feelings of agency during stimulus control.        participants controlled the movements of a trapezoidal stimulus labeled as either       a “bullet train” or a “house” in two levels of implied       friction. results revealed a marginally-significant increase in fd with implied       friction. agency also varied significantly between implied friction conditions,       but only when participants conceptualized the stimulus as a bullet train and       implied friction decreased across blocks (i.e., implied effort became       optimal).
we explore the boundaries of learnability, ecological rationality,       and decision robustness in uncertain, non-stationary, finite-sample environments.       our approach combines machine-learning-based heuristic search techniques with the       integrated learning model (ilm) computational cognitive process theory of human       and animal learning. the scientific contributions of this research are in       understanding whether and how decision heuristics are acquired in binary       classification contexts, with an emphasis on fast and frugal decision trees. the       real world relevance of this research is in improved decision training and       aiding.
there is an ongoing debate about the relative contribution of       conceptual and perceptual information to inductive generalization in early       childhood. in the classic study bearing on this debate, pictures representing       familiar animals were arranged such that category membership was supposed to be       in conflict with perceptual similarity. however, later studies revealed that most       of the stimuli in this study failed to impose this conflict. the present study       revisited this issue. extensive calibration was conducted to ensure that the two       sources of information were in conflict. despite near-ceiling accuracy in       identifying the category membership of objects used in the study (e.g.,       bird-bird-bat, dog-dog-cow, cat-cat-raccoon, etc.), 4-year-old children relied on       their knowledge of category membership only 55% of the time when there was strong       conflict between category membership and perceptual similarity. these findings       will be discussed in relation to alternative accounts of knowledge acquisition       and generalization early in development. 
recent research suggests that perception and action affect       performance on cognitive tasks (e.g., beilock & goldin-meadow, 2010; landy &       goldstone, 2007). here we investigated perceptual and motor influences on causal       judgment from contingency using a causal discounting paradigm (e.g., goedert &       spellman, 2005). participants learned about two potential causes of a common       outcome on a trial by trial basis. we varied the left/right location of a target       cause and the left/right location of the “yes” response button for       predicting the cause would produce the outcome. when there was a mismatch between       the target location and the “yes” response, participants discounted.       however, they did not discount when the two locations matched. thus, we observed       more accurate causal judgment with spatial overlap in the perception and action       information. these results are generally consistent with an embodied cognition       framework; however, their exact mechanism remains to be explored.
there is considerable evidence that analogical comparison can       foster stem learning. for example, gentner, levine, dhillon, & poltermann (2009)       used comparison to teach 6-8-year-old children an important engineering       principle: namely, that a diagonal brace confers stability in construction.       children compared two buildings, one with a diagonal brace, and one with a       horizontal (nonbracing) piece instead. after the comparison, children were shown       an unstable building, and were given a piece to stabilize it. children who       received the comparison training were more likely to attempt to stabilize the       building with a diagonal placement of the piece. we extended this research to (a)       test for retention after two weeks and (b) examine effects of relational labeling       (which has been theorized to support long-term retention) the results indicate       that the training utilizing comparison and relational labeling elicited more       diagonal placements both after a brief delay, and after a delay of two weeks.       
the relationship between language and space has been intensely       investigated. the underlying question has been whether one affects the other,       usually within the scope of spatial language. largely ignored is the possible       role of bilingualism. given that the average person speaks more than one       language, and the mounting evidence showing that bilingualism interacts with       non-linguistic processes (e.g., bialystok & senman, 2004), we investigated what       effect bilingualism would have on non-linguistic spatial processing.        we tested 120 participants with a range of linguistic abilities using four       classic spatial tasks, e.g. mental rotation. we found patterns of systematic       interaction between bilingualism and spatial processing. these findings raise       questions beyond the relationship between spatial language and spatial cognition,       suggesting that language as a cognitive process may share a common neural       substrate with space. 
a series of experiments were conducted to examine conceptual       priming within and across modalities with pictures and environmental sounds. in       experiment 1, we developed a new multimodal stimulus set consisting of two       picture and sound exemplars that represented 80 object items. in experiments 2       and 3, we investigated whether categorization of the stimulus items would be       facilitated by picture and environmental sound primes that were derived from       different exemplars of the target items. the results demonstrated that the       categorization of environmental sounds and pictures were facilitated in a similar       way by conceptually related exemplars presented in advance, but only when a long       inter-stimulus interval (1000 ms) was used. additionally, conceptual cross-modal       priming effects by picture and sound primes were asymmetric with systematic       switch costs across modalities and with differences in the time-course of       activation. 
taking another person’s perspective when describing spatial       scenes is more common when a person is present in the scene. (tversky & hard,       2009). what about seeing another person elicits an allocentric perspective?        participants were shown one of a variety of pictures displaying a book and cup       placed, side-by-side, on a table. some photos also pictured a man sitting behind       the table, either facing the camera or facing to the left or right. viewers were       more likely to take the man’s perspective while describing object locations       when the man was facing the camera than when the man was facing to either side.        many factors influence which perspective people take. these results suggest that       the mere presence of a person in a scene does not guarantee a viewer will take       someone else’s perspective, but rather the way a person is positioned in a       scene might also be of critical importance.       
metacomprehension monitoring accuracy is defined as the ability to       accurately predict how well one will do on a later test of learned material.       metacomprehension monitoring is presumed to be a critical skill for the effective       self-regulation of study behaviors that impact learning. in two experiments,       ecologically valid science texts and inference tests were employed to examine       whether a test expectancy intervention could improve students’       metacognitive judgments, self-regulated study, and learning outcomes. experiment       1 was a lab experiment in which test expectancies were instilled only after       reading was complete, thus preventing any encoding effects. results suggest that       test expectancies impact metacomprehension monitoring accuracy via selection of       more valid cues at the time of judgment rather than only via encoding effects       that impact cue accessibility. experiment 2 was a classroom study showing that       the effect of test expectancies on monitoring accuracy translates into more       effective self-regulated study and improved learning.
the paper explores the cooperation rate in one-shot       prisoner’s       dilemma games in three cases – when the game is played       among friends, among foes, and among a mixture of friends       and foes. the paper checks empirically the prediction that       simpson’s paradox like effects are to be expected in this       situation (chater, vlaev, & grinberg, 2008). the existence of       a bias for cooperation when playing with friends and for       defection when playing with foes, is expected to lead to a       reinforcement of cooperation based on higher average payoffs       in the mixed condition, i.e. when playing with friends and       foes together. at the same time, the average payoff for       cooperation remains lower for games with friends and foes       taken separately (simpson’s paradox). there results of the       experiment support the existence of such effects and suggest       that further exploration is worthwhile.
how do we make sense of the 43 million or 1.3 billion dollar       budget cuts that are being made in congress? large quantities such as these are       common in our political discourse, yet recent studies demonstrate substantial and       systematic biases in evaluating them (landy, silbert & goldin 2012). we explore       how the integration of numerical and political information affects voters’       evaluation of political scenarios, and more specifically the effect of number       training on this evaluation. the current study investigates the effects of a       number training intervention on the numerical estimation task and evaluation of       deficit-reducing proposals using a within-subjects design and a typical voting       population. participants in the training condition completed a number estimation       task (siegler & opfer 2003) and were shown the accurate location of 1 million on       a number line from 10 thousand to 1 billion. line estimation and situation       evaluation were assessed before and after the intervention. 
we examined people’s ability to judge the degree of morality       of good and bad actions, and their consistency in doing so. participants judged       the degree of morality of actions on a scale from +100 (moral) through 0       (neither) to -100 (immoral).  they judged the degree of morality for individual       actions e.g., ‘a man intervened to stop a fight’, ‘a man gave       blood’, and their conjunction, ‘a man intervened to stop a fight and       he gave blood’. most judgments were consistent, i.e. the conjunction was       judged to be more moral or immoral than its components. however, a reliable       number of judgments were inconsistent, i.e. the conjunction was judged to be less       moral or immoral than one or both of its components. consistency improved when       participants read the conjunction after the conjuncts, compared to when they read       it before. we discuss implications for understanding the mental representation of       degrees of morality.
creativity is the drive for advancement in many aspects of society       such as arts, economy, or science. it is unclear if creativity consists of       several different skills and abilities or if it is one core construct. it is also       unclear to what extent creativity is influenced by culture and to what extent       creativity constructs can be generalized across cultures. to investigate these       questions, we administered three different creativity tests assessing fluency,       originality, flexibility, and creative achievement to over 900 students in five       countries: germany, guatemala, india, south africa, and the united states.       results showed weak correlations between the different aspects of creativity       speaking for heterogeneity of different creativity constructs, across all       cultures. whereas participants from the five countries did not differ in their       creative achievements, they differed in the cognitive creativity measures.       results are interpreted referring to the eco-cultural context and existing       cognitive frameworks of creativity.
asd is diagnosed by perseverative behaviors and social deficits.       while asd children’s selective interest in the physical world may lead to       more extensive exploration (and learning) of physical objects, they may learn       less due to their perseverative behavior. how is exploration affected in children       with asd? we quantified exploration and discovery as children with asd (n=35,       m=8.5 yrs) and their controls (n=35, age, iq matched) explored a novel toy with       hidden functions. asd children showed more perseveration than controls on every       measure, and the diversity of their actions was negatively correlated with       severity of autism. furthermore, asd children discovered less hidden functions       than controls. while the control group showed a marked decrease in perseveration       with age, asd group showed a heightened level of perseveration independent of       age. these data suggest that children with asd show marked difference in their       exploration of the physical environment, and this difference has real       consequences for learning and discovery.
how do people learn underlying properties, such as mass and       friction, from objects' interactions in complex scenes? such inferences are       difficult: the parameters cannot be directly observed and have nonlinear effects       on the physical dynamics. yet, people learn them. participants predicted the       stability of blocks stacked in complex tower configurations. after observing the       true outcome, they answered, "which blocks are heavier?". their responses       indicate rapid learning of the blocks' relative masses. we view such learning as       probabilistic inference in a generative model of newtonian rigid-body dynamics,       and express this hypothesis in a model observer that infers parameters using a       procedure of approximate physical simulation. while participants' judgments       qualitatively matched the model's, they also deviated in key ways that may be       explained by resource limitations. this work advances our understanding of how       people infer unobserved physical properties, and offers a framework for modeling       such behavior in complex, real-world scenes.
expectations are generated with different degrees of predictive       uncertainty prior to onset of musical events. this study explored influences of       genre specific expertise in non-musicians, classical, and jazz musicians       listening to unfamiliar charlie parker solos.        two probabilistic computational models of expectation were trained: one on       folksongs (general), the other on jazz (bebop). twenty-four melodies were       selected whose final notes differed in shannon entropy estimated by the two       models. listeners' uncertainty was assessed explicitly and inferred from       expectedness ratings of different continuation tones.        the analysis showed that jazz musicians followed 'bebop' and non-musicians       followed 'general'. classical musicians showed some decoding of the jazz style,       utilising a somewhat underdeveloped version of 'bebop'. moreover, experts       experienced more salient prediction errors in low-entropy contexts, and musical       skills predicted the extent of cognitive model optimisation.        our results suggest that expertise entails both possessing an accurate predictive       model and selecting an optimal model for the given context.
social interaction involves the simultaneous uptake of a range of       linguistic and nonlinguistic information. in a seminal study, rubin (1992) has       shown that a lecture spoken by a native speaker of standard american english       presented along with a photograph of an ethnically asian instructor affected       comprehension score and accentedness ratings more negatively as compared to the       same lecture and speaker presented with a caucasian instructor. here we asked       whether such effects could be observed in a multicultural environment, with a lot       of interactions with different ethnicities and non-native speakers. furthermore,       we investigated how the effect could be modulated by the quality of the speech       input (clear compared to noisy speech). the results showed that ethnicity affects       accentedness ratings only under adverse listening conditions and that       comprehension scores do not depend on ethnicity of the speaker. thus, the effect       of nonlinguistic information on linguistic processing is constrained in       multicultural settings.
the effect of minimally counterintuitive information on memory is       well established.  however, less work has addressed the processing of maximally       counterintuitive stories (i.e., stories containing at least three domain       violations).  the current study examined memory for maximally counterintuitive       stories.  the first two experiments investigated whether explicit instruction to       make sense of “strange information” influenced memory for maximally       counterintuitive stories.  although no such effect was observed, post hoc       analyses indicated that the extent to which concepts in maximally       counterintuitive stories contained domain violations from similar or different       categories influenced memory performance; stories with similar domain violations       enjoyed a memory advantage.  the third study addressed the believability of       concepts with similar domain violations with a rating task.  participants were       more likely to agree with two counterintuitive concepts with similar domain       violations compared to a single counterintuitive concept.  the results are       discussed within upal's (2005; 2009) context-based view of memory for       counterintuitive ideas.
an effective learning environment is designed to expose student       misconceptions because, once explicit, they are available for remediation. how       does one design such an environment, and what are the consequences for learning?       in a previous study, we demonstrated that a significant revision to the cognitive       tutor geometry intelligent tutor had a generally positive effect on the speed of       skill mastery (hausmann & vuong, 2012). however, the revised version demonstrated       a higher error rate for easy skills. we hypothesized that the revised interface       reified certain mental steps that students were previously allowed to complete       implicitly. specifically, students are now required to write an expression for       the length of the side of a special right triangle before calculating the length.       while the error rate for the calculation remained low (1.71%), writing the       expression proved to be particularly difficult (13.93%). we contrast the evidence       supporting this hypothesis with evidence for other potential explanations.
as an agent gathers information about its environment and monitors       the decisions of other agents, its behavior may fluctuate adaptively over short       time scales while still maintaining a long-term strategy. we designed a real-time       virtual environment to experimentally investigate the relationship between the       micro-level dynamics of dyadic behavior within single games and the macro-level       dynamics of outcomes across iterated games.        in one experiment, participants played a real-time game of "chicken,"       simultaneously guiding avatars toward high-payoff or low-payoff targets. if both       participants reached a demarcated vicinity of a target at the same time, that       target was destroyed. we recorded their trajectories, and induced uncertainty by       adding noise to their movement speeds. at the macro-level, we found evidence of       self-organized turn-taking across repeated games. at the micro-level, we found       that even within a turn-taking equilibrium, both players competitively pursued       the high payoff for a period of time before one of them diverted.
children's conception of lies has been important issues for       children's cognitive development. however, little is known about whether       children's understanding of lies is different form adults' one. four kinds of       stories were presented for children aged 6- to 7- year olds and undergraduate       students. first, a protagonist had a deceptive intention and produced a false       statement. second, he had a deceptive intention but produced a true statement by       a false belief. third, he had a truthful intention and produced a true statement.       fourth, he had a truthful intention but produced a false statement by a false       belief. the results showed that undergraduate students judged that these       protagonist's statements were lying or not by considering his intentions. by       contrast, children judged regardless of his intentions. these results suggest       that children's conception of lying is different from adults' one, and that their       conception becomes sophisticated after middle childhood.
medical care is increasingly implementing shared decision making       that requires participation of informed patients in an effort to maximize       treatment-related decision satisfaction (ds). patient comprehension of relevant       information is important in decisions involving high risk and uncertainty, like       surgery for lung cancer.        lung cancer patients (n=43) completed pre- and post-consult questionnaires, and       their consults with the surgeon were audio recorded.        post consult knowledge was low (53%) while ds was moderately low (m=44.56,       sd=13.71). higher complication risk (rs = .34, p<.05), external locus of       control (r = .31, p < .05), belief in a controlling deity (r = .37, p<       .05), and desire for control (r = -.38, p < .016) predicted lower ds. consult       recordings showed that patients possess counterfactual beliefs, such as airborne       spread of cancer in surgery, and benefit from removing most of the tumor.       experiments are needed to understand how patient comprehension can be improved.       
infants have expectations about physical properties of solid       objects. however, evidence on infants’ understanding of nonsolid substances       (e.g., water or sand) is sparse and equivocal. we conducted four       habituation/dishabituation experiments demonstrating that 5-month-olds have       distinct expectations for how objects and substances behave. experiment 1 found       that infants use motion cues from the surface of a contained liquid or solid to       predict whether it would pass       through or rest on a grid when the container was upended. experiment 2 extended       these findings to show that motion cues led to different expectations about       whether a new object will pass through or remain on the top surface of a liquid       or solid. experiments 3 and 4 replaced the liquid with sand. we found that       infants expected sand, like liquid, to go through a grid, but did not expect       another object to pass through it. these findings begin to characterize       infants’       understanding of substances.
turn-transition in adult conversation is remarkably precise, with       a median close to zero milliseconds. this means one needs to predict the end of       their interlocutor’s turn to come in on time. the interaction engine       hypothesis (levinson, 2006) suggests the ability to appropriately time turns in       social interaction is realized early in development, before and independent of       language. few studies have assessed timing of turn-taking in infant development.       we analyzed video-recordings of 12 mother-infant dyads at 12 and 18 months in       free-play interactions. findings indicate that in the first half of the second       year of life infants become more skilled in taking turns in vocal exchanges as       evidenced by decreasing onset times of their turns (median = 700ms at 18 months)       as well as a decrease in number of onsets produced in overlap with their mothers,       which at 18 months is at the maternal level of overlapping onsets produced (20%).       
as a species, humans stand out for superior cognitive capacities,       including improved working memory and abstract representation. however, these       abilities evolved, develop, and are generally utilized within a context of       cultural transmission and ongoing interaction with the environment. this raises       two complementary questions: to what extent does culture scaffold effective       employment of our cognitive capacities, and to what extent is learning possible       in culture’s absence? experiment 1 demonstrates that participants given a       verbal “hint” can use working memory to optimize rewards in a simple       sequential learning task, whereas even after hundreds of trials of experience,       those not given a hint can only learn the task suboptimally. experiment 2       demonstrates similar results for hierarchical rule abstraction. in these       experiments, hints are akin to cultural scaffolding, and their influence on       learning helps identify how our ability to spontaneously leverage our unique       cognitive capacities is limited in isolation from culture.
in a previous paper we showed that a set of representations, which       we referred to as “atomic operational representations,” which are       explicit spatiotemporal representations, can perform the function of grounding       concepts of activities and interactions in the physical world. in this paper, to       demonstrate how these operational representations can function in cognitive       processes, we develop the basic ideas further by showing 1) how actions and their       consequences can be observed and captured in operational representations; 2) how       causal rules of actions can be learned and encoded in the form of operational       representations through an unsupervised causal learning process; and 3) how the       learned causal rules can be used in problem solving processes that produce       desired action plans. we show that the same representations can be used across       the various levels of cognitive processing in a unified manner. experiments are       proposed to test if the brain uses explicit temporal representations.
it has been suggested that individuals use simple decision       strategies for comparative judgments. according to the recognition heuristic (rh;       goldstein & gigerenzer, 1999), people infer that a recognized object scores       higher on a criterion, if one of two objects is recognized, but not the other.       hilbig, erdfelder, and pohl (2010) have argued that previous research lacked       process-pure estimates of rh use and rigorous model testing and proposed the       r-model, a multinomial processing tree (mpt) model. addressing these       methodological issues, we present a first mpt analysis of differences in rh use       between younger and older adults. model-based analyses indicated that in both age       groups the rh was used adaptively more often in the environment with higher       recognition cue validity (cities), as opposed to a domain with lower cue validity       (diseases). the validity of further knowledge or recognition as decision cues did       not differ between age groups. moreover, we examined the model estimates on the       individual level by applying a bayesian hierarchical approach and compared these       estimates with behavioral indices and measures derived from signal-detection       theory. the resulting comparisons with standard rh-adherence rates indicated high       correlations. further implications are discussed.
research on two classic moral dilemmas, trolley and footbridge,       suggests that one’s past moral experiences can affect one’s       subsequent moral decisions. these dilemmas have interested moral psychologists,       in part, because they have found that people’s judgments about the dilemmas       are affected by the order in which the dilemmas are considered. furthermore, this       effect is asymmetrical: people that consider trolley after footbridge have       significantly different judgments than people in control conditions, but the       converse is not true. we argue that this asymmetry is the result of a difference       in how the each dilemma affects pre-existing beliefs regarding the importance of       saving lives. in two experiments, we show that footbridge disconfirms these       beliefs, while trolley does not significantly affect them. consistent with       predictions of a belief adjustment model of ordering effects, these findings       offer a clear and parsimonious account of the asymmetry. 
previous research has shown that gestures produced by caregivers       and teachers facilitate children’s learning in problem-solving tasks.       however, little is known about whether such facilitating effect varies with the       task difficulty. we here asked twenty-eight three-year-old children to       participate in two puzzle games (12-piece and 20-piece), with three episodes in       each game. in episodes 1 and 3, children played alone. in episode 2, caregivers       instructed their children (e.g., “let’s put this piece upside       down” while rotating left hand clockwise). for both puzzle games, children       assembled more puzzles in episode 3 than in episode 1, suggesting that       caregivers’ instructions were beneficial for children’s learning.       however, such benefit was significantly greater in 12-piece than in 20-piece,       t(27)=1.71, p<.05. this finding lends support to vygotsky’s theory in       which children can gain more from caregiver’s scaffolding when the task is       within their capacity than when the task is beyond their capacity. 
dual-process accounts claim that responses to reasoning tasks       often default to automatically cued belief-based responses. however, recent       findings show that when participants are instructed to evaluate the believability       of a conclusion, its logical status interferes with their judgment. this finding       is inconsistent with the view that belief based judgments are cued automatically.       in this paper we present the results of three experiments that examined the       impact of a secondary task (random number generation) on belief and validity       judgments. experiment 1 examined simple modus ponens arguments, experiment 2       included disjunctive syllogisms and experiment three employed a blocked       presentation design.        in line with previous research belief judgments took longer and resulted in more       errors than validity judgments. however, in general, rng impacted more on       validity than belief based judgements.  these finding suggest that both belief       and logic judgements require effortful processing but draw upon different types       of executive resource.        
srnengine is a windows-based application package for training       neural networks.  the graphical user interface allows the drag-and-drop creation       of neural networks with a variety of architectures, without the need for any       programming.  at present, these architectures/learning algorithms include simple       recurrent networks, jordan networks, and any kind of feedforward backpropagation       network, with up to five each of input, hidden, and output layers (pools of       units).  a version that adds backpropagation-through-time is in development. the       interface is designed to conform to the microsoft windows gui environment that       most pc users are already familiar with.  srnengine includes tools for creating,       editing, and manipulating various types of training data, and is especially       optimized for working with text/language data, including automatic       word-to-input-representation translation at runtime for text corpora.  the       distributed computing feature allows multiple simulations to be run on a network       of workstations, co-ordinated via a central ftp server.
we investigated the roles of comparison and explanation in       teaching children an important engineering principle – that triangular       cross-bracing confers stability to structures. we aimed to discover how best to       convey this principle to 4- and 6-year-olds and to reveal the cognitive       mechanisms involved. children either compared contrastive cases (a braced       building vs. a non-braced building), received an explanation of the principle, or       both, and were then tested on their ability to apply the principle to various       contexts. we found that 4-year-olds benefited from comparison, but surprisingly       did not benefit from a combination of comparison and explanation. 6-year-olds,       however, benefited greatly from the combination, suggesting that more developed       abilities are required to combine the two inputs. performance on a mental       transformation task was also related to successful brace placement. these       findings suggest that comparison and explanation can both contribute to learning,       both singly and together, depending on ability and/or age.
second language learners’ construction of their syntactic       representation is greatly influenced by their l1 characteristics and the input of       their l2. although it is known that the more universal a pattern is, the easier       it will transfer to facilitate the formation of the representation, the role of       markedness on such representation remains unclear. the current study tested two       groups of mandarin l2 learners, i.e., native speakers of english and japanese       with three levels of proficiency using the four structures in mandarin: svo, ba       ov, s ba o v, and topicalization with novel verbs and neutral animacy cues in a       forced choice paradigm to investigate what role of markedness plays in such       representations. the results indicated that in addition to the initial transfer       for the syntactic representation that is affected by learners’ l1 cue       validity, the degree of markedness exerts impact on learners’ rate of       acquisition of syntax at different levels.
the present experiment was to test if high-arousing chinese words       can lead to increase repetition priming for emotional semantics. participants       were randomly assigned into two groups: one group was presented with positive       words and another group with negative words. in phase 1 of the experiment,       participants rated high-arousing words and neutral words for concreteness. in       phase 2, they made decision to determine if it was novel word (half       high-arousing, half neutral). in phase 3, they were told to value the features of       chinese words which were not presented previously in a 5-point likert scale and       finished some parts of the basic personality inventory (bpi) for assessing and       controlling possible cognitive processing bias. the results showed a significant       priming effect in two groups and the words presented in phase 1 had shorter       reaction times than the novel words. these findings revealed selective       enhancement of chinese word repetition priming by emotional arousal.
we used a prototype-distortion task and adopted erps to test       between prototype and exemplar theories on categorization, which suggest that       categories are represented as a prototype via an abstraction process or via       storing previously encountered exemplars in memory, respectively. in experiments       1 and 2, participants were presented low- or high-distortion category-members       (i.e., dot-patterns) without anticipating subsequent categorization or       recognition test. they were more likely to process low-distortions via prototype       abstraction in both tests, and differently process high-distortions via prototype       abstraction in categorization test, but via storing exemplars in recognition       test. in experiment 3, participants were explicitly instructed to do       categorization or recognition task. we found that participants did categorization       test via prototype abstraction (n1) only for studied items, not for unstudied       items. and conversely did recognition via familiarity processing (fn400) only for       category-members, not for non-members. in conclusion, the nature of category       representations depends on the experimental contexts.
previous work has shown that a continuum of truth is reflected in       real-time motor movement behavior (mckinstry, dale & spivey, 2008). in a       mouse-tracking paradigm, participants responded yes or no to statements of       varying truth-values such as "a thousand is more than a million" or "english is a       language" as well as more ambiguous statements such as "murder is sometimes       justifiable". in the present study, we replicated these results along an 11-point       continuum of truth-values, finding that the end-points of averaged mouse       trajectories vary as a function of truth-value. in addition to this, negated       versions of each stimulus were tested and revealed that truth-values for negated       sentences follow more complex trajectories and do not preserve the original       truth-value of the statement. the evidence found presents a problem for theories       of negation that require a revision from the affirmative meaning. alternative       mechanisms for how truth is affected by negation are proposed. 
the attempt to forget some recently encoded information can indeed       cause later retrieval difficulties. however, such attempts are only effective       when new information is learned shortly thereafter. in the present study, we       asked whether the new information has to match the format of the to-be-forgotten       information for forgetting effects to emerge. participants studied words or line       drawings (l1), and were afterwards instructed to remember or forget these items.       then, a second list (l2) was presented that either matched or mismatched the l1       format. forgetting effects were only observed when the list formats matched. this       result establishes an important boundary condition on intentional forgetting, and       can be explained by the context change account (sahakyan & kelly, 2002), which       assumes that forgetting occurs when retrieval is guided by temporal context only.       salient cues (such as differences in list format) allow for reinstatement of the       l1 encoding context, thus eliminating forgetting.
we argue that much recent literature on disgust, dirtiness and       purity has been guilty of conflating two evolved mechanisms: an oral disgust       mechanism aimed at avoiding the ingestion of dangerous substances, and a       self-grooming (cleanliness) mechanism aimed at eliminating ectoparasites from the       skin. though phylogenetically distinct, these two mechanisms become associated in       human ontogeny due to their similar targets and overlapping image schemas: one       focused on the mouth, the other on the body as a whole. we show that several       puzzles in the literature on disgust and moral purity can be resolved using this       model. the idea of contamination so central to purity norms may more plausibly be       based on grooming responses to ectoparasites than on disgust responses to       endoparasites. the disgust image schema may more easily be extended to moral       judgements about others, while the cleanliness schema is more easily extended to       judgements about the self, with interesting consequences.
this study examines whether an art course with various kinds of       inspiration derived from others and their artworks is useful in improving       undergraduates’ photographic creativity and their views of photo taking. in       collaboration with a professional photographer, we organized an undergraduate       course in artistic photography, which included lecture sessions in basic artistic       skills and knowledge, imitation sessions of unfamiliar artistic photographs,       photo taking sessions, and presentation of the students' own works in the class.       21 students participated in the course for a semester. we collected       students’ diaries of their photo taking, their photographs, and       questionnaire survey data about their photo taking experiences. the results of       data analyses show that the creativity of the students’ photographs       improved after lecture sessions. the students reported that reflecting on their       photography contributed to their acquisition of metacognitive knowledge of       artistic creation.
capacities of mindreading are essential for human social life. it       is hypothesized that people selectively use two types of mindreading strategies;       when a target person is perceived to be similar to oneself, people project       one’s own mental states to the person (projection): when the target is       perceived to be dissimilar, category-based stereotype is used (stereotyping). in       this study, we tested this hypothesis with the reaction time paradigm (e.g.,       tamir & mitchell, in press). given that the both projection and stereotyping are       computationally modeled as anchoring-and-adjustment processes, the reaction time       paradigm can be used to detect a strategy used in mindreading. we found the       stereotyping was unanimously employed independent of the similarity to the target       person and projection was employed only when the perceived similarity was high.       our results are congruent with tamir & mitchell (in press) and confirmed the       utility of the reaction time paradigm as a tool for investigating mindreading       strategies.
where do people look when searching for multiple targets under       time pressure: at salient targets, at locations with high uncertainty about       target presence, or somewhere else? preceding research suggests that people tend       to look at salient targets. this is suboptimal, because educated guesses can be       made about target presence at these locations without looking (verghese, 2012).       we ran an experiment and constructed bayesian models to test the generality of       this finding. participants saw stimuli at two locations for 400 msec (i.e.,       allowing only 1 saccade), and then judged target presence at each location. noise       of low or high contrast was superimposed at the two locations. we observed       individual differences in saccade strategies. one participant made no saccades,       while achieving reasonable performance. others applied a mixture of strategies,       sometimes favoring salient targets, sometimes favoring uncertain locations. this       work provides further insight into task and cognitive constraints that influence       saccade strategy selection. 
our research aimed at investigating whether 8-to-12-year-old       children spontaneously make the conventional implicature induced by       ‘but’ -combined with ‘so’ and ‘nevertheless’-       in ‘p but q’ sentences. we presented the children with stories ending       with a ‘p but q’ sentence. they were instructed to indicate the       ‘appropriate’ conclusion introduced by either ‘so’ or       ‘nevertheless’. in addition, we measured children’s working       memory (wm)-capacity in order to explore the possibility that making these       inferences is effortful. our results show that children do make the inferences to       a certain extent but are sensitive to the content of the arguments. whenever the       p- or q-argument is an absurd argument (contrasted with a sensible argument),       this argument almost always gets ignored in favor of the sensible argument,       irrespective of the ‘appropriate’ conclusion ‘but’       directs the reader to. no reliable wm-effect was found. high wm-span children did       not make the inference more often than low wm-span children.
the “spatial arrangement method” (spam) has gained       popularity for measuring similarity judgments (perry, cook, & samuelson, 2011;       hout, goldinger, & ferguson, 2012; kriegeskorte, 2012). in spam, multiple stimuli       are freely arranged in two dimensions such that more similar stimuli are close       together. we performed two spam experiments to investigate the process by which       participants make multiple simultaneous similarity judgments using novel stimuli.       the experiments differed across either two or three feature dimensions. mouse and       eye-tracking measures, as well as the sequence of stimuli placed, provided a rich       picture of participants’ decision processes as they made these judgments.       both experiments revealed strong effects of group context. clustered presentation       of stimuli by feature influenced both the order and the timing of placements, and       despite equal metric spacing of stimuli along each dimension, participants       typically warped placements along dimensions nonlinearly. we discuss implications       of these findings for theories and models of similarity. 
judging whether multiple events will co-occur is an important       aspect of everyday decision making; however, the underlying probabilities of       occurrence are usually unknown and have to be inferred from experience. using a       rigorous, quantitative model comparison, we investigate how people judge the       probabilities of multiple events to co-occur. in a computerized experiment,       participants had to repeatedly choose between two pairs of conjunctive events       (represented as two gambles). participants had access to a small sample of       information to estimate the probability that both events occur. a hierarchical       bayesian approach used for estimating the models’ parameters and for       testing the models against each other showed that the plurality of participants       were best described by the configural weighted average model. this model assumes       that constituent probabilities are ranked by importance, weighted accordingly,       and added up. the cognitive modeling approach provides an understanding of the       cognitive processes underlying people's conjunctive probability judgments.
humans have the unique ability to have goals, cooperate according       to plans and in respect of norms and rules (football is a good modern example).       this ability is based on 1) collective intentionality among participants, 2)       distributed cognition of the shared plan and 3) normative cognition in the       ability to follow rules and 4) evaluate practice in relation to norms.         in cooperative social interaction, social institutions function by uniting these       4 dimensions. social institutions ‘make us smart’ collectively when       constitutive rules and regulative rules on the socio-cultural level are       internalized as constitutive and regulative representations on the cognitive       level (knowing ’what counts as what’).         social institutions are cognitive tools with force because they       ‘store’ and ‘radiate’ normative cognition and often       ‘crystallize’ in rituals, e.g. weddings (fusing 1-4). the functions       of normative cognition in social institutions should be an important subject in       cognitive anthropology. 
learning to linguistically encode spatial relations is       traditionally considered a problem of acquiring the meanings of prepositions (in,       on, under). based on production data from english speaking 4-year-olds,       6-year-olds and adults, we provide evidence for an alternative verb-based       hypothesis: children and adults may essentially share spatial concepts and       prepositional semantics, differing primarily in their use of lexical verbs (hang,       stick, attach) to describe spatial relations. this hypothesis was formalized as a       hierarchical generative model in which child and adult spatial descriptions are       drawn from a common distribution, modulo a penalty on lexical verbs that is       stronger for children. the model accounted for child production data       significantly better than a model based on average adult performance, and the       strengths of the estimated penalties were overall greater for 4-year-olds than       for 6-year-olds, suggesting a developmental process in which lexical verbs       gradually become integrated into the linguistic system for describing spatial       relations. 
several behavioral studies have reported functional similarities       between visuospatial imagery and visuospatial perception. for instance, in the       classic image-scanning paradigm (finke & pinker, 1982) participants first inspect       a dot pattern, which later disappears and is replaced by an arrow on a blank       screen. the task is to judge whether the arrow points towards one of the previous       dots. results commonly show that the response time (rt) increases linearly with       the distance between the arrow and the previous dot and has been taken as       evidence for a structural equivalence between perception and imagery. typically       eye movements are prevented in this paradigm.        in the present study, eye movements were recorded for 23 participants in a free       viewing version of the image-scanning paradigm. results revealed that saccadic       amplitudes increased linearly with the “imagined” scanning distance       (p < .001). but contrary to previous studies there was no significant effect       between rt and scanning distance. 
wh-words in auditory sentences like "who/what did barbie push the       ___ into?" generate expectations for animacy at the blank (e.g., a filled       potential wh-gap). specifically, the animacy is expected to be opposite of the       wh-word ( “who” and “what” predict inanimate and animate       nouns, respectively). fontenau and van der lely (2008) found early left anterior       negativities (elans) when animacy matched wh- animacy in typically developing       individuals but not individuals with "grammatical-specific language impairment".       however, to focus attention on the task, they added final noun phrases to       violation items ("who did barbie push the clown into the wall?") but not to       expected animacy items ("what did barney push the clown into?"). we ask whether       participants implicitly learn to predict sentence-final anomalies from animacy       match. we tested this by presenting one group with the original contingency and       another with the contingency reversed. contra the learning hypothesis, we       observed elans for both groups. 
here we explore the possibility that the speed of learning is       affected by the precision of our sensory estimates for the learned       category’s diagnostic feature dimensions. colour information from a       foveated stimulus, if represented as a sample on a metric colour dimension,       should faithfully represent differences in the shapes and precision of the       estimates as a consequence of the sample size. differences in the sample       variability are expected to have affect on exactly what gets associated during       learning. we provide evidence that a manipulation in sub-fovea feature size,       0.18° vs 1.19° of visual angle, influences learning speed. in both       conditions the simple colour features are easy to see and we do not detect any       gaze differences as measured by total fixation durations and individual feature       fixation durations. learning methods that metrically represent activity on       feature dimensions such as dynamic field theory (dft) may be able to account for       this data.
there is considerable evidence that representations of word       meaning are “embodied” and grounded in our perceptual and motor       experiences (barsalou, 2008; glenberg, 2010). this research has mostly relied on       priming and interference procedures, or measuring brain activity. the present       study manipulated the perceptual appearance of words, specifically font size, to       be congruent or incongruent with an object’s actual size (e.g., elephant       presented in a large or small font, respectively). participants were presented       with the words prior to a recognition memory test and property judgment task, in       the same session and after a 2-week delay, to see if the perceptual font       information would be incorporated into the representations of words to       potentially alter participants' memory and judgments. font size generally did not       significantly affect how participants represented and processed the words. these       results therefore present a challenge for embodied accounts of semantics, but       some potential explanations and issues will be discussed.
many decisions are made under the advice of another person. we       investigated the environmental circumstances under which two prominent       strategies—averaging and choosing—are effective and adaptive and       explored how people employ them. we report two experiments, in which participants       (n = 111 and n = 90, respectively) provided initial estimates for general       knowledge questions that varied in perceived difficulty. in experiment 2, they       additionally received advice in the form of an estimate and confidence rating of       another person before providing a revised estimate. we found that items of       different perceived levels of difficulty exhibited distinctive statistical       properties, thus constituting different social environments. environmental       structure affected the theoretical performance of strategies (such as averaging       and choosing), and the ways, in which people integrate advice. we embed our       analyses in the frameworks of ecological rationality and the probability,       accuracy, redundancy (par) model of advice taking (soll & larrick’s, 2009;       jep:lmc, 35).
threaded cognition theory predicts that switching is opportunistic       and depends on availability of cognitive resources. laboratory studies of       multitasking suggest people are rational in their switch choices regarding       multitasking, while observational studies suggest they are not. to establish       whether effective multitasking can become ineffective we introduced delays in the       primary task.        the participants answered emails by looking up information (similar to       customer-service employees) while being interrupted by chat messages. when       participants were faced with a delay in the email task, they switched more often       to the chat task on high-workload points. choosing to switch to the secondary       task instead of waiting made them slower. it also made them forget the       information of the e-mail task half of the time, which slowed them down even       more.        we concluded that people’s rationality in multitasking behavior is only       local, which agrees with the threaded cognition account of switching.
we investigated kansei difference between a child and a caregiver       in room arrangement workshop. seven pairs of parents and children volunteered to       participate in a workshop held in a university in japan. in the workshop, each       child and caregiver arranged a room layout using a prepared set of furniture. we       then interviewed them about the layout of the arranged room and their own room at       their home. we categorized their arrangement of the furniture into       "center-arrangement" and "corner-arrangement" using video-data. results show that       half of the children arranged a piece of furniture in the center of the room       whereas all caregivers arranged a piece of furniture at a corner. interview data       suggested this difference reflected their kansei differences such as preferred       activities and perspectives toward room arrangement between children and       caregivers.
previous research has shown that auditory training helps       non-native speakers learn to perceive difficult phonemic contrasts in a second       language (l2) (hirata, 2004), but there is much room for improvement. given that       hand gestures influence many aspects of native language processing (hostetter,       2011), we examined whether imitating versus observing gestures helps to improve       native english speakers’ ability to perceive novel phoneme contrasts in       japanese as an l2. participants were assigned to either a gesture observe or       gesture imitate training condition. there was no overall training advantage of       imitating gestures over simply observing them. however, in a preliminary analysis       of a sub-group of participants with low scores on the auditory pretest, observing       gestures was actually more beneficial than imitating them on an erp post-test of       auditory perception. the results suggest that producing gestures does not always       help with learning, and for particularly challenging auditory perceptual tasks,       may actually interfere with it.
word order varies not only across languages but also within a       specific language. turkish, for example, has a non-rigid word order. therefore,       it is a good test-bed to understand the processing complexity driven by the       order. one way to observe the complexity is to investigate it via diagrammatic       reasoning. in this study, 18 sentences with scrambled word orders and the       corresponding diagrammatic representations were analyzed by 20 turkish native       speakers. there were deliberate errors in the representations and the       participants were asked to report them. the participants’ eye-movement data       were also collected. results indicate that scrambled word ordering also causes       latencies in diagrammatic reasoning task. the eye-movement fixation orders showed       that the participants favored vso and vos eye-fixation orders independent of       sentential word orders. it is also concluded that finding the errors in verbal       representations were more time consuming than finding the errors in object and       subject representations.
the present poster discusses the role of the famous quinian       bootstrapping learning process in the acquisition of mental state terms such as       happy, believe, pain, etc. at first, the poster characterises  quinian       bootstrapping in which the so-called placeholder structure plays an important       role. the placeholder structure consists of symbols whose meanings are initially       learned in terms of each other. later, the placeholder structure is infused with       meanings via the so-called modelling processes. a modelling process can be       analogical mapping, abduction, induction, etc. susan carey (2009) introduced       quinian bootstrapping in her explanation of the acquisition of numeral list       representation and rational number as well as certain aspects of intuitive       physics. second, i apply this well-known learning mechanism to the acquisition of       the meaning of mental terms. i distinguish between three stages in the learning       of the semantics of mental words. the present poster will characterise the three       stages in detail. 
building on dual-space theories, the three-space theory of problem       solving suggests to add search of a model space in addition to search of       experiment and hypothesis space. this study aimed at exploring the three       postulated spaces, especially model space, by means of verbal protocols.        participants (n=32) were asked to think aloud while working with a computer based       learning program. with this program they could learn about torques in physics       using interactive graphics in which experiments could be conducted. their       knowledge about torques was tested before and after working with the program.       verbal protocols were analyzed with regard to the amount of search of the three       spaces and regarding the quality of the participants’ models for torques.        our results add to the validity of model space, showing that the three postulated       spaces could be reliably identified in the protocols and that the model quality       score predicted final knowledge beyond prior knowledge. 
a novel human memory system architecture is proposed. the memory       system is an integration of three distributed memory systems associated with       respective autonomous organic systems, including the perceptual system that takes       care of sensory input from the environment, the conscious system that performs       deliberate decision making, and the unconscious system that carries out action       selections in the environment. this memory system architecture is consistent with       the wide range of recent findings in the field of neurosciences. the memory       system architecture works as a memory component in the comprehensive real brain       model, mhp/rt, published in the cognitive science conferences, and the bica       conferences. mhp/rt is capable of simulating human daily behavior considering       real time constraints that should define strong mutual dependencies among the       three systems. with this memory system architecture, mhp/rt becomes a real brain       model to be contrasted with virtual and partial models, such as act-r.
we determined whether verbalization had an effect on lie       detection. participants were randomly assigned to one of the three conditions:       the lie condition, the truth condition, or the control condition. they were asked       to indicate whether the target man was either lying or telling the truth. prior       to making their judgments, the participants in the lie condition were required to       describe some behaviors exhibited by the target individual that indicated that he       was lying. similarly, prior to making their judgments, those in the truth       condition were asked to describe some behaviors exhibited by the target       individual that indicated that he was telling the truth. the participants in the       control condition were asked only to make judgments. the participants in the lie       condition detected lies more often than those in the other two conditions. thus,       verbalization influenced lie detection.
how does a person's personal space change when the person       approaches or retreats from another person? in this study, we examine the       anisotropy of personal space in a virtual room constructed by three-dimensional       computer graphics. in two experiments, a participant took the first-person point       of view, and an unfamiliar avatar was placed in the virtual room. the       stop-distance technique was used to measure the personal space between the       participant and avatar. the participant was required to approach the avatar until       he or she felt uncomfortable (approaching condition) or to retreat from it until       he or she felt comfortable (retreating condition). we also controlled the room       size and the unfamiliar avatar's direction. the results clearly showed that the       personal space was larger under the approaching condition than under the       retreating condition. moreover, we found that  the avatar's direction influenced       the effect of the room size on personal space.
in order to study the formation of symbol communication systems,       we conducted an experiment based on a game introduced by galantucci (2005). this       involved pairwise communication in which the pairs engaged in a coordination task       through an exchange of messages composed of a small set of geometric figures. we       analyzed the transfer entropy—which is a measure of the information flow       between two information sources or stochastic processes—between the figures       used and the actions by individuals. consequently, we confirmed that the transfer       entropy reduced significantly across individuals, but not within each individual.       moreover, it correlated negatively with the performance of the task. from these       results, we suggest that the transfer entropy appropriately shows the degree of       formation of symbol communication systems. then, we report the causal       relationship between the uncertainty and the performances using a computational       model based on reinforcement learning.
in noisy domains where category distributions overlap, people       categorise better at test after being trained on idealised category structures.       this may happen, because under the assumption that humans selectively sample from       memory when performing categorisation, idealised category learning leads to       sampling of more appropriate items and better performance. here we propose that       idealisation of category distributions occurs naturally via a process of       forgetting and re-estimation of category labels.        we model a process in which items’ category membership is forgotten and       then re-estimated from the remaining distributions. with time this leads to       lowering the variance of category distributions, equivalent to idealising       training data. we test this potential idealisation in a paradigm in which we       train participants on overlapping category distributions and withdraw feedback       for some trials in one group thus enforcing re-estimation of categories. the       model predicts that the group with less feedback will perform better at test due       to idealisation.
the effect of language on category learning is an ongoing debate       among researchers. according to previous research words can facilitate category       formation even if they aren’t used as feedback. however in most research       investigating language influence on category learning, the varying of verbal       labels often correlates with varying of perceptual features. such confound       doesn’t allow to clarify if the language is a means of perception       augmentation (language-feedback hypothesis) or a social marker for generalization       (word-meaning-as-intention hypothesis). in the present experiment we separated       the process of category learning from the label receiving. two groups of subjects       performed visual search task either with or without labels. right after that task       subjects had to form a category on the basis of new perceptual information added       to the old one. as a result subjects from label condition form a category but       subjects from the no-label condition didn’t. the given data agree with       word-meaning-as-intention hypothesis.
emotion perception is not only influenced by the ethnic       group-membership of interaction partners but also depends on whether a person is       engaged with the encoder of an emotion. to characterize the neural correlates of       the influence of ethnicity and engagement on emotion perception, german       participants rated the valence of video-sequences while undergoing fmri. in these       video-sequences asian-looking and european-looking virtual characters expressed a       positive (happiness) and a negative (anger) emotion while either gazing directly       at the participants or at another agent, thereby varying the perception of       engagement. results show that the ventromedial prefrontal cortex is involved when       participants observe ethnic in-group members compared to ethnic out-group members       express a positive emotion at them compared to at another person. in contrast,       the dorsolateral and dorsomedial prefrontal cortex are involved when participants       observe ethnic out-group members compared to ethnic in-group members express a       negative emotion at them compared to at another person. 
conceptual art and cognitive science have more common ground than       is acknowledged. for example, both disciplines are principally engaged in       describing and visualizing facts about basic categories of mind (space, objects,       language, etc.). along these lines, conceptual art can inform the cognitive       science of abstract concepts. cognitive scientists studying aesthetics can also       learn from conceptual artists to push their research forward. while empirical       investigations in aesthetics typically focus on perceptual preferences (i.e.,       “what is beauty?”), conceptual art often goes deeper ontologically       (i.e., “what is art?”). this level of analysis can inform questions       regarding the evolution of art and object processing. the present study examines       the artwork of mel bochner who may have staged the first conceptual art       exhibition (1966).  bochner’s work addresses spatial       semantics/representation, and anticipates the neuropsychological distinction       between categorical and coordinate spatial relations; all while reconsidering       what it means for an object to be thought of as art.
some studies on judgment and decision-making have demonstrated       that uncertainty in probability influenced curvature of function given by judged       probability or proportion (i.e., probability weighting function). in this study,       we concentrated on proportion judgment about visual input. we investigated the       possibility that the efficiency of feature detection of visual stimuli would be       related to uncertainty in their proportion judgment. concretely, our participants       in the experiments performed proportion judgment task using two sets of visual       stimuli pairs, "red vs. green dots" and "right vs. left tilted lines". in       addition, we adopted different types of responses; in one condition, the       participants were asked to response using numerals; in another condition, they       were asked to response by adjusting the line bar which indicated the proportion.       our results suggested that the efficiency of feature detection of visual stimuli       influenced the curvatures of the probability weighting function.
our research aims to study the effect of set in the process of       perception of unconscious information.  in the experiments, we use serial       (multiple) unconscious stimulation and the modified masked priming technique to       give unconscious stimuli to our participants. in the experiments we demonstrate       that, as a result of the  specially organized preliminary experimental series, it       is possible to receive the steady priming-effect for the unconscious stimulus       which initially didn’t render any noticeable influence on the effectiveness       of the tasks solutions. we can conclude, that at unconscious level cognitive       system analyzes series of unconscious influences. so, the nature of influence of       each following unconscious stimulus on the current conscious cognitive activity,       by the time of its occurrence, is already set on the basis of the analysis of the       previous series of influences. it is possible to model these individual settings       in the experimental environment.
wayfinding difficulties in architecturally ambiguous environments       can be overcome by orientating with given landmarks. however, it is not clear at       which locations landmarks are most suitable to facilitate orientation. our study       addressed two questions: (1) is subsequent wayfinding performance facilitated if       participants freely place a number of landmark objects in a complex building? (2)       where do participants place the landmarks and which strategies guide effective       landmark placement? first, participants were instructed to learn a number of goal       locations in a virtual model of the tate gallery london. then, participants in       the experimental condition were instructed to place five unique landmarks in       order to re-find the goals in a third phase; participants in a control condition       could not place landmarks. finally, participants were tested on their ability to       find the goals again, with time and distance as main dependent variables. results       are discussed with respect to placement strategies and environmental       properties.
automatic parallel processing occurs in visual search when a       target differs from other display objects on a salient visual dimension and the       phenomenon is termed ‘popout’. the present two studies answers the       question: do the interference effects cancel or add? both studies used a ring of       twelve fixed-size green circles with embedded gabors oriented vertically or       horizontally. targets and foils were one of green square, a larger green circle,       or a red circle. each of these served as a target for one of the three sessions,       with the others serving as foils. in one task the observer found the target and       reported its gabor orientation. the other task used targets only on one half the       trials and the observer reported target presence or absence. in both tasks       accuracy was uniformly high. in both tasks rt interference increased from one to       two foils, the slowing mainly isolated to the slowest decile of rts.
the nature and basis of creative thought is the subject of       wide-ranging inquiry, yet remains elusive. we focus on a core issue: why do       people struggle to solve problems that require a creative insight and what type       of support can make success into the norm? drawing on the idea of relational       encoding (e.g., gentner, loewenstein, & thompson, 2003), we sought to improve       creative problem solving by activating structured content (relations between       objects) in the problem encoding. we developed an alternative to a comparison       task: completing a set of sentence frames explaining how pairs of objects in the       problem setting relate to one another. in two experiments, we found evidence that       participants in the relational encoding group were significantly more likely to       solve an insight problem than controls. an important caveat is that the advantage       was only found for the easier problems tested - there were no differences for the       more difficult problems. we address implications of this work from both       theoretical and applied perspectives.
hardly any concept is as frequented as emergence in current       cognitive science. for many authors it has become solution of eternal       psychophysical problem, for many it has been only a mysterious incantation in       regard to this. this poster should point out that concept of emergence as well as       many other promising concepts has a fundamental problem with determination,       definition and usage. the thesis is evident from the title: not emergence as       emergence, or better: like emergence, not like emergence. there are many       different concepts of emergence. the contribution is based on the belief that the       confrontation of  artificial intelligence with philosophy of mind, the comparison       of these two areas in which emergence occurs very often, could be interesting and       could enable to formulate or outline certain tendencies in understanding and       using of the concept.
there is a growing body of evidence that the human brain may be       organized according to principles of hierarchical predictive coding. a current       conjecture in neuroscience is that a brain, organized in this way, can       effectively and efficiently perform genuine bayesian inferences. given that many       forms of cognition seem to be well characterized as bayesian inferences, this       conjecture has great import for cognitive science. it suggests that hierarchical       predictive coding may provide a neurally plausible account of how forms of       cognition that are modeled as bayesian inference may be physically implemented in       the brain. yet, the jury is still out on whether or not the conjecture is really       true. in this presentation, we demonstrate that each key sub-computation invoked       in hierarchical predictive coding potentially hides a computationally intractable       problem. we furthermore identify ways in which computational modelers may or may       not overcome these 'intractability hurdles.'
survey spatial representations are map-like mental representations       in which directional relationships among landmarks are preserved. survey       representations allow people not only to re-trace routes already experienced, but       also to find new routes and shortcuts (golledge et al., 1999). this study       investigated whether and to what extent verbal and spatial working memory (wm)       are implicated in the construction of survey representations. we adopted a       dual-task paradigm, asking participants to learn a new environment from       navigation and, concurrently, to perform either a verbal or a spatial task,       assumed to load verbal and spatial wm, respectively. ninety undergraduates were       assigned to one of three groups according to concurrent task condition:       articulatory suppression, spatial tapping, or control (no concurrent task).       acquisition of a survey representation was tested by asking participants to       perform direction estimations and shortcut tasks. the results supported the       involvement of spatial wm in the acquisition of survey knowledge, showing       significant differences between the spatial tapping group and control group for       the survey measures.         
numerosity judgment involves determining the number of items,       which highly correlates with mathematical achievement. this study investigated       age-related differences on numerosity judgment among middle-level elementary       students and college students in terms of strategy use and problem-solving       efficiency determined by participants’ eye movements. stimuli were grids       consisting of 7 x 7 units which were either “on” (yellow block) or       “off” (blank). participants were asked to determine the number of       yellow blocks.         results showed that given energy- and time- consuming, third graders consistently       adopted “addition strategy” on larger numerosity trials. for strategy       adaptiveness, adults outperformed younger peers, most of whom starting using       “subtraction strategy” on critical and larger trials (e.g., 25 and       larger numerosities). regarding efficiency, adults determined numerosities more       efficiently than elementary students, because adults’ eye fixations were       significantly fewer than those of younger groups, while only marginal difference       on the number of fixations was observed for the two younger groups.       
we investigated motor resonance effect(mre) during perceiving       interactive social action scenes of two people. perspectives of the social action       scenes were manipulated by the voice (active vs. passive) of sentences describing       the scenes. in exp1, subjects' response time for stepping on a pedal was analyzed       for investigating mre during understanding of the scenes where a person is       stepping on a foot of the other person. in exp2, the response time by the lip       action on a microphone were analyzed for exploring mre during perceiving of the       scenes where a person is biting an arm of the other person. in results, the mre       in both experiments was significant only when the scenes were described in the       active voice. our results indicate that the motor resonance effect can occur       during perception of social events, but it can be modulated by the perspective of       the mental construal of the event.
this work investigates why the psych sentence 'she is dizzy' with       the third person subject in present fine, whereas its counterparts in korean and       japanese are odd unlike the first person subject utterance na-nun ecirew-e (k)       ‘i am dizzy.’ we have no way of knowing if others’ internal       psych state is such at speech time. we argue that an evidence acquisition event       (ee.a) such as i just heard from mary/i just saw mary precedes or is accommodated       prior to speech time for the third person present psych sentence even in english.       the present realization is a consequence of “double access” sequence       of tense interpretation in english, i.e. mary was dizzy and still is dizzy. a       psych predicate requires the 1st person experiencer’s direct perceptual       experience of one’s own psych state or of individual object as in       predicates of personal taste. first-person interoceptive psych judgments of i am       dizzy/in pain have “immunity to error through misidentification,”       unlike de se thoughts.
to investigate neural activity with respect to language switching,       we measured brain activation with functional magnetic resonance imaging (fmri)       while 5 early korean-chinese bilinguals performed a covert property generation       task with language switching. forty stimulus photographs of animals and tools       were presented as stimuli, accompanied by captions written either in korean or       chinese. when the stimuli were shown in korean, participants were asked to do the       covert association production task in chinese (k>c), and vice versa (c>k).       results from the fixed effect analysis revealed that the k>c condition (korean       as orthographic stimuli and chinese as semantic execution language) activated       primarily left precentral gyrus and left inferior frontal gyrus while the c>k       condition activated primarily the region straddling right precuneus and right       middle/posterior cingulum. these contrasting activation patterns might support       the hypothesis that the neural representations in language switching tasks hinge       on the linguistic typology and the cognitive motor control. 
this paper looks into the effects of visual/linguistic stimuli in       the activation of cognitive domains (e.g. image schemas for primary metaphors)       which are necessary for the understanding of sentences content by individuals       affected by alzheimer’s disease (ad). ad studies point out to cognitive       impairments at early stages of the disease which make comprehension tasks such as       abstract inference, and metaphorical reasoning more costly to ad subjects in       comparison to other groups of normal aging. we designed a 3x3 experiment in which       subjects (ad and control group) were presented with primes of cognitive domains       (words, pictures, and ideograms as control) followed by a choice task of       metaphorical, literal, and abstract sentences in order to measure time spent to       understand sentences in each condition, and frequency of each choice. our       hypothesis is that when the subject is primed with visual rather than linguistic       input of a domain, s/he understands more readily and more accurately the       metaphorical/inferential content of a linguistic expression, even though literal       understanding frequency keeps higher.
intention understanding is necessary during the formation of human       communication system. though the linkage between mirror system and intention       understanding has been examined by many studies, the evidence of activities of       mirror system during the formation of human symbolic communication system, in       which no explicit demonstration of actions is involved, are still limited.        we recorded the neural activities with electroencephalography during a       coordination game with message passing, which involves formation of symbolic       communication system. in this experiment, two subjects were separated into two       rooms, thus they could not see any movement of communication partners or hear any       sound from the partners’ actions. significant mu rhythm suppression is       found over sensorimotor cortex both when the subjects send and receive messages.        this preliminary result indicates that intention understanding involved in       message interpretation can also induce the activities of mirror system, even       without explicit referring to actions.
before an election, voters are inundated with messages about       candidates running for office. our work examines the influence of metaphor in       messages about political races. of special interest is the role of manner of       motion (e.g., slow, fast) and aspect (e.g., perfective, imperfective) in messages       that include motion metaphors (e.g., “candidate a raced/was racing ahead of       candidate b” and “candidate a inched/was inching ahead of candidate       b”). we discuss results from our experiments with english and russian       speakers. in line with our predictions, manner of motion and aspect were found to       interact in interesting ways, and to systematically influence opinions about who       is likely to win an election. these novel results have valuable theoretical and       practical implications for political communication and how people conceptualize       political elections, and expand prior work on framing effects in political talk,       especially motion metaphors and grammatical aspect (fausey & matlock, 2010;       matlock, 2012).
for at least 350 centuries, humans have invented music that       offered special aesthetic appeal. yet, the reasons for these preferences and       effects are not understood. here, we show that listeners prefer music with an       underlying rhythmic structure that closely approximates our biological structure.       specifically, listeners preferred music with musical (rhythmic) structures that       correspond to biological rhythmicity (motions). this finding, grounded in a       straightforward biological framework, provided an intellectual advancement in the       long history of thought and experimental work on the basis of musical       preferences.
we examined whether skeptics hold implicit supernatural beliefs.       in study 1, priming by reading a biological or a religious story about death had       no effect on skeptics' afterlife beliefs. in study 2, participants indicated       whether they would partake in a (bogus) scientific study that involved visiting a       fortune teller and whether they would prefer a fortune teller who predicts       positive and negative events or one who predicts only positive events. believers       chose the positive fortune teller more often than skeptics did. study 3       investigated whether participants' views about the afterlife, other paranormal       phenomena, and ontological confusions differ in speeded and non-speeded response       conditions. the results were moderated by thinking style: ontological confusions       increased in speeded conditions for intuitive skeptics but not for reflective       skeptics. the results indicate that skeptics don't hold implicit supernatural       beliefs but intuitively thinking skeptics hold ontological confusions       predisposing to supernatural beliefs. 
memory processes play a major role in many models of decision       making. several fast-and-frugal heuristics assume a sequential search of       information in memory (e.g. the take-the-best heuristic). fast-and-frugal       heuristics exploit regularities in the structure of the environment and basic       cognitive capacities, such as memory. however, until now only few attempts have       been made to relate models of memory and decision making to the structure of       information in the environment. the act-r architecture provides a quantitative       theory about the interplay between the information structure in the environment       and the memory system. based on internet statistics, we use act-r to predict       people´s recognition and knowledge about objects in the world, as well as       the associated retrieval time distributions of respective memories. we show how a       corresponding model integrating memory and decision processes within act-r allows       predictions about the ecological rationality of decision strategies that operate       on the accessibility of information in memory. 
motor representation is understood by grush (2004) and pezzulo       (2008, 2011) in terms of simulation/emulation: internal models simulate motor       effectors and environmental conditions.  motor intentionality, thus, is regarded       as based on the standing-for relation.          in their thesis of motor representation, knowing in preparation of motor actions       is highlighted but the system’s doing when manipulating on-going motor       activities is overlooked.  that ‘system’s doing’, however,       retains an essential role in motor intentionality, a role which accounts for       complexities of real environment, animate apparatus to be represented, and       goal-oriented nature of motor movements.           contrasted to grush and pezzulo’s thesis, my research highlights a       pragmatic role of motor representation, pragmatic in sense of explaining how a       motor agent can successfully achieve a goal by maintaining motor movements.        internal models, in my account, not only supply emulation but serve to assist the       motor system in its goal-achieving activities, resulting in efficient control and       flexible movements.        
the click-detection paradigm was employed to probe the load       exerted by the parser within simple spanish sentences. in experiment 1, three       positions at the beginning of clauses were established and results suggest that       ss are better prepared the deeper into a sentence the click is. experiment 2 ran       an erp experiment to determine whether these rts were the result of the       “uncertainty” ss may have felt regarding the click position, the idea       being that the amplitude of the p300 would correlate with the click positions. in       experiment 3, click positions were moved to the end of clauses to establish if       the end of a sentence results in a specific strain on working memory. rts show       that ss are slower in the first position but the measures even out after that,       with the possibility that ss may have attempted to “wrap it up” in       both the second and the third positions.
we examined differences between the processing of inflectional       versus derivational morphology in visual word recognition in greek using masked       and delayed priming. a lexical decision task to target verbs and nouns preceded       by morphologically related primes of the same grammatical class was used to       examine inflectional morphology, whereas the same target words preceded by primes       of the other grammatical class were used to examine derivational morphology.       greek, a highly inflected language, allows use of words consisting of a stable       stem and verb or noun inflectional suffixes, keeping the orthographic and       phonological overlap constant across conditions. both noun and verb targets were       significantly primed by the same grammatical class, consistent with inflectional       processing. when preceded by primes of different grammatical class, verb but not       noun targets showed priming, precluding firm conclusions about derivational       morphological processing.    
with the underrepresentation of minority students in science,       technology, engineering, and mathematics (stem) related fields, it is important       for us to develop ways to narrow this gap. this study examines the use of lego       robotics to increase the interest and motivation of children, particularly       hispanic and african-american students. participants were fifth graders from two       low ses schools attending an after-school robotics program. students were       randomly assigned either learning science in the traditional classroom setting or       learning science with robotics. the results from this study found that learning       with lego robotics can increase minority students' interest and motivation in       science and technology.
studies have shown that vision perception is pliable and that       perceptual estimations can be affected by a variety of factors. it has been shown       that perceptions of slope, distances, and heights are subject to the influence of       physiological, emotional, and/or social variables. the studies conducted and       outlined here investigated the impact of an individual’s actual height on       estimations of slope and object height in analog settings, as well as pictorial       and linguistic stimuli as presented from a nonimmersive desktop computer monitor.       results suggest that without a relative horizon to utilize eye-height scaling an       individual will instead estimate the height of objects relative to their own       height.
resolving disagreements by collective decision making requires       knowledge about task and others’ opinion quality. we tested dyads in a       visual discrimination task to first show confidence of their individual decision       and in case of disagreement announce their joint decision. using a bayesian       approach, for each participant we compared the optimal decision rule (i.e.       relative reliability of participant’s own opinion to that of his partner)       to the empirically obtained (fitted) decision rule. the less sensitive observers       (i.e. the ones who made poorer individual decisions) were significantly less       successful in group decision making compared to their more sensitive partners.       these less sensitive observers insisted on their individual decision as the group       decision more often than recommended by the optimal decision rule. our findings       extent the previously found dunning-kruger effect to social decision making       domain: the more incompetent are often less aware of their greater       fallibility
categorical perception describes the phenomenon that visual       stimuli can be discriminated more easily when they belong to distinct rather than       common linguistic categories. here we investigate the role of the meaningfulness       of linguistic categories in categorical perception. to disentangle the effects of       labels and semantic contents of verbal categories we employed a learning paradigm       in which participants acquired information about initially unfamiliar objects.       linguistic knowledge was manipulated by labeling object pairs either with the       same or different names. furthermore, the labels could be associated with       in-depth knowledge or learned in isolation. two days after learning, the eeg was       recorded while participants performed a lateralized object discrimination task.       verbal labels affected object processing already at about 120 ms, unaffected by       semantics, while separate semantic effects were found at about 200 ms, suggesting       that the influence of verbal categories on perception may not be modulated by       semantic information associated with the categories.
we report the results of whether syllables are frequency-modulated       prelexical units in dyslexic children. twenty-two french dyslexic children were       compared to 44 chronological age-matched and reading-level-matched controls. a       syllable compatibility procedure was combined with a visual syllable detection       task (exp. 1) and a visual masked priming paradigm in a lexical decision task       (exp. 2). dyslexic children exhibited robust frequency-modulated prelexical       syllable effects; high-frequency syllables elicited a syllable compatibility       effect in both experiments, while low-frequency syllables favored either a cv       target length or a cvc prime length effect. the frequency-modulated syllable       effects were constant across both experiments following an expected developmental       course, especially in a highly feasible task (exp. 1). however, performance was       drastically low in a highly demanding task (exp. 2), suggesting impaired       phonological procedures. we propose that dyslexic children do not have obvious       impaired phonological representations but rather delayed or compensated       phonological representations with impaired phonological procedures. 
tests modify memory and can improve memory performance: practice       tests outperform additional study trials as a learning technique when the final       memory test is difficult (e.g., delayed in time). this is referred to as the       testing effect. although existing theories propose single mechanisms to underlie       this effect, the contributions of different cognitive processes are yet to be       dissociated. because most testing-effect accounts attribute the testing advantage       to either encoding, maintenance, or retrieval processes, we propose a multinomial       processing-tree model that disentangles the contributions of all three memory       processes. by applying this model to testing-effect data, we show that (a)       testing memory primarily creates maintenance benefits (i.e., resistance against       forgetting) and that (b) the critical interaction of testing vs. study benefits       with final-test delay is not driven by different retrieval strengths. our results       thus support maintenance accounts of the testing effect and are difficult to       reconcile with retrieval-based explanations.
the aim of this study was to examine cultural universality of the       international affective picture system (iaps) on a russian sample (lang et al,       2008). one hundred subjects evaluated 300 iaps pictures according to their       valence, arousal and dominance.  affective space determined by valence and       arousal dimensions had a similar distribution to the american sample. there were       significantly high correlations between north american and russian ratings of       valence, arousal and dominance.  nevertheless comparison of these ratings showed       that there are significant differences between north american and russian       valence, arousal and dominance scores. such differences suggest cultural       specificity оf situations which induce emotion and provide evidence of       cultural factors effect on the affective experience.  lastly, it shows the       importance of using local cultural norms for internationally available stimuli in       addition to the original stimuli, even in the study of such universal processes       as an emotion. supported by rfh grant 12-06-12058.
research on information search has found widespread evidence of a       “positive test strategy” (pts), where people search for predicted       outcomes of a focal hypothesis. a recent analysis by navarro and perfors (2011)       showed that the pts is consistent with normative models of search under       “sparse” hypothesis spaces, where each possible outcome is predicted       by a minority of hypotheses (a property shared by common kinds of categories).       despite this justification, learning often involves a transition to a       “dense” hypothesis space as information is accumulated, at which       point the pts becomes markedly worse than a strategy of searching for diagnostic       information about multiple hypotheses. using a perceptual search task, our       experiment tested whether people independently switch between these strategies       based solely on changes in sparsity. the results show that, in general, people       continue to make errors consistent with the pts even when faced with       “dense” hypothesis spaces where that strategy is ineffective.
this study revisits categorization of infant engagement used in       infant language acquisition research. we provide a novel, component-based       analysis of interaction structures – centered on attention, interaction,       and goal-oriented behavior. with this approach, we are able to extend the       classification of engagement by differentiating two independent categories of       engagement that have been overlooked. to verify this new categorization, an       experiment was conducted with 84 participants in regard to the presence/absence       of goals in naturally observed infant interactions form a western and a       non-industrial community. results demonstrate that the extended categorization of       engagement levels via interaction components and processes is sound because there       are no significant differences between sites, and no significant differences       between participants and trained coders. these results further support the use of       a more extensive categorization of engagement, as well as the use of natural       observation data and cultural immersion in language acquisition studies.       
how does social presence influence the perception of a physical       environment? people think about social relationships in terms of space. for       instance, when drawing routes on maps they draw paths closer to friends than       strangers (matthews & matlock, 2011). how does the mere presence of a friend       alter spatial reasoning?        here, participants imagined working for an outdoor magazine. they viewed photos       of bridges one might encounter while hiking. some participants were told they       preferred crossing bridges last (in a group), while others were told they       preferred crossing them first. all participants estimated bridge length. those       who crossed last, and imagined their friends on the other side of the bridge,       provided reliably shorter length estimates than those who crossed first and       imagined their friends standing immediately behind them.        these results provide new insights into how social presence can influence our       perceptions of physical environments. 
a number of popular philosophical and psychological theories that       model causality in terms of causal dependency assume that causal relations in       chains are transitive. when a causes b, and b causes c it typically follows that       a also causes c. in contrast, dispositional theories focus on intrinsic causal       properties (i.e., causal dispositions) of the involved participants of causal       relations. according to this account, a causal chain is transitive only when a       originally has a disposition towards c. we present an experiment that contrasts       scenarios with transitive chains (a disposes towards c) and scenarios with       intransitive chains (a does not dispose towards c), according to the       dispositional account. in line with dispositional theories of causation, we found       a strong dissociation between cause-effect judgments (a causes c) and probability       judgments, p(c|a), in intransitive scenarios but not in transitive scenarios.       across both types of scenarios judgments for single relations did not differ.       
previous research has identified systematic sound-to-meaning       mappings (sound symbolism) in words for object size, shape, and surface       lightness. in the present study we investigate whether sound is used       systematically in spatial relational terms in 17 languages, and whether native       english-speaking individuals can determine the meanings of these terms. in a       forced-choice task, participants were asked to choose the correct english       translation for each unfamiliar foreign word. all items were spatial terms with       either proximal or distal meanings (translations of english 'here', 'there',       'near', 'far', 'this', 'that'). participants nominated the correct meanings of       the words significantly above chance, suggesting that they used sound structure       to infer meaning. acoustic analyses were conducted to examine the relation of       acoustic properties to word meaning, as well as to listeners’ judgments.       the findings suggest that the sound structure of language can be systematically       used to mark relational meanings related to space.
recent evidence suggests that fractions are represented as       visuo-spatial analog magnitudes on a “mental number line” (schneider       and siegler, 2010). in order to test this theory, we evaluated subjects in two       tasks: fraction comparison and number-line marking. both magnitude difference and       response time to mark a fraction on the number line predicted response time to       compare the fraction’s magnitude to a standard held in memory. this       supports the notion that even symbolic numerical cognition is grounded in       visuo-spatial processing. we also found a symbolic cost to processing: fractions       with more digits were processed more slowly. we propose a model of fraction       comparison wherein fractions are processed from symbols into analog magnitudes,       then compared to a standard by sequential sampling decision-making. this model       provides a superior fit when compared to the log distance model, despite having       fewer parameters. furthermore, it has a direct interpretation in terms of       psychological processes.
we used a srt task in which the preceding two trials of a run of       three predicted the third 2/3 of the time, and added another predictive cue, a       colored square, which could also predict the next response required. the question       was to what extent would these two cues compete for control of behavior? we       assessed this by comparing the dual cue group to a color only control and a       sequence only control. our results showed that the dual group learned about both       cues to about the same extent as the individual controls, but that when switched       to a test phase where each cue could be assessed independently, the dual group       showed a marked decline in performance relative to the controls. we interpret       this as evidence for overshadowing occurring between the two predictive cues in       the dual group.
the maxim of quantity states that a speaker should provide enough       information for an object to be identified but no more (grice, 1975). however,       research has shown that children tend to produce too little information       (under-description) and adults tend to provide too much information       (over-description). in this study, we examined the production of referring       expressions across the course of development (i.e. 7–18 years).       participants were required to generate a referring expression, and we manipulated       the presence or absence of a contrasting object and display complexity. results       showed an age effect on the production of under-descriptions: young children       produced significantly more under-descriptions in more complex arrays compared to       older children. in addition, an analysis of voice onset times and eye movements       investigated whether there are speed-accuracy tradeoffs associated with visual       search and the tendency to include extra information. conclusions focus on the       development of reference mechanisms from childhood to adulthood.   
coordinating actions with another person can be a challenging       endeavor for young children. for smooth coordination of actions with another       person two skills are hypothesized to be crucial: action prediction and       inhibitory control. in this study, we investigated how developing abilities of       action prediction and inhibitory control are related to young children’s       joint action coordination. using a simple turn-taking game,       2½-year-olds’ joint action coordination performance (timing       variability and accuracy) was assessed. additionally, children’s action       prediction skills were measured by anticipatory looks using eye-tracking.       inhibitory control was tested in an age-appropriate gift delay task. results show       that timing stability during the joint coordination was positively correlated to       measures of action prediction. in turn, accuracy in the joint coordination was       positively correlated with measures of inhibitory control. these findings       indicate a distinctive role of action prediction and inhibitory action control       for different coordination qualities (timing variability and accuracy) in young       children.
although it is well established that regions of ventral premotor       cortex (vpmc) are active during action observation, it remains       controversial whether that activation plays a causal role in action       interpretation. in the experiment reported here, we used offline       continuous theta-burst stimulation (ctbs) to investigate this       question. all participants received offline ctbs to the hand area of       vpmc in one session and to the lip area in a separate session, and       after each session performed an action-interpretation task in which       half of the trials were pantomimed hand actions and half were       pantomimed mouth actions. the results show that participants       were less accurate in interpreting hand actions after receiving       ctbs over the hand area than after receiving stimulation over the       lip area, and less accurate at interpreting lip actions after receiving       ctbs over the lip area than after receiving stimulation over the       hand area. this double dissociation provides evidence in support of       the claim that somatotopically organized regions of vpmc       contribute causally to action interpretation, and the claim that       action production and action interpretation rely on overlapping       mechanisms. in more general terms, they reveal an involvement of       the motor system in more sophisticated cognitive processes than       has hitherto been demonstrated.
recent evidence suggests that we have an intuitive number sense       and that visuospatial processes may ground simple mathematical reasoning, but       higher level mathematical cognition is often assumed to depend only on the       manipulation of symbolic expressions, governed by a set of rules and logical       axioms. to assess rule vs. visuospatial thinking in a higher level mathematical       domain, we asked undergraduates to solve trigonometry problems and to report       their use of rules, mnemonics, and visuospatial representations including the       unit circle, right triangle, and sine and cosine waves. use of the unit circle       was reported most commonly, and was associated with better performance, even       after controlling for the extent and recency of trigonometry experience. while       unit circle users took more time, their performance was robust to problems that       rule users tended to fail. our findings suggest that even higher level       mathematical cognition is more than just the manipulation of symbolic       expressions.
the glamorgan problem solver (glam-ps), an example of a       computationally implemented theory of embodied cognition, is a novel cognitive       architecture that has been applied to algebra problem solving, tower of london       problem solving and stroop tasks. glam-ps is a distributed production system       architecture, with all modules playing a role either in perception or action.        each module has its own working memory, production memory and production matching       bottleneck.  inter-module communication allows each module to see the working       memory of other modules and to coordinate action with activity in other modules.        despite the lack of explicit goal representation the architecture is able to       model offline multi-step problem solving in algebra.  action representations are       used to hierarchically structure action in tower of london problem solving,       allowing ‘subgoaling’ of particular disks.  performance on stroop       tasks highlights the architecture’s ability to model controlled behaviour.        these domains demonstrate glam-ps potential for providing insights into human       behaviour.
much effort has been devoted to exploring the ways in which       manipulating attention during encoding influences performance on memory tasks       (craik et al., 1996). however, fewer studies have examined the effects of       manipulating attention during memory retrieval. the purpose of this study was to       further examine selective attention at retrieval in the young and elderly.       younger and older adult participants were exposed to a study list followed by a       recognition test. participants made memory decisions under selective attention or       full attention conditions (dudukovic et al., 2009). participants then completed a       memory test consisting of items that had been previously tested under full       attention, selective attention, and selectively ignored conditions as well as       previously untested items. the results suggest that selective attention during       retrieval does not result in significant costs for memory decisions regardless of       age group. the results are discussed with reference to current theories of aging,       attention, and memory.
sleep-associated consolidation plays an important role in language       learning (dumay & gaskell, 2007; gomez et al., 2006). here we test the hypothesis       that greater levels of arbitrariness in the material to be learned are associated       with an increased involvement of sleep (eichenbaum et al., 1999). two participant       groups were trained to equivalent levels on novel words incorporating       regularities mirroring a grammatical gender system. after training, participants       had a 90-min break filled with either a polysomnographically recorded nap or an       awake control task. subsequently, the nap group outperformed the wake group in       recognition and recall of the trained vocabulary items. both groups showed       evidence of generalization of the systematic aspects of the grammar to untrained       items, but the nap group outperformed the awake on the grammar test on the       trained items. the findings are discussed in the context of the complementary       learning systems approach (kumaran & mcclelland, 2012; mcclelland etal.       1995).
the present study examined how the presentation of similar       situation to character’s situation would support children’s empathic       understandings toward character. according to barnes & thagard(1997), people find       similar situation of which the target is in, and transfer the emerging emotional       state to target to understand his feelings empathically. therefore, it was       expected that teacher’s presentation of similar situation to       character’s situation would scaffold children’s understandings toward       character’s feelings. sixth graders’ 6 moral education lessons were       observed and speeches were recorded. the scenes, where similar situations to       character’s situations were provided by teacher and used by children, were       analyzed. as a result of qualitative analysis, the followings were found: 1)       children who had difficulties in understanding characters’ feelings were       able to imagine it by using presented similar situations. 2) teacher presented       similar situations to emphasize not only “similarity”, but       “differences” between situations to prompt children’s       understandings toward characters.
an expression style refers the graphical or phonological style of       language. (i.e., letters or phonemes in words). in daily life, typographies or       prosodies are often made to harmonize its connotative meanings with words’       meanings they convey. to investigate the role of these harmonization, we       demonstrated previously that the harmonization between words’ meaning and       the typography at encoding had effects on implicit memory in the visual       word-fragment completion task (wfc), which implied that harmonization facilitated       visual processing of presented words. expecting that harmonization in sound and       word’s meaning has same effects, we conducted another experiment, which       manipulating the harmonization between words’ meaning and their prosody in       utterance, using an auditory and visual (classical) wfc. the results showed no       effects of harmonization. these results suggest that typography in visual       processing and prosody in auditory processing had different function in their       connotative meanings. 
in this study, the relationship between prior recall and       recognition and its effects on false memory was investigated using low and high       confusable phonological associates. participants who had falsely recalled       critical words in an earlier phase were less likely to falsely recognize them       later. this pattern of results is in contrast with veridical memory, where       participants were more likely to recognize a word after correctly recalling it       earlier. we further investigated this phenomenon with the remember-know paradigm,       and found that recognition of prior recalled words was associated with more       remember responses while recognition of falsely recalled critical words was       associated with more know responses. these findings suggest that the underlying       processes for veridical and false recognition may each involve different aspects       of recollection and familiarity for phonological associates.
production choices are driven by many factors: experience with       language statistics, task-or message-specific factors and constraints on human       cognition. understanding how these constraints operate together is crucial for       understanding sentence production.        speakers described human and inanimate targets (baby/vase) in scenes showing       human agents acting on these targets. the task elicited relative clauses to       contrast targets from competitors (“the baby/vase that the woman is       carrying/that is being carried by the woman”). participant utterances were       affected by target noun animacy, and this effect persists across languages. this       suggests a role for learning; a speaker’s lifetime of experience with their       language, including structure alternatives afforded by each language, affects       production choices.        in addition to long-term learning, immediate demands affect production choices.       targets varied in visual salience, which affected structure choices. effects are       consistent with a task-dependent account of visual salience.        immediate and long-term learning motivations for these effects will be       discussed.
worry consists of intrusive, repetitive negative thoughts, usually       in verbal form, about a future event of uncertain outcome. excessive occupation       of working memory (wm) subsystems by worry-related representations might cause       deficits in wm performance and efficiency. attentional control theory (act)       predicts that worry occupies the central executive, but not the storage       components of wm (phonological loop, visuospatial sketchpad). we tested worry       effects on visuospatial and verbal wm memory tasks, with and without binding, in       46 brazilian undergradutes divided into a low-worry (lw, n=21, 11 female) and a       high-worry (hw, n=25, 23 female) group. the hw group showed significantly lower       accuracy in the verbal tasks and higher reaction times in the visuospatial tasks.       within the hw group, binding caused lower accuracy in the visual task and lower       rts in the verbal task. results are discussed according to act, which predicts       differential effects of worry on performance and efficiency accross wm       modalities.
altruistic punishment has a central role in cooperation among       humans. people punish uncooperative individuals at a cost to themselves, inducing       adherence to social norms. little is known about altruistic punishment comparing       ingroup and outgroup context. using fmri, we studied the behavior of altruistic       punishment during the third party punishment game. this game shows the behavior       spending one’s own money, without any personal benefit, to punish unfair       behavior of player a who violate cooperation norms to player b.this behavior may       be differently displayed depending on the in-group (player c and b same       nationality) versus out-group (player c and b different nationality) setting, in       favor to one’s own group. this attitude is called parochial altruism.       preliminary results showed activation of anterior cingolate cortex involved in       conflict between cognitive and emotional motivations in altruistic punishment.       data also show activation of anterior insula that reflects social norm violations       during unfair ingroup condition.
participants were trained to perform a multitasking task involving       prioritizing the sorting of a set of objects while frequently being interrupted       by new objects to sort. after training, during an fmri session, participants       performed both the original task and a version of the task in which the function       of a key part of the interface was modified. analysis focused on the cognitive       control network, a set of regions that decrease in activity with increasing       levels of task experience. the functional connectivity of the anterior insula       with the other regions of the control net work predicted the degree to which       participants successfully adapted to this modified task better than other       individual difference variables collected. the anterior insula is thought to be       part of a salience network, and this salience network may help to inhibit old       rules of the task set that must be replaced by new rules. 
actions in joint tasks are affected by the way the partner is       acting. as action planning is mediated by an anticipation of their sensory       consequences, this influence is likely to encompass the expected reactions of       others to one's own actions. if so, it should be easier to perform actions that       trigger compatible partner reactions instead of incompatible ones. to test this,       we used a spatial action-effect compatibility paradigm in a joint task. subjects       moved virtual objects to different locations on a multi-touch table, followed by       either a partner's manual reactions on the same or another object, or by       automatic visual effects. there was a tendency for faster performance of actions       with compatible effects, and no interaction with effect type. however, for the       joint condition alone, no reliable compatibility benefit was found. the results       highlight several difficulties in applying the basic research on ideomotor action       control to more naturalistic, joint tasks.
upon reading headlines like “traffic fatalities fell last       year,” people often overestimate how well they would have anticipated       changes. in the present study, participants who estimated fatality statistics and       listed possible causes before learning true statistics (foresight) were more       surprised than those who listed possible causes only after learning true       statistics (hindsight). pezzo (2003) linked hindsight bias to causal explanations       that minimize initial surprise after an outcome—but to what extent can       people build an expectation for alternative causation before learning the true       outcome? before seeing true statistics, a subset of our foresight participants       listed causes for changes in the opposite of their expected direction. this did       not reduce surprise for those who learned that statistics had moved in the       opposite of expected direction, but the number of opposite causes they provided       reliably predicted their second set of estimates. moreover, participants       frequently explained surprising statistics using their earlier alternative       causes.
abstract: one of the promising strains of humanoid robotics is       that which focuses on explicating and reproducing “inner” cognitive       functions of humans. this approach is motivated by an ambitious aim of realizing       a human-like mind in a robot. in this general context, we have been working on       the mechanism of joint attention, the ability of which infants acquire during the       earlier stage of development. we already succeeded in constructing a robot which       can engage in joint attention activity of an elementary level.        in a more matured stage, however, humans ascribe intentions to each other in       joint attention. in order to realize this process in a robot, it is not       sufficient for them merely to acquire the ability to follow others’ eye       direction. our point is that it is necessary to implement in a robot the relevant       inferential mechanism which involves an apparatus for emotion-detection and       object-categorization. in our presentation, we will show how this mechanism can       work well in our infant-robot.       
the distractor-response binding effect states (frings, rothermund,       & wentura, 2007) that distractors appearing on a prime display create an       association with the response given. this association is retrieved when, in the       probe, the distractor is repeated; the retrieved response can be compatible or       incompatible to the currently demanded probe response thereby influencing       behavior. we tested if the distractor-response binding effect also occurs in       decision making processes under uncertainty (n = 31). participants had to decide       whether two consecutive, imagined patients suffered from either of two diseases.       each decision was based on two cues; one did not discriminate between the two       diseases and the other was either strongly or mildly associated with one of the       two diseases. the repeating of the irrelevant cue influences decision       significantly. furthermore, we replicated these findings when we varied the       strength of the discriminating cue as between-subject factor. 
when engaging in concurrent multitasking, it quickly becomes clear       that some activities combine well, while others do not. but which factors       determine the compatibility of different tasks? we propose that the overlap in       cognitive resources causes interference between tasks that limit performance, and       that this performance can be predicted using a cognitive model. to test this, we       built a model of three tasks, each using a well-defined set of cognitive       resources. these tasks were executed separately as well as concurrently and the       performance of the model was recorded. afterwards, we ran an experiment where       participants had to perform the same paradigm. our results show that the model       prediction has a good qualitative fit to the participant data: task combinations       with more resource overlap had lower performance when performed concurrently,       compared to combinations with little or no overlap.
when two individuals engage in their tasks with a common stimulus       display, the partner’s presence, response, task, and/or focus of attention       often affects one’s own task performance. the present study investigates       how the partner’s task affects one’s own task performance when one of       two adjacently sitting participants engages in location-relevant task and the       other in location-irrelevant task, with a common stimulus display and separate       response sets. the target appeared at left or right. one participant pressed a       left or right button according to the color of the target when it was green or       red. the other participant pressed a left or right button of another response set       according to the location of the target when it was white. although the spatial       compatibility effects were observed within each task, no cross-task (i.e.,       cross-participant) interference was observed. results are discussed in terms of       what is co-represented in joint task settings.
story-telling performers often rely on their audience’s       smiles, sounds of laughter, body movements, and other qualitative observations to       gauge whether their performances are appreciated by the audience. the current       study aims to capture the temporal patterns between a performer and his or her       audience. a professional rakugo story-teller performed live in front of 20       audience members aged 16 to 67 (m = 40.6, sd = 16.4) in a laboratory. videotaped       performances were categorized by a computer-aided coding system, and the       audience’s reactions were quantified using the face-tracking and background       subtraction computer program. results demonstrated performer-audience       correlations only in a particular frequency band. while the audience often smiled       in response to incongruent lines and interpreted gestures, the performer       sometimes delivered the points only after audience-initiated smiles and       movements. this dynamic co-creation may offer suggestions for a variety of       orators who speak regularly in front of audiences.
the ability to choose problem solving strategies flexibly and       adaptively is an important part of expertise. however, it is unclear how simple       forms of problem solving practice affect flexibility. we investigate to what       extent flexibility in strategy use is dependent on learners’       characteristics as intelligence, working memory and prior knowledge and to what       extent these individual differences influence how a student can exploit a       learning situation.         in a microgenetic design with 24 trials of a mathematical problem solving task,       we found that ninth-graders adaptivity of strategy choices increased linearly       during practice without feedback and that feedback on strategy adaptivity       facilitated the process. adapting strategy choices to problem types led to       shorter solution paths, higher solution rates, and higher speed. this is true       independently of students’ intelligence or working memory capacity.       however, prior knowledge was a predictor of adaptivity, thus leading to a faster       development of adaptivity.        
the purpose of this study is to extend a method of dynamic       estimation of emphasizing points (deep) to estimate the emphasizing points of a       group. a preliminary experiment investigated whether the interaction process       would differ depending on the interaction style used, avoiding conflict or       expressing opinions. the difference is caused by confidence in their opinions and       their commitment to the decision making. we also proposed two extended methods       corresponding to the different interaction processes. we then conducted an       experiment to evaluate the methods using embodied conversational agents. in       conclusion, these proposed methods accurately estimate proposals and satisfy       participants in the appropriate group. we could also observe that the       participants carefully looked to their partner for their reaction in "avoiding       conflict" group and that the participants concentrated on execution of the task       in "expressing opinions" group.
the layout of targets is known to affect spatial memory in       association with special frames of reference. however, most of the previous       studies have been conducted on the learning from specific viewpoints. the present       study examines whether the layout, as the structure of special reference points,       has any effect on special memory when learning from all sides while walking       around targets. in the experiment, participants explored a virtual circular room       under the one of two conditions. the objects were arranged like spots on dice. in       the square array, 4 objects were set in a square shape, while in the node array,       one more object was added at the center. after the learning phase, they judged       the directions of the targets from several imaginary positions of the room. the       results suggest that the participants in the node array made quicker and more       accurate judgments than those in the square array.
this study examined how the students' expectation of context       sharing with audience causes effects on their writing arguments. fourth-grade       students (n=30) from elementary school in japan were assigned to do two writing       argument tasks. in each task, students made an argument and persuaded different       audiences (transfer student and old friend) at random. the contents of written       arguments were categorized into "claims", "evidence", and "reasoning". moreover,       difficulty of each audience's persuasion and its reasons were asked in       questionnaire. the analysis suggested followings. (1) students generated more       "reasoning" in transfer student condition than old friend. (2) students evaluated       persuasion of transfer student was more difficult than old friend. students       judged that the transfer students do not share much context with them, so they       tried to persuade by giving more information. the students read the degree of       context sharing and changed the contents of writing with changing audiences.
what are the “cognitive after-effects” of making a       similarity judgement? what, cognitively, is left behind and what effect might       these residues have on subsequent processing?  in this paper, we probe for such       after-effects using a visual search task, performed after a task in which       pictures of real-world objects were compared. so, target objects were first       presented in a comparison task (e.g., rate the similarity of this object to       another) thus, presumably, modifying some of their features before asking people       to visually search for the same object in complex scenes (with distractors and       camouflaged backgrounds). as visual search is known to be influenced by the       features of target objects, then any after-effects of the comparison task should       be revealed in subsequent visual searches. results showed that when people       previously rated an object as being high on a scale (e.g., colour similarity or       general similarity) then visual search is inhibited (slower rts and more saccades       in eye-tracking) relative to an object being rated as low in the  same scale.       there was also some evidence that different comparison tasks (e.g., compare on       colour or compare on general similarity) have differential effects on visual       search.
there have been two distinct notions of heuristics, i.e., kahneman       and tversky’s (1974) heuristics as biased approximations to rational       inference, and gigerenzer et al.’s (1999) idea of smart and adaptive       heuristics. despite the conceptual differences, we provide evidence that       heuristics can be seen as approximations to a rational account which is at its       core adaptive. in a large cross-validation, we demonstrate that a regularized       regression model (from machine learning) with a penalty noise parameter could       outperform both heuristics and simple linear regression. importantly, the       penalized regression with an l2-norm could be approximated by tallying, whereas       the l1-norm was approximated by take-the-best. results indicate that the       penalized regression treats both heuristics and linear regression as extreme       cases of the model. the research implies a common rational basis for heuristics       and integrative strategies, suggesting that the relation need not be adversarial.       implications for reconciling adaptive and irrational views of heuristics are       discussed.
people often rely on popular scientific information when seeking       advice for health-related issues. in these cases, further usage of such       information should be influenced by its presentation. with n  = 157 students, we       examined how referring to the tentativeness of health information by using hedges       and pointing to the origin of scientific knowledge in science-related texts       impacts processes of decision-making. we found that decisions were easier to make       when there was no indication given. furthermore, participants’ further use       of text-related information was more likely when hedges were used. in contrast,       individuals rather relied on their own knowledge when there were no linguistic       markers of tentativeness. additionally, participants’ decisions were more       in favor of the direction implied in the texts when no indication of the sources       of the science-related information was given. however, no effect of experimental       manipulation on the confidence of the decisions exists. finally, we discuss how       the presentation of information may contribute to engaging in critical and       elaborated processing of scientific information.
in linguistic pragmatics and social anthropology, several       influential researchers believe that politeness is essential for maintaining       social order by way of disarming potential aggressiveness [goffman 1967; brown &       levinson 1987; gumpers 1987]. in one of the most detailed of these theories,       brown and levinson's, speakers pursue a single goal (e.g. getting the hearer to       stop doing something) by using a mental model of the hearer to select a position       on a one-dimensional spectrum of strategies that identifies the best balance       between achieving the speaker's practical goal while avoiding offense to the       hearer (as might occur from a purely brusque request). but are speakers actually       limited to this one-dimensional spectrum of strategies? and given that people       often pursue more than one goal at once, how might they do so in such a       simplistic model of polite communication? i describe and evaluate a computational       model that generates strategies for multiple simultaneous goals.
previously, we investigated the distribution of instances of       early-learned object-based categories in toddler’s realistic everyday       learning episodes; we found important differences in terms of frequency and       variability (3d vs. 2d; real object vs. realistic toy vs. simple shape).        using a picture book task we tested 24-36 month olds’ recognition of these       categories in four conditions: realistic; features (only parts of the photo       visible); silhouettes; and geons (a shape caricature version made with only 3-4       parts and no color or texture). results show similar recognition for all       realistic and silhouette versions; geons were lower than the first two; and       features had the lowest recognition rate. critically, categories with the highest       variability in our previous study were readily recognized by features but       difficult to recognize in geon version. these results suggest that abstracting       global shape is influenced by the specific trajectory of experienced       exemplars.
complex network analysis is applied to study late second language       (l2) acquisition using highly proficient late l2 learners when compared to       monolinguals performing a morphosyntactic task. specifically, we assess for       (dis)similar topological properties of the functional networks associated with a       gender mismatch condition between article and noun at the beginning of a sentence       in a spanish monolingual group and a group of late learners of spanish whose       native language is english (which does not encode gender as a grammatical       category). our results suggest that the detection of incorrect grammatical gender       agreement in spanish recruits the neural networks that subserve the cognitive       processing differently in each group. this result provides insight into the       functional cooperation and interactions of brain areas while processing an l2       trait not present in l1.
human communication compresses a massive amount of conceptual       structure into conventionalized speech patterns. how do these patterns emerge?       experimental semiotics offers new empirical techniques to address such questions       (fay et al., 2008; galantucci, 2005; garrod et al., 2007; kirby et al., 2008). we       devised an experiment to observe the emergence of communicative conventions. the       study explores the development of vocal communication systems through an       iterative vocal charades game. the game is played by two players each given a       stack of 12 cards. written on each card is a word from six antonymic pairs       (rough/smooth, bad/good, etc.). over ten rounds, players took turns       “vocalizing” the meaning of their words without using language or       gestures. analyses reveal how sounds conventionalize, leading to stereotyped       forms and improved guessing. the conventional forms that develop are predicted by       iconic correspondences with meaning, but also exhibit more arbitrary features       that distinguish semantically similar words.
humans are exquisitely sensitive to social interactions. this       study explored whether this extends to interactions in music performance. jazz       musicians are fluent at working together to produce music that is more than the       sum of its parts, and listeners claim anecdotally to hear when musicians are       ‘in the groove’. we employed jazz-standard duets varying in the       opportunity for collaboration (two-way, one-way, none), to test listeners’       perception of collaboration. in experiment 1, participants rated random       selections from these recordings in the dimensions of synergy, creativity,       emotionality, and engagement. results showed considerable sensitivity to       collaboration, with sensitivity varying both with social intelligence and musical       training of the participant. in experiment 2, participants made explicit       judgments of whether the selections involved collaboration, with the results       showing they could not. we conclude that the degree of collaboration in joint       musical performances influences the implicit experience of listeners, but is not       accessible for explicit judgments.
in face-to-face communication people have problems recalling which       facts they have disclosed to whom. we explore if such destination memory (dm)       problems also exist in computer-mediated communication (cmc). participants (n =       64) disclosed 50 pieces of personal information to 50 fictitious partners in a       sham skype environment in two conditions, one-sided “telling” and       communicative “turn-taking”. their recall for facts, faces, and       fact-face-pairs was measured as dependent variables. anova results show a       significant main effect of type of recall (f (2,61) = 222.47, p < .001):       recall for facts was better than for faces or fact-face-pairs, indicating that dm       problems emerge when faces are previously unknown. additionally, we found a       significant main effect of conditions (f (1,62) = 6.75, p = .012): contrary to       expectations recall in the “telling” condition was best. these       interesting findings and those of a second study will be discussed considering       the specific characteristics of cmc.
creating correct shape categories requires young children to       overcome reliance on perceptual features and surface similarity as cues for       membership and to use abstract rules as bases for categorization (e.g., triangles       are enclosed shapes with three sides). relying on surface similarity, children       often wrongly include non-triangles that resemble familiar triangles in the       triangle category, and exclude unfamiliar actual triangles. this study attempted       to improve preschool-age children’s triangle categorizations by presenting       structurally aligned comparisons that either shared a common structure or that       highlighted a contrasting structure. across both types of comparisons, the       exemplars were either highly or lowly superficially similar (both variables       manipulated between subjects). we hypothesized that low-similarity       common-structure comparisons would support extension of the triangle category       beyond prototypical exemplars, while high-similarity contrastive alignments would       highlight category boundaries. preliminary results suggested that improvement in       categorization accuracy was primarily driven by a reduction in erroneous       identification of a non-triangle as a triangle.
this study explores how previous experience affects current       performance. despite the vast amount of research on transfer and learning effect       in problem-solving, as far as we know little to no work has been done on how       failure to solve a problem affects subsequent problem-solving ability. the       current experiment explores this issue and the role of working memory in the       process. two variables were manipulated – the experienced success or       failure on a single multiplication problem and the amount of working memory       resources required by the following addition problem. results show negative       impact of failure on subsequent process-time: the problem-solving time for the       addition problem was higher for participants who failed to solve the       multiplication problem. there was no interaction between experienced performance       and the wm resources required by the subsequent problem. these results suggest       that researchers must probably be careful to avoid fixation on failure as a       confounding variable.
two experiments will be presented. experiment 1 examined whether       simultaneously observing and making gestures while studying animations would       lighten cognitive load and facilitate the acquisition of grammatical rules, as       would be predicted by theories of embodied cognition and cognitive load. however,       results showed that children in the gesturing condition performed worse on a       subsequent test than children in the control condition. this was particularly       true for children with low levels of general language skills, whereas children       with high language skills experienced no detrimental effects of gesturing.       because simultaneously observing and making gestures hampered learning, the       question is whether only observing gestures would be effective. moreover, because       it is still unclear whether seeing animated sentence transformations has a       positive effect on learning, experiment 2 compares the effects of three       instructional conditions for both low and high-ability learners: static pictures,       animation without observing gestures, and animation with observing gestures.
earlier studies showed an important role of vocal imitation in       social interactions. at least some kinds of social imitative behavior, including       gesture and pitch adaptation, appear to be triggered by direct eye gaze (wang,       ramsey & hamilton, 2011). past research indicated that autistic individuals may       have difficulties with both shared gaze focus and joint attention. therefore, we       might expect that their vocal imitative behavior would differ from the behavior       of td individuals. in our study, we explored vocal imitation by autistic speakers       in an experiment with stimuli eliciting eye contact (shared focus), joint       attention or a disruption of eye contact. 
in psychology, philosophy, and linguistics there has been a debate       about two competing frameworks of causal reasoning. dependency theories,       especially causal bayes nets, focus on causally motivated statistical or       counterfactual dependencies between events (causes and effects). in contrast,       force dynamic theories implement causation as arising (deterministically) from       force interactions involving agents impinging on the prior tendencies of       patients. to date force dynamic theories have primarily focused on the       representation of different semantic causal concepts in scene descriptions. our       goal is to bring the two competing frameworks together. we will present a model       that implements the interaction between agents and patients in terms of       probabilistic forces. we have tested this new model in an experiment in which we       tested how contingency information interacts with the assumptions about intrinsic       tendencies of patients in people’s usage of semantic causal concepts (e.g.,       cause, prevent, hinder, help, allow, and enable). 
the n400 erp component is widely used in research on language and       semantics, but the specific underlying mechanisms are currently unclear. we       explored the mechanisms underlying the n400 by examining how a connectionist       semantic network’s performance measures covary with n400 amplitudes. we       simulated six n400 effects obtained in empirical research. network error was       consistently in the same direction as n400 amplitudes, namely smaller for high       frequency words, words with few semantic features, semantically related targets       and repeated words. furthermore, the repetition-induced decrease was stronger for       low frequency words and words with many features. in contrast, semantic       activation corresponded less well with the n400, and instead seemed related to       lexical decision performance. our results suggest an interesting relation between       n400 amplitudes and semantic network error. in psychological terms, network error       has been conceptualized as implicit prediction error. thus, n400 amplitudes may       reflect implicit prediction error in semantic memory (mcclelland, 1994).
how do we map joint actions we participate in onto joint actions       we observe others performing, such as when a couple dancing tango observes       another couple dancing tango? we investigated this question using a task where       participants were instructed to perform individual or joint movements in       synchrony with individual or joint movements observed on a computer screen. the       observed movements started slowly and then continuously increased in tempo (from       1.75 hz to 3 hz). the results showed that, with regard to spatial parameters,       joint performance was more accurate when observing joint performance than when       observing individual performance. individual performance was more accurate when       observing individual action than when observing joint action. there were no       systematic differences with regard to timing parameters. these results suggest       that mechanisms of temporal coordination may be less susceptible to differences       between individual and joint action than mechanisms of spatial matching.
the cognitive mechanisms that underlie beliefs in the supernatural       are not well       understood. in an attempt to understand this phenomenon, we hypothesized that the       cave       environment “affords” such usage. in our experiment, 52 participants       completed a survey       about their metaphysical beliefs inside a room providing a great deal of natural       light,       while another 52 participants completed the same survey in a dark and windowless       room.       the survey asked participants to rate their beliefs in a variety of supernatural       phenomena       and also included multiple-choice questions which described bizarre scenarios       that could       be explained either scientifically or supernaturally. the supernatural responses       to both       the rating-scale questions and to the multiple-choice questions were       significantly higher       in the cave-like condition. these results are consistent with anthropological       claims       that the dark zones of caves may have played a role in the environment of       evolutionary       adaptedness that contributed to humans’ tendency toward magical       thinking.
the human ability to learn from sparse rewards has been modeled       with the temporal difference learning mechanism, using an actor-critic       architecture (montague, dayan, & sejnowski, 1996). these models incorporate an       "adaptive critic" which learns a "value function": a mapping from the learner's       current situation to expected future reward. in complex environments, a "value       function approximator" (vfa) must be implemented to allow generalization between       similar situations. while some implementations of vfas have been successful       (tesauro, 1992), this approach does not consistently converge to a solution       (boyan and moore, 1995). with the goal of developing a general and reliable vfa       mechanism, capturing human level learning performance, we have explored the use       of spiking neural networks, including liquid state machines, as a technique for       vfa learning in complex environments. we report on simulations demonstrating the       benefits and pitfalls of using the temporal dynamics of neural spikes to encode       the learner's state. 
in the picture-word interference paradigm low-frequency words have       been shown to induce longer naming times, and thus more interference, than       high-frequency words. in this study we used event-related potentials (erps) to       explore the time course and locus of frequency effects within the language       production system. furthermore, we tested whether frequency effects are related       to non-lexical variables such as valence and arousal. we presented pictures and       superimposed high and low-frequency distractors and additionally varied the       emotional valence and arousal of the distractor words. the effects of distractor       frequency in naming times and erps - starting at about 300 ms - were modulated by       arousal, suggesting that non-lexical mechanisms can modulate distractor effects       in the picture-word interference paradigm. 
infant language learners are faced with the difficult inductive       problem of determining how new words map to novel or known objects in their       environment. bayesian inference models have been successful at using the sparse       information available in natural child-directed speech to build candidate       lexicons and infer speakers' referential intentions. we begin by showing that       when a bayesian model is optimized for monolingual input (frank et al., 2009),       the model does not sufficiently handle bilingual input, especially as referential       ambiguity increases. here we propose an extended bayesian model that approximates       infants' mutual exclusivity bias to support the differential demands of       monolingual and bilingual learning situations. the extended model is assessed       using corpora of real child-directed speech, showing that performance can be       optimized for both monolingual and bilingual contexts. we show that including       both monolingual and bilingual demands in model optimization yields significantly       different results than when only one context is considered.        frank, m. c., goodman, n. d., & tenenbaum, j. b. (2009). using speakers’       referential intentions to model early cross-situational word learning.       psychological science, 1-8.
recent evidence suggests that lexical-semantic activation spread,       including the formation of ad-hoc relations, can be dynamically shaped by       contextual factors (abdel rahman & melinger, 2011). in this study we investigated       whether cognitive processing modes can affect lexical-semantic activation during       single word production. specifically, we tested whether prior processing of       linguistic ambiguities, presented in the form of puns, has an influence on the       co-activation of unrelated meanings of homophones in a subsequent language       production task. in a picture-word interference paradigm with word distractors       that were semantically related or unrelated to the non-depicted meanings of       homophones we found facilitation induced by related words only when participants       listened to puns before object naming, but not when they heard jokes with       unambiguous linguistic stimuli. this finding suggests that a cognitive mode of       ambiguity processing can induce the activation of ambiguous messages during       speech planning. 
research on causal-based categorization focuses on how people       categorize exemplars that have causally linked features. one prominent account,       the generative model (rehder, 2003) models membership judgments as a function of       an exemplar's likelihood being generated by the category's causal model. in       contrast, mayrhofer and rothe (2012) found that the explanatory role of the       causal model strongly influences membership judgments - indicating the importance       of explanatory reasoning processes and that in such tasks people might be guided       by explanatory goodness (i.e., how well an exemplar's membership can be explained       in the light of the category's causal relations). however, the evidence for this       claim was quite indirect so far. in the present categorization study, we       collected judgments about category membership, frequency, and explanatory       goodness. in contrast to the predictions of the generative model, membership       ratings are far better resembled by ratings of explanatory goodness than by       subjects' estimations of exemplar likelihood. 
this study investigated the influence of interaction gestures on       learning       using multi-touch-tables. during a learning phase, participants learned how to       categorize renaissance and baroque paintings either by moving them over       the display of the multi-touch-table or by tapping a marked field on the       display representing an art epoch. in the testing phase, participants had       to categorize paintings known from the learning phase and new paintings       in a forced-choice task. the gestural conceptual mapping approach argues       that congruency between gesture and mental processes enhances learning. due       to the discrete nature of the categorization process, learning should       benefit from a discrete tapping gesture. the reality-based interaction       approach argues that gestures should map with interaction       experiences in the real world to promote learning. moving objects to       places that represent categories can be considered similar to the real       world experience of sorting objects and should facilitate category       learning. the results support the latter approach.       
the challenge of integration of virtual agents and co-robots into       the human society requires for these future artifacts to become human-compatible,       in addition to being generally intelligent and capable of providing specific       expertise. specifically, a human-compatible agent should be able to induce in       humans a sense of co-presence of a potentially equal mind capable of mutual       understanding and human-like learning, long-term personal relationships and       generous initiative. achieving these qualities requires social emotional       intelligence. in order to be able to implement equivalents of social emotions in       artifacts, it is vital to better understand social interactions in small groups       based on cognitive architectures like ebica (samsonovich, 2013). the present work       makes one step further in this direction, continuing the development and       computational exploration of the new framework for emotional cognitive       architectures. in the focus are relationships of trust and mutual respect,       leadership and allegiance, and related to them social and complex emotions.
the dimensional change card sort (dccs) task is a model paradigm       for studying developmental change attention switching during childhood. in the       dccs, children are asked to sort two-dimensional cards (e.g., blue star) by one       dimension and then again by the other. typically, 3-year-olds fail to switch       dimensions, continuing to sort the cards by the first dimension. four-year-olds       readily switch dimensions. the source of this sudden developmental change has       been widely debated. a recent proposal is that only older children are able to       selectively attend to one dimension, enabling them to flexibly switch the       dimension along which they sort. we present results showing that experience       matching values along one dimension prior to participating in the dccs task       facilitates 3-year-olds’ ability to switch dimensions. we implemented this       experience in a dynamic neural field model of dccs performance and found that it       mimicked developmental change in dimensional attention in the model. 
the metaphor of cognition as a dynamical system - which evolves       under external forces, is constrained by the internal structure, and is shaped by       the agent's behavioral history - is a fruitful source of inspiration guiding       experimental and theoretical work. dynamic field theory offers a framework, in       which cognitive processes and their development may be modeled quantitatively as       dynamics of activation functions defined over behaviorally-relevant parameter       spaces. although learning through memory trace formation is an integral part of       the dft, the behavioral spaces are assumed to be given. however, these spaces may       be shaped autonomously while acting in an environment. the autonomy of learning       processes is achieved if the behavioral states have intentional structure, which       sustains representations to enable learning and ensures their deactivation when       appropriate. in this work, i show how intentional structure realized with dynamic       neural fields enables autonomous development of a sensorimotor mapping involved       in looking behavior.
search requires individuals to balance exploration (finding new       resources) with exploitation (making use of current resources) over time. how       individuals perceive reward in a temporally extended search may significantly       influence their explore/exploit decisions. furthermore, how individuals perceive       reward is related to impulsivity. different aspects of impulsivity can lead to       different predictions for people's search patterns. we tested some of these       predictions in a search task with a non-depleting condition where resources would       maintain value when exploited, and a depleting condition where resources lost       value when exploited.  participants with larger temporal discounting rates       (greater impulsivity) started exploiting depleting resources later than those       with smaller discount rates, surprisingly appearing more patient and performing       closer to the optimal level. however, this difference disappeared when resources       were non-depleting. greater impulsivity might make individuals more risk-seeking       in the depleting search environment and thus explore depleting resources longer       at the beginning phase of the search task.
behaviorism and cognitivism are two perspectives in cognitive       science that have had significant impact in the evolution of mind theory.       behaviorism is centered in the study of mind from the perspective of externalized       behavior. behaviorism is opposed to the approach to mind analysis from an       introspective point of view, even rejecting the existence of internal states.        the cognitivist reaction explained some aspects of memory and learning that       behaviorism failed to account for. internal mental states –beliefs, values,       intentions- are the common trade of cognitivist models. cognitivism employs       computer-based information processing as the paradigmatic principle sustaining       cognitive modeling, where data structures implement the required internal mental       states. these two approaches to cognitive science are usually considered as       antagonistic; but they are not. the only difference is that they approach the       problem of the modeling of mind from an input/output perspective or from a       state-based perspective. behaviorism focuses on using a black box model of minds       while cognitivism focuses on white box models. both are right and complementary       approaches and are degenerate forms of a more fundamental approach that may be       applied to mind modeling: systems identification. 
for almost a half century, it has been known that participants       consider the truth value of “if p then q,” in a       “defective” way, as true when p and q are both true, false when p is       true but q is false, but uncertain whenever p is false. recently, researchers has       given this truth table a new normative status, under the theory of subjective       probability by de finetti, as of conditional event, q|p. on the basis of ample       evidence that p(if p then q)=p(q|p), we study biconditionals, “if p then q,       and if q then p.” here we show the psychological priority of biconditional       event to material equivalence. additionally, we discuss the logical background of       (bi-)conditional event and three types of uncertainty. two are ones in the domain       and codomain of the truth-function, and the other is connected to the       indefiniteness of a world or the frame problem.
perceptual categorization is a key problem for an agent to cope       with its internal and external world. following a functional and subjective       approach of cognitive modeling, the primary purpose of perceptual categorization       is modeled as the valuation of a stimulus regarding its potential to satisfy an       agent’s current needs. additionally an integrated and holistic approach is       used, where categorization considers the integration of subjective influences.       such an approach complies with the consideration of top-down perception and       priming. using an activation-based exemplar model, the objective criterion of       perceptual similarity, which represents bottom-up aspects of perception, and the       subjective expectation-based criterion of cathexis, which represents top-down       aspects of perception, are integrated in a holistic multi-criteria model of       perceptual categorization. an artificial life simulation demonstrates the       model’s ability to relate stimulus objects to an agent’s internal       needs. additionally, the usage of multiple criteria provides a more confident       valuation of stimulus objects.
during mind wandering, attention is directed away from the       external environment and cognitive processing is decoupled. mind wandering is       usually treated as a dichotomy and often measured using self-reports. we here       propose the levels-of-inattention hypothesis, postulating graded decoupling at       different processing levels. to measure levels of decoupling during reading we       introduce the sustained attention to stimulus task (sast), which relies on       psychophysics of error detection. we found that subjects were less likely to       notice errors at higher levels of cognitive processing. eye tracking showed that       before errors were overlooked effects of high- and low-level linguistic variables       were reduced in a graded fashion, indicating episodes of weak and deep       decoupling. individual gaze durations predicted overlooking of errors five       seconds before they occurred. our findings support the levels-of-inattention       hypothesis and suggest levels of mind wandering can be measured in the sast. eye       tracking provides a promising tool to detect mind wandering online. 
while metaphor comprehension deficits were initially reported in       right hemisphere lesion patients (rhls), more recent work fails to find such       deficits. one possibility is that the metalinguistic tasks typically used only       uncover conscious, controlled comprehension processes. we tested the hypothesis       that chronic rhls would show a deficit in a task that taps automatic processes,       even if their performance on a metalinguistic task was not abnormal.  nine rhl       were tested on a sentence/matching-word lexical decision priming task with       literal and metaphorical sentences and a short soa. nine left hemisphere lesion       patients and thirteen age and education matched healthy adults served as       controls. a two-way mixed anova revealed a main effect of sentence type (f(1,28)       = 7.0, p = .01) but no effect of group. all three groups showed larger priming       effects for literal sentences (m=70ms sd=70ms) than for metaphorical sentences       (m=34ms, sd=68ms). these data suggest chronic rhls do not have metaphor       comprehension deficits even with an automatic processing task. 
this contribution presents studies currently underway about the       impact of interactive, digital maps in architectural settings. google indoor maps       allows users of android smartphones to identify their position and heading in       complex public buildings. the study compares participants with and without access       to such a device. participants perform both spatial learning and free navigation       tasks in a building. we evaluate how their wayfinding behavior as well as       performance on spatial memory measures differs between groups with respect to:       efficiency, effectiveness on the task; satisfaction and perceived competence with       both the digital device and the building setting. we further compare groups with       high vs. low spatial abilities (perspective taking, sbsod sense of direction) as       well as different cognitive styles (route vs. survey preference), as expect an       impact on both strategies of interacting with the device and task success.
we investigated interactions between mothers and their children       and specifically measured differences in the mothers’ verbal and nonverbal       communication as a function of their children's age.        forty two-year-old children and forty five-year-old children and their mothers       were video-recorded in two conversational settings. measures were obtained for       the mothers' speech complexity (mlu, use of verbs, complex sentences, and direct       objects), their emotional prosody (pitch, pitch variability), and their pointing       gestures.        mothers of 5-year-olds used more complex speech than mothers of 2-year-olds,       whereas mothers of 2-year-olds showed more emotional prosody, and pointed more       often than mothers of five-year-olds. this is interpreted as an adaptation to       their children's conversational abilities. as younger children do not understand       very complex utterances, but might rely on more nonverbal communication (such as       pointing gestures and emotional prosody) than older children, their mothers might       use a less verbally complex, but rather emotionally rich and non-verbally       sophisticated interaction style. 
the aim of the reported study was to test the hypothesis that       text-picture combinations aid learning because pictures reduce the       learners’ need to actively generate mental images on their own. this, in       turn, should free up cognitive resources which can be used for other cognitive       processes associated with learning, resulting in better performance compared to a       text-only condition. this hypothesis was confirmed in an experiment based on a       2x2 design with picture presentation prior to text (yes vs. no) and visuo-spatial       secondary task (with vs. without) as independent variables: learners without       pictures showed a higher load of the visuo-spatial sketchpad (i.e., higher       interference with the secondary task) during text processing than learners with       pictures, presumably because the former generated mental images during reading.       this interpretation is supported by the finding that pictures were especially       helpful for learners with low imagery capacity. the implications of these results       are discussed.
when people move through large-scale environments, they use       multiple strategies to find their ways. while many studies have investigated       individual wayfinding strategies, in naturalistic settings people usually       don’t navigate alone, but search for their destinations in pairs or small       groups. having a shared goal can have an impact on the perception of the scene,       the attentional focus and the behavior of the individual participant. we       investigate how social interaction influences navigation behavior and focus on a       cooperative scenario. we developed a joint wayfinding paradigm to measure walking       trajectories, walking speed, gaze behavior and speech data in a naturalistic       indoor setting. we use two mobile eyetracking devices to analyse the behavior of       pairs of participants solving wayfinding tasks. we’ll present data on the       impact of participants’ cooperation behavior on perceptual and attentional       processes and wayfinding strategies.
this study examined whether listeners keep spatial story       representation created by speaker’s cohesive gestures beyond the concurrent       sentence. participants were presented with three-sentence discourse with two       protagonists, in the first and second sentences, the gestures consistently       assigned the two protagonists in either right or left of the gesture space. the       third sentence (without gestures) referred to one of the protagonists, and the       participants responded with one of the two keys to indicate the relevant       protagonist. the response keys were either spatially congruent or incongruent       with the gesturally established locations for the two participants.  experiments       1 and 2 showed that the performance in the congruent condition was better than       that in the incongruent condition. thus, listeners make a spatial story       representation based on the gestures, and the spatial representation persists       beyond the concurrent sentence, and the information is still activated in a       subsequent sentence without a gesture.  
in this study we manipulated colors and shapes in different blocks       in order to investigate the differential effect of stable spatial cues on color       and shape recall. the task involves recency judgment where two items from the       stream of serially presented stimuli are shown and the subjects have to respond       by indicating which of them came later in the sequence. our studies show a clear       dissociation between color and shape recall. while spatial cues seem to       facilitate shape recall, they seem to degrade the color recall performance. this       effect becomes significant for shape-location trials beyond the working memory       capacity limit of 4 items. the results can be interpreted as if individuation of       colored objects draws from the same attentional resources as spatial attention       and the resulting competition degrades performance in serial order judgment       involving color whereas shape recall does not seem to be subject such       competition.
it has been suggested that in creative activities, cognition and       physical action are related to each other. this study focuses on this       relationship in breakdance, which is a creative activity of artistic and       acrobatic movements. for four months, we conducted field observations of practice       sessions of three expert breakdancers, and held interviews with them to       investigate the creation process of new and original movements. the video records       of the 34 practices and the interview data were analyzed with respect to two       aspects: 1) whether or not the dancers performed important movements       appropriately; and 2) what the dancers were thinking when generating new aspects       of the movements. the results show an interactive process between the development       of dance movements and the generation of ideas. the dancers gradually became able       to perform the movements appropriately by generating new ideas, and they       generated new ideas using the somatic sensation of the new movements.
a peer-based reviewing on writing often leads to improving       learners’ writing quality. particularly, reviewing by writing comments       lifted writing quality more greatly than reviewing without writing comments. this       implies that learners’ hard working on peers’ writing engenders       benefits on their own writing. this study attempted to explore which cognitive       mechanism underlies in this cooperative learning system. we questioned whether       learners’ use of metacognitive strategies during reviewing might facilitate       learners’ self-learning. in a preliminary study, participants were asked to       categorize their comments on peers’ reports. results from the study       revealed that learners who categorized comments used metacognitive strategies       more increasingly than those who did not. controlling for the amount of using       metacognitive strategies, writing quality was improved numerically more when       learners were engaged in the categorization task than when they were not. with       further data, we will examine to what degree learners’ metacognitive       learning during reviewing contribute to writing improvement. 
precise walking requires ample cognitive resource to control       balance in the single leg stance while head moves periodically in the vertical       axis within each stride cycle. because visual information is a key factor in       motor control, we hypothesize that walking alters the allocation of visual       attention, thereby affecting the selective intake of visual information.       participants localized a peripheral dot while identifying the central letter in a       display during treadmill walking, stepping in place, and standing still. vertical       head movement occurred only in the walking condition. results show that visual       attention was skewed in the single leg stance during walking and stepping in       place. vertical head movement affected the allocation of visual attention because       only in the walking condition was attention oriented downward without skewing       during the double leg stance. cognitive resources and head vertical movement       appear to work differently in adaptation of visual attention to walking. 
past research has demonstrated that neighborhood variables (e.g.,       neighborhood density) influence lexical processing (andrews, 1989; vitevitch &       luce, 1999), but can have distinct effects for different languages (vitevitch and       stamer, 2006). to explore how neighborhoods can vary both within and across       multiple languages, we have developed clearpond (the cross-linguistic easy-access       resource for phonological and orthographic neighborhood densities), a database of       phonological and orthographic neighborhood information for five languages: dutch,       english, french, german, and spanish. analyses using the clearpond database       revealed consistent effects of lexical frequency and word-length on neighborhood       size across languages, while also highlighting how the languages differed in the       distribution of neighbor-types (phonological/orthographic). clearpond not only       provides a tool that can be used to study differences between languages but also       provides detailed information about characteristics of individual words in       multiple languages. the clearpond database is freely-available online and can be       accessed at http://clearpond.northwestern.edu.
listening to a 90-sec excerpt of thematic music (e.g., baby music)       affects performance in a subsequent generation task by increasing the likelihood       that concepts associated with the thematic music (e.g., “sleep,”       “baby”) will be incorporated into the novel product (sifonis & fuss,       2012). the generation task theme (e.g., writing a story about a visit to an alien       planet versus writing about a visit to an undiscovered, foreign land) also       interacts with the music theme to affect the degree to which concepts associated       with the music are incorporated into the generated product.        the current study tested and supported the hypothesis that listening to thematic       music activates complex schematic structures. the generation task theme provides       context, thus affecting the specific manifestation of the thematic elements in       the generation task (e.g., including concepts associated with a foreign land with       many children versus those associated with an alien planet with many children).       
a new theory of visuo-spatial mental imagery and a computational       model of the theory are presented.        the theory assumes (visual) perception to be an active and guided process       comprising of several low-level perceptual actions. mental concepts are grounded       in sets of such actions. imagery comprises the "offline" employment of these       actions providing concrete instances of the mental concepts through bodily       feedback such as proprioception.       the theory is compared to the contemporary theories and evaluated against a set       of well established phenomena, i.e., mental scanning, mental reinterpretation,       eye movements, unilateral neglect.       it is argued that the theory provides explanations that go beyond those offered       by the contemporary theories.        the results provide support for the explanatory power of an embodied approach to       cognition in which sensorimotor interaction constitutes conceptual knowledge in       that it provides grounding and concrete manifestation of the semantics of mental       concepts in the domain of visuo-spatial mental imagery.
the aims of the current study are to analyze research evidence of       the ways in which collective recall exhibits extended social identity effects .       our core hypothesis was that the use of twitter as a recall tool significantly       contributes to social identity generation in general and self-categorization in       particular. based on a study of a representative sample of latvian-language       twittersphere, we argue that a social network serves a two-fold role: (a) it       extends the individual self as part of a distributed social reality and as part       of a distributed on-line social network.        the core results of our study show that twitter functions as an extended       distributive linguistic cognitive system supporting different kinds of recall       tasks while at the same time exhibiting strong categorization effects through       eliminating redundant information and reducing the descriptive complexity of the       environment in recall.        
efficient visually-guided behavior depends on our ability to form,       retain, and compare visual representations that may be separated in space and       time. this ability relies on visual working memory (vwm). here, we describe a       layered neural architecture that captures the cortical population dynamics that       underlie vwm. we then test this model using functional neuroimaging. recent work       has shown that the bold response is strongly correlated with local field       potentials (lfps). an analog of lfps can be estimated from dynamic neural field       (dnf) models. this estimate can be convolved with an impulse response function to       yield time-dependent hemodynamic predictions. using this approach, we show that       the dfn model quantitatively captures fmri data from recent studies probing       changes in the bold response in the intraparietal sulcus (ips) as set size       increases in change detection. we also test a novel prediction of the model that       bold responses should be greater on false alarms versus misses. these data run       counter to common explanations of the origin of errors in change detection.
we investigated the relationship between linguistic and visual       information, combining divided visual field and blank screen paradigms. in an       eye-tracking experiment, two objects appeared for 180 ms, one in the right (rvf)       and one in the left visual field (lvf), while participants maintained central       fixation. after the objects disappeared, a word was presented auditorily. in       matching trails (50%), it indicated one of the objects previously shown.       participants had to decide whether the word named a man-made or a natural entity.       findings revealed that they were more likely to saccade toward the side of the       referent object when it had been presented in the lvf than in the rvf. moreover,       saccades in the lvf targeted more precisely the object’s empty location.       this suggests a crucial role of the right hemisphere in activating visual       representations during language processing, indicating its greater ability in       using spatial indexes to retrieve useful visual information.
recent work has started to ask to what degree common ground, i.e.       shared background knowledge, may affect the articulation of co-speech gestures,       specifically as regards viewpoint. we extend that work by asking how gesture       articulation is affected, and how the spatial location of those gestures changes       as a result of common ground. using naturalistic data, we find that with quotes       grounded in past interactions, co-speech gestures are fewer and smaller, whereas       with quotes ungrounded in past interactions (ugpi), co-speech gestures are more       numerous and larger. moreover, when speakers repeatedly reference the same       entity, the co-speech gestures used become smaller with each repeated reference,       thereby suggesting a kind of ‘online’ grounding. we also find that       the use of gestural space is more consistent for ugpi utterances. this suggests       that common ground affects both the articulation of gestures, and the way that       gesture space is used.
abstract: this study compared 4th grade children in the u.s. and       taiwan on understanding (linearity, area, and volume. taiwanese and american       children were both under 50% correct for the concepts of area and volume in       october. by may, taiwanese children learned 90% of the targeted concepts.       american children were still under 50% correct.        during the following year, u.s. children received five weeks of instruction on       linear, square, and cubic measure, or they received no instruction. results       showed significant increases on accurate knowledge of all measurement concepts,       average score = 89%. improvement was related, at the .72 level, to memory for       forward going digit span. the control group did not improve on any type of       measurement concept, despite their similar scores on memory for digit span. a       third study showed that repeated practice on multiplication lowered the effects       that digit span memory has on learning measurement concepts.       
fictive motion (specifically the co-extension path type:       “the road runs through the desert”) is widely considered a specific       class of figurative language. however, cognitive-linguistic and       conceptual-metaphoric evidence is presented which suggests that linguistically       expressed motion in fictive motion implicitly refers to the processing of a       concrete action: to eye motion that occurs while scanning along a static visual       percept (or mental image). as such, fictive motion differs principally from       genuinely figurative expressions like argument is war – the figurative       element of the latter cannot be interpreted as referring directly to a physically       existing action or object. also demonstrated is how a       “non-figurative” theoretical approach to fictive motion can explain       and predict so-called “non-fictive motion”; fictive motion-like       temporal cognition; and fictive-motion types other than co-extension path. it is       also shown how the various experimental cognitive and neurocognitive findings on       fictive motion can be (re)interpreted in the new framework.
a common view in the judgment and decision making literature is       that humans posses a repertoire of decision strategies, from which we choose       adaptively when dealing with decision situations. modeling this adaptive strategy       selection process has proved to be difficult, but advances were recently made by       modeling it as a reinforcement learning process. dieckmann and rieskamp (2007)       investigated the influence of information redundancy in a multiple-cue learning       setting and found surprising evidence for adaptive strategy selection in       situations without outcome feedback, which is difficult to explain by a pure       reinforcement learning model. we challenge these findings by pointing out       problems in their experimental design. we replicate their experiment, add       conditions with stricter experimental controls, and investigate possible       underlying mechanisms. in conditions with stricter controls we find no evidence       that participants manage to incorporate information redundancy into strategy       selection and conclude there is no adaptive strategy selection without outcome       feedback.
we are poor lie detectors, with accuracy only marginally better       than guessing. raters in social situations such as these must battle with their       own uncertainty if they are to make a judgment, yet lie detection research has       given little attention to the effects of uncertainty. we present evidence       suggesting prior knowledge and expectations have an early influence on the       judgment process, but only when forced into judgment. if able to abstain, raters       do not rely on prior knowledge but rather indicate their uncertainty by       withholding judgment until all the available information has been presented.       after the speaker has presented their statement, and when no additional new       information is available, we provide evidence from a number of experiments that       lie detectors integrate their pre-existing biases and experience about deception       in general with more specific information about the statement at hand.
recent research supports the notion that word learning can be       conceptualized as a statistical learning process. as many have noted however,       statistical learning is constrained by processes such as attention and memory.       here we tested an attentionally constrained framework of statistical word       learning. we observed, through infant-perspective head cameras, infants’       visual input as parents labeled novel objects during an infant-parent object-play       session. we then constructed statistical learning models that aggregate       word-to-object associations. we fed a baseline model the word-to-object       co-occurrence patterns obtained from parent-infant observations. we fed an       attentionally constrained model weighted co-occurrence patterns based on the       perceptual properties of the objects (i.e., object sizes from the infant’s       view) at the time words were uttered. models’ learning was compared to       children’s forced-choice test results. of interest is which of the two       models best approximates children’s learning. implications of these results       for statistical learning accounts of word learning will be discussed.       
in sentence processing, retrieval cue parsing accounts predict       that processing difficulty occurs due to interference between similar noun       phrases at verb integration (van dyke & lewis, 2003; van dyke, 2007). an       important factor is number marking of the nouns because the number of the verb       and the subject has to agree. according to lewis and vasishth (2005), different       types of retrieval cue overlap (e.g., verb subcategorisation, semantics, number)       should all cause interference simultaneously during processing. however, van dyke       (2007) reported that interference due to subcategorisation overlap preceded       semantic interference, suggesting that syntactic interference may occur before       interference due to other cues. we investigated whether interference due to       number overlap also occurs later than interference due to subcategorisation       overlap. interestingly, using eye-tracking, we found that the number congruency       effect occurred early and no later than the subcategorisation interference       effect, indicating that number interference has a very rapid effect on sentence       processing.
affective stimuli encountered in everyday life - such as emotional       words, scenes or facial expressions - can elicit well-investigated emotional       experiences. for instance, two distinct event-related brain potentials (erps)       have been reported in response to emotional facial expressions, an early       posterior negativity (epn), associated with enhanced attention and perception of       affective stimuli, and a later centro-parietal positivity (lpp), assumed to       reflect processing of the intrinsic relevance of emotional stimuli. other rich       sources of emotions that have yet received little attention in eeg research are       internal mental events such as thoughts, memories and imagination.         here we investigated mental imagery of emotional facial expressions and its time       course using erps. we presented participants with neutral faces and asked them to       imagine the faces with an emotional or neutral expression. early erp modulations       during imagery resemble the effects frequently reported for emotional facial       expressions, suggesting shared early processes underlying emotion perception and       imagination.
the current study investigated the effect of perspective       preference on spatial learning. previous studies revealed that certain factors,       such as strategies and goals, affect wayfinding behavior and map learning. we       focused on perspective preference as analyzed through measurement of eye       movements, which enables us examine potential differences in spatial learning. we       divided university students into a survey or route preference group through a       map-learning questionnaire. while participants studied the maps, we measured       participants’ eye movements to each map element (landmarks, streets, and       compass rose). after studying a map, participants completed verification tasks       and wrote their own map of the learned environment. in contrast to our       prediction, the survey and route groups did not show the difference in regard to       their gaze to most of the map elements. although results did not emerge as       expected, we discuss the effect of perspective preference on map learning and       memory.
in extracting statistical regularities from the seemingly random       environment, our minds grow special interests in patterns. to account for such a       behavior, much research has been focusing on top-down influences such as the       representativeness heuristic and bayesian belief updating. here we take a       reverse-engineering approach by first examining the waiting time statistics and       the self-overlap property of patterns and revealing a normative basis for       people's special attention to patterns. with a unsupervised neural network       simulation, we show that different patterns may leave different traces in mind       corresponding to the waiting time statistics, indicating an early pattern       dissociation without any top-down guidance. we argue that the sense of randomness       could have started locally with short sequences and emerged early at the       perceptual level, and, the process of spatial-temporal association may be the       early driving force towards a structured hypothesis space.
after decades of research, the reason why people are attracted to       the supernatural (paranormal, magical, superstitions) is poorly understood. it is       possible that the question has been approached from the wrong angle and that it       is skepticism that needs to be explained, not the beliefs.  taking this as a       starting point, we examined (n = 40) whether skeptics have stronger cognitive       inhibition than believers. because cognitive load disrupts inhibition and reveals       intuitive thinking, we hypothesized that working memory load increases       ontological confusions less among skeptics than among believers.  ontological       confusions, such as conceiving of lifeless objects as having mental states, are       known to be central to supernatural beliefs. the results supported the       hypothesis.  strong cognitive inhibition may thus partly explain why supernatural       beliefs, albeit based on natural information processing, seem so unbelievable to       millions of people. an ongoing study examines skeptics’ and       believers’ cognitive inhibition in more detail.
a classic paradigm for investigating memory is the category recall       task, where participants recall as many items as possible from a given category,       within some time window. category recall tasks have been used to investigate       memory as a search process, where memory is conceptualized as a landscape with       distributed resources (resources being the target items of memory recall). rhodes       and turvey (2007) show that the dynamics of memory search are akin to animal       foraging behavior. specifically, patterns of recall exhibited lévy       processes, which have been observed in many species and at many scales, and are       hypothesized to be optimal under certain conditions. here, we investigate the       effects of social context on lévy processes using a collaborative category       recall task. although the processes of collaborative recall may differ from       individual recall, our results suggest that the products of that recall are       similar.
the present study utilizes a novel task to test two competing       hypotheses concerning the automaticity of dishonesty. the traditional hypothesis       claims that in order to act dishonestly one has to first overcome the truth bias,       which results in more time and effort. the opposing hypothesis indicates that       lying in order to serve self-interest is an automatic tendency, and therefore       takes less time than refraining from lying.        the goal is to look at the action dynamics of dishonesty in order to investigate       its underlying cognitive processes. subjects were asked to privately predict the       outcome of a virtual coin-flip. after observing the actual outcome they reported       whether their prediction was correct or wrong. the movements of the mouse towards       the target answer were recorded and used for action dynamic analysis. our results       support the latter hypothesis indicating that dishonest people take less time and       experience less hesitation while choosing the deceptive answer.
text comprehension is the process of searching and uniting       information. in this process, some pragmatic triggers such as metaphorical       expressions can help select important sentences from the text. in this regard,       taira and kusumi’s (2008) demonstration of the effect of metaphor       comprehension on the text rereading process is controversial and lacking in       persuasive data. this study comprises two aspects: a reanalysis of taira and       kusumi and an additional experiment examining how the effect of metaphor       comprehension on text rereading works. the results of this study showed the       effect of metaphor, and indicated two points: (1) the effect of metaphor provide       a meaning-searching process that showed a delayed reading time of sentences that       describe important information regarding a text topic, and (2) this effect was       shown in the case of unfamiliar metaphors, and not familiar metaphors.
the art concept plays an essential part in the creation of       contemporary art. in order to capture the progress of the formation process of an       art concept, we conducted a case study of a contemporary artist. we interviewed a       professional artist about his creation process once every three weeks for about       ten months. this report focuses on an early phase of the search for ideas, in       which he took many photographs to collect visual information to form the core       part of the art concept. using both the photographs he took and the interview       data collected during this phase, we identify when and how features of his art       concept emerged. the results show that his art concept was formed through cycles       of two types of search for visual information: an active, explorative search to       find the unexpected, and more a focused search to interpret it.
some classically rational standards for actions such as       optimization are simply intractable. we often instead satisfice a certain       reference level that is good enough for us. we can use some heuristics but they       may lead to biases. though rational analysis by anderson (1990) can argue the       adaptive rationality of biases in relation to the environmental structure,       heuristics and biases have been mostly studied in isolation from other factors in       conformity with the tradition in psychology. to show the efficacy of the       subrational heuristics in union, we execute computer simulations adopting the       framework of reinforcement learning that models iterative decision-making under       uncertainty. we implement three characteristics representative of human behavior:       satisficing (simon, 1952), risk attitudes and reflection (tversky & kahneman,       1981), and comparative valuation (kahneman & tversky, 1979). we show that they,       combined together, exhibit an adaptively optimal behavior with an extremely easy       parameter tuning.
displacement, which is to express absent objects, is one of the       important design features of human language. it has not been well considered in       the context of communication. we conducted a graphical communication experiment       to investigate displacement in communication. in this experiment, two adults are       paired, and a sender drew an absent object expressed by an unconventional       combination of two words, adjective and noun, while a receiver answered what the       drawing represented. this process was repeated 8 times for one object in each       pair. the senders usually drew two pictures corresponding to two words,       respectively. the analysis of results indicated that nouns should be understood       in advance for understanding adjectives which are difficult to represent by       drawings. this suggested that in displaced communication source-target mapping       strategy was used to compose expressions like metaphors, and that identifying       which expression represents a target was important in order to understand absent       objects.
origami paper folding involves challenging spatial problem       solving, including a number of complex cognitive processes that have not been       extensively explored. to gain insights into the nature of these processes, we had       participants think aloud while following origami instructions (verbal and       pictorial). our analysis of participants’ verbalizations revealed recurring       patterns that reflect the underlying cognitive processes. namely it showed       evidence of reading and reformulating the task description, considering actions       and task status, comparing task status to instructional pictures, evaluating       progress, referring to previous experience, recognizing problems, and adding       ideas about the current instructional step. the last two categories highlight how       participants conceptualized this spatial task. the verbalizations also reflect a       typical order that the cognitive processes follow: reading – reformulating       – reconceptualizing – evaluating. the recurring pattern in this       ordering suggests that participants gradually moved away from the original       instruction towards a broader conceptualization for action in the current       context.
despite a vast amount of research, debate continues concerning the       mechanisms underlying correct use of morphological systems such as the english       past tense. relatively little is known about precisely what, when, and how       children acquire aspects of inflectional morphology due to the paucity of studies       examining the earliest stages of development, and the generally narrow focus on a       small number of items and predictors.  to address these problems, we provide       comprehensive evidence concerning the earliest stages of development. 543       english-speaking children (196 2-year-olds, 176 3-year-olds, 171 4-year-olds)       took part in a past tense elicitation task. responses were elicited for 300 verbs       (200 for 2-yr-olds) and measures derived (largely from child-directed-speech) for       a wide range of frequency, phonological and semantic predictor variables. we       present the outcomes of analyses relating these novel predictor variables to the       unique behavioural dataset, revealing the cognitive and linguistic underpinnings       of children’s early past tense development.   
listeners customize speech processing to accommodate       talker-specific phonetic variation. for example, listeners modify established       phonetic boundaries to incorporate a talker’s idiosyncratic productions. in       addition to being marked by boundaries, phonetic categories exhibit a graded       internal structure, with some members of the category considered better members       than others. here we examined whether sensitivity to talker-specific phonetic       variation influences internal category structure. two groups of listeners heard a       talker produce /k/. word-initial voice-onset-time (vot) was manipulated such that       one group heard the talker produce /k/ with shorter vots relative to the other.       listeners were then presented with a range of vots and asked to rate each for       goodness as /k/. results to date indicate that exposure during training robustly       influences the range of vots considered the best exemplars of /k/, suggesting       that accommodating talker-specific phonetic variation results in a comprehensive       re-mapping of acoustic-phonetic space and is not limited to the boundary       region.
the stimulus equivalence paradigm studies the learning of stimulus       classes (categories) composed of functionally equivalent stimuli with or without       perceptual similarities. the relations between stimuli in a class can either be       learned or be derived from other stimulus relations: if stimulus a is equivalent       to b, and b to c, then the equivalence between a and c can be derived without       explicit training. there has been little work on the mechanisms underlying       equivalence class formation. here we present a neurobiologically plausible neural       network model of stimulus class learning. the network successfully models three       classic studies on stimulus equivalence.  the hebbian weights in the model       describe the formed equivalences and the levels of association between class       members, and resulting activation patterns are correlated with the response       accuracy and response latencies in the original studies. the model predicts that       stimulus equivalence formation depends on the environmental regularities of       stimuli occurrence and co-occurrence.
crisis management (cm) situations are most-often complex and       dynamic, and require team members to make optimal decisions under constraints of       high risk, uncertainty, high workload, and time pressure (see, e.g., brehmer,       2007). an edge organization (eo) is an adaptive, rapidly reconfigurable, and       distributed team structure in which no roles are previously assigned, and       resources are not distributed in advance. such a team structure is assumed to be       able to improvise and respond quickly to emerging problems. we used the c3fire cm       simulation to measure the coordination (of units and resources) efficiency       amongst edge team members. twenty-four teams of four participants completed four       c3fire scenarios, each lasting 10 minutes. results revealed that team members       achieved better coordination as they progressed through the scenarios. this       learning effect suggests that it could be beneficial to train team members to       coordinate their actions efficiently and fully exploit the potential agility       provided by eo.
according to lynch (1960; p. 83) “the sequence [of       landmarks] facilitates recognition and memorization”. thus, under which       circumstances do landmarks facilitate wayfinding? we therefore investigated the       helpfulness of landmarks during route knowledge and survey knowledge retrieval       from long-term memory. a field study with citizens of a street festival in a       mid-size german town (giessen) was performed. sixty-three participants had to       draw the shortest possible route between two given locations in the town. within       this experiment, two different conditions were tested respectively: drawing the       route without landmarks and with additionally presented landmarks. a comparison       of conditions revealed different performance groups: perfect performance (8%);       performance improvement with additional landmarks (32%); equal performance in       both conditions (36%); and performance decrement with additional landmarks (23%).       these results were confirmed in two further experiments. we demonstrate that the       decremental findings may be a result of the so-called visual impedance effect       (knauff & johnson-laird, 2002).
the study aimed to study the inhibitory mechanism in syllogistic       reasoning when the outputs of the heuristic strategy and analytic reasoning       disagree. we manipulated the congruency of the quantifier of the conclusion with       those of the two premises according to the matching strategy and the validity of       the syllogism. after each syllogistic evaluation task, a lexical decision task       was used to check if the semantic content of the conclusions was inhibited. the       results suggested that after correctly solved conflict problems (match-invalid or       mismatch-valid), the semantic priming effect of the words related to the two       terms in the conclusion diminished. for no-conflict problems, the recognition       time of the related words was faster than that of the unrelated words. the       results suggested that inhibition on the content of a syllogism may not only be       triggered by the conflict induced by the believability but also by the surface       structure of the syllogisms.
research on the psychology of simple, perceptual choices has led       to an impressive progress in capturing the underlying mental processes as optimal       mechanisms. within this theoretical framework, perceptual decisions arise from a       feed-forward process involving the sampling and accumulation of momentary       evidence up to a decision boundary. according to this view, the stage where the       information is accumulated is automatic and decision makers can exert strategic       control on the decision boundary only, in order to adapt their performance to the       task demands (e.g. speed-accuracy trade-offs). we present new behavioural and       eye-tracking data challenging this view and suggesting that the way information       is accumulated in perceptual decisions, is subject to differential weighing that       depends on the task framing (e.g. select the brightest or the darkest spot). we       conclude that choices are mostly influenced by extreme values, and whether       positive or negative peaks are more pivotal is frame-dependent and subject to       top-down control.
recent research has demonstrated that with a positive prior       experience, an actor who decides to switch decisions should feel more regret than       one who decides to repeat (the status quo effect). conversely, with a negative       prior experience, the switcher should feel less regret than the repeater       (reversal of the status quo). we tested the influence of a maximizing tendency on       the strength of these two effects, measured using the japanese version of the       regret and maximization scale. in the positive prior experience scenario, the       maximizer group scored higher on presumed regret and counterfactual thinking than       the satisficer group. in the status quo scenario, the maximizer group scored       higher on counterfactual happiness than the satisficer group. our results       indicate that maximizers show a reversal of the status quo effect in some       settings.
self-explanation (se) is an effective strategy for improving       understanding and it relied on learners’ proper deployment of prior       knowledge. surprisingly, there is limited research on how might misconceptions       affects learning despite they are inherent part of learners’ knowledge       system. we examine the influence of se on processes and outcomes of science       learning for 36 sixth grade students by varying degrees of prior knowledge and       relevant misconceptions. the se group read and self-explained a text describing       state changes of water requiring proper notions of molecules while the control       group read twice and think aloud. the results indicated that there are no effects       of se, prior knowledge for learning outcomes. however there is significant effect       of se by misconception interaction. low misconception students benefit from se       but not for high misconception counterparts. se did influence amounts and types       of verbal protocol students generated. the results indicated that the influence       of se heavily modulated by learners’ misconceptions.
the purpose of this study is to examine whether japanese junior       high school pupils really dislike mathematics. in addition to questionnaires to       inquire explicitly of the likings of school subjects, we administered the fumie       tests (mori et al., 2008) to 512 junior high school pupils to assess the implicit       evaluative association to the school subjects. we found a considerable proportion       of pupils answered negatively to the target school subjects in the questionnaire       while their implicit association scores showed somewhat positive valences. the       discrepancies were larger for “mathematics” than       “science”. one hundred of 512 pupils answered negatively to       mathematics while their implicit measures were positive. in contrast, only five       of 102 showed the same discrepancy for science. these results imply that there       may exist a tendency to pretend to be a math-dislike in pupils. we discussed this       tendency that may eventually lead them to real math-dislikes.
an intrinsic motivation for social interaction has often been       proposed and is thought to be unique to the human species. however, little is       known about underlying neural mechanisms. here, we investigated whether       experiencing engagement in social interaction recruits the reward system of the       brain. a combined eye-tracking and fmri paradigm was used in which participants       interacted with a virtual agent in a series of gaze-based interactions in       real-time. to create situations in which they experience the interaction as       social or as non-social, they were made believe that during each block the       agent’s gaze behavior could either be controlled by another human       participant or a computer algorithm. the other participant was a confederate of       the experimenter, which enabled experimental control of the agent's gaze       reactions. after each block participants had to indicate whether they experienced       the interaction as social or not. results demonstrated that gaze-based       interactions with a perceived human partner is associated with activity in the       ventral striatum, a core component of reward-related neurocircuitry, while       interactions with a computer-driven agent activate attention networks. in       addition, the nature of the interaction with a human partner (naive vs.       cooperative) differentially modulates striatal activity. 
we examined the effects of participants’ linguistic       expertise on their communicative behaviors and their interactional attitudes in       conversations in their second language. quantitative analyses of eye-gazes during       utterances showed that the speakers with lower linguistic expertise were observed       more by the listeners in the second language conversations, whereas, the       listeners' expertise level did not affect the amount of their gazes to the       speakers. the analyses of a questionnaire suggested that the participants with       lower expertise were not conscious of their own gazing activities; they       self-evaluated the amount of their gazes to the speakers' eyes much lower in       conversations in their second language than those in their native language. the       participants with lower expertise evaluated the pressure they felt higher than       those with higher expertise. it is likely that they were too occupied with       conducting conversations to maintain enough control over their interaction       activities.        
bilinguals have been shown to activate their two languages       simultaneously during spoken word recognition (e.g., blumenfeld & marian, 2007).       we investigated whether top-down conceptual processing influences parallel       language activation using the visual world eye-tracking paradigm. cultural       knowledge was used to manipulate semantic activation in l1 during l2 word       processing. critical trials contained target items that were culturally       meaningful to individuals who grew up in germany, alongside german competitor       items that had word-initial phonological overlap with the target word. we       hypothesized that german-english bilinguals would fixate the german competitor       items more in the culturally salient condition than in the culturally neutral       condition. preliminary data from seven german-english bilinguals and 10 english       monolinguals revealed a competitor effect in the culturally salient condition       only for bilinguals (p=.03), with no effect in the culturally-neural condition       (p>.1). results suggest that activation of cultural knowledge in bilinguals       exerts a conceptual top-down influence on parallel language activation. 
retrieving information from memory improves the long-term       retention of that information more than continued restudying (e.g., karpicke &       roediger, 2008). we investigate if this testing-effect can be applied to word       learning during reading by manipulating the sentence context in which words are       presented. in a within-subject experiment, adult learners without prior knowledge       of swahili studied 80 swahili words and then repeatedly read the words either in       an l1-context that was uninformative and required the retrieval of word meanings       from memory to be understood (e.g., “i use the =funguo=”) or in a       rich context that enabled the readers to derive word meanings (e.g., “i use       the =funguo= to unlock the door”). recall-accuracy and speed for the newly       learned words were measured during reading as well as immediately and seven days       after practice to evaluate effects of sentence context and retrieval success       during reading on the retention of word form and meaning. 
one of the most distinctive characteristics of the parallel       distributed processing (pdp) approach to cognitive modeling is that       representations are distributed across a large set of units. however, this is not       always the case. in a series of simulations we show that pdp neural networks tend       to form localist representations under certain conditions. first, localist       representations are developed when the mapping between the input and output       patterns is arbitrary. a second pressure to learn localist codes comes from       having to keep multiple representations active at the same time. introducing       biologically plausible constraints on the network architecture also fosters       developing local codes. taken together, these findings suggest that the       widespread assumption that pdp neural networks learn distributed representations       is often wrong. moreover, exploring the computational reasons for which pdp learn       localist representations provides insight into why selective neurons are often       found in the brain. 
moyamoya disease is a rare entity characterized by progressive       narrowing of intracranial blood vessels. moyamoya in most cases does not respond       well to medical therapy and often leads to surgical revascularization. the       physiological benefits of the surgery for moyamoya patients have been well       documented, yet the effects of surgery on cognitive skills are far less studied.       participants in the current study were 30 patients, 24 to 85 years of age, who       underwent surgery and were all treated at mayo clinic in jacksonville, florida.       all patients underwent a physical and cognitive preoperative evaluation, where       speech, memory, and intellectual processes were measured. after the surgical       intervention, patients returned for 3 follow-up assessments over a period of 6       months. all patients experienced stabilization or improvement of physiological       symptoms. regarding cognitive functions, speech, memory, and intellectual       processes improved significantly after surgery. further prospective studies are       needed to better assess cognitive outcomes after revascularization for       moyamoya.
the degrees of separation are essential in the study of social       networks. we develop a graph theoretical methodology inspired in this concept to       study behavioral data. having a similarity measure appropriate to the data, we       propose to build a graph connecting each agent its nearest n neighbors, having       that their similarity exceeds a threshold p. from here, graph theoretical       indicators such as connectivity and clustering can be studied as functions of p       and n.        we apply this methodology to a psychological experiment where 97 participants       estimate the typicality of 8 objects with respect to the concept       “hat”, in 2 contexts. using correlation distance as a similarity       function, we compute clustering properties, and average path length as functions       of n and p. interestingly, only n=20 connections are required to keep the       similarity structure of the system, having an average path length near 2.       
ever seen two people walking down the street in the exact same       pace? this kind of interpersonal synchrony has been observed in both humans, as       well as in animals (e.g., large groups of fireflies flash at the same time,       schools of fish and flocks of birds synchronize their movement). for animals it       appears to be beneficial (for survival) to synchronize their behavior, but what       are the benefits for humans to do so? there are indications that interpersonal       synchrony supports social bonding. previous studies have shown that interpersonal       synchrony can have both an effect on (e.g., increases memory), and can be       affected by social factors (e.g., higher likeability ratings, more interpersonal       synchrony). the goal of the present study was to examine whether social factors       (e.g., popularity, friendship) affect interpersonal synchrony when working       together. furthermore, we looked at the relation between interpersonal synchrony       and learning and likeability.
when participants observe a man who looks to have fallen or jumped       off of a cliff, spatial memories of the man’s location are further down a       gravitational trajectory compared to his actual location (freyd, 1985). previous       research has repeatedly observed that inferring gravity – a top-down       process – modulates spatial memory. the present study found that       differences in the eye gaze orientation of the man by a cliff such as facing up       or facing down, and linguistic information such as ‘jumped’ or       ‘fell’, independently influence the spatial memory of the man’s       location. a brief discussion is presented regarding the influences of top-down       and bottom-up processes in spatial memory.
richardson, spivey and hoover (2009) observed that attending to       one of two choices in a decision making task increases the likelihood of that       response by ten percent. reflexive gaze orientation, attending to the same area       as others, has also been shown to influence reaction times on simple dual choice       tasks. the current study addressed how the eye gaze direction of a highly       simplified face influences decisions made regarding questions with no obvious       answer. observed results indicate that the appearance of eyes looking toward one       answer over another significantly impacts the decision making process. similar to       past work on the impact of social stimuli on orienting, we show that social       stimuli can also impact decision making under uncertainty.
previous research on word & category learning has hypothesized       that memory processes may be critical to the long-term ability to generalize       information. the current experiment was designed to elucidate the recognition       memory processes occurring during children and adults’ category learning.       participants were presented with a novel noun generalization task and five       recognition memory tasks. the results revealed that there were developmental       differences in (a) the retention for information presented during category       exemplar presentations, and, (b) the sub-categories of recognition memory that       were significantly related to category learning performance. these findings       suggest the relationship between recognition memory and category learning       processes may change across development.
in the last decade, numerous studies in inductive reasoning have       shown that people are remarkably quick at picking up the relevant features that       allow generalizations. one formal account of (some instances of) cases where this       ability emerges, relies on the assumptions people make about the manner in which       the observations are sampled from the world. according to a weak sampling scheme,       observations are randomly drawn from the environment. however, a reasoner can       also assume that the observations are sampled deliberately from the intended       hypothesis (strong sampling). in the present contribution, we compare these       assumptions in a inductive reasoning task using semantic stimuli from 4       superordinate concepts (animals, clothes, vehicles,musical instruments). model       analyses are performed to examine the sampling assumptions of reasoners in this       context. we find that people generally assume a strong sampling scheme. however,       the model seems to underestimate the relevance sensitivity of the       participants.
cognitive developmental research has documented that children       acquire rich knowledge about the physical and psychological world before they are       exposed to science, and that learning science requires substantial ontological,       epistemological and representational changes to happen in the conceptual system       of the child.  for example, vosniadou & skopeliti (2005) showed that while the       majority of third grade children categorized the earth as a physical object       distinct from solar objects like the sun and the moon, 90%  percent of 5th       graders categorized the earth as an astronomical object, belonging to the same       category as the sun and the moon. in the present research we will present two       novel, chronometric, tasks for assessing the conceptual re-organizations that       take place as children are exposed to systematic science instruction and for       further exploring the question of whether naive theories are overwritten or       survive and continue to exist together with the scientific theories.         references        vosniadou, s., & skopeliti, i. (2005). developmental shifts in children’s       categorizations of the earth. in b. g. bara, l. barsalou, & m. bucciarelli       (eds.), proceedings of the xxvii annual conference of the cognitive science       society, italy, 2325-2330.       
humans use counterfactual thinking in order to evaluate their       previous choices, comparing the actual outcome of a choice with what would have       happened if they had chosen another action option. two prototypical emotions       resulting from such counterfactual evaluations are guilt and regret, both of       which play an important role in regulating human choice behavior. guilt is       thought to refer specifically to social choices, while regret occurs for both       individual and social choices. here, we introduce an fmri compatible new       experimental paradigm to differentially induce guilt and regret under controlled       conditions as a result of real decision. behavioral data confirm that guilt but       not regret specifically occurs in a social context (i.e. after harm for another       person caused by own choices). on the neural level, initial results point to a       critical involvement of different sub-regions within the prefrontal cortex in the       processing of guilt vs. regret.
a critical step in language acquisition is segmenting speech into       words. prior cross-linguistic research demonstrates the importance of       language specific segmentation strategies (gervain & erra, 2012).       english-learning infants can use statistical information to segment       words in laboratory experiments (saffran et al., 1996), but its       informativeness in segmenting english is unclear (yang & gambell,       2004; swingley, 2005). we analyzed one corpus of 611,837       child-directed utterances (theakston et al, 2000; macwhinney, 2000),       and one corpus of 50,776 adult-directed utterances (pitt et al., 2007)       and found that, in both corpora, a simple strategy that assumes that       each syllable is a word would be highly effective in segmenting words.       accuracy was 69.68% and 61.7% in the child and adult corpora,       respectively, segmenting 87.44% and 87.90% of the corpora. these       findings should guide further investigations into the processes       infants actually use to segment speech, and more broadly how they       learn appropriate language-specific word segmentation strategies.       
a chinese sentence contains no extra spaces between words. we       hypothesize that implicit word segmentation by chinese readers is developed via       the statistical learning mechanism that is universal. twenty non-chinese speakers       were exposed to a sequence of 3600 characters constructed from six disyllabic       words with 6 different characters. the transitional probabilities between any two       characters were .46 to 1 within words, and 0 to .29 between words. the sequence       was presented one character every half a second. occasionally, the presentation       rate doubled. the participants’ task was to detect the instances of double       presentation. upon completing the task, a surprise test followed that consisted       of a word and a nonword (reversals of the characters in a word) from the       sequence. the participants had to decide which one had appeared before. the       averaged accuracy rate was greater than chance (.53). this suggests the       statistical learning mechanism is available to all language learners.
structure mapping theory (smt) is an important and influential       theory in       cognitive science. one unresolved issue is this theory's intractability. it       is known that finding optimally systematic analogies under smt is np-hard,       making it unrealistic that human analogizing is characterized by       optimality. yet, experimental studies suggest that the optimality assumption       gives the best fit to human performance data. a solution to this paradox may       be that smt can be efficiently approximated to such a degree that, for       practical intents and purposes, human analogies appear to be optimal.       however, outside of a limited empirical evaluation of the commonly-used       greedy sme heuristic given in forbus and oblinger (1990), no analyses of the        approximability of smt have been done to date. we fill this void by       providing both the first theoretical analyses of the types of efficient       approximability available for smt and the first systematic empirical       evaluation of the greedy sme heuristic.
three humans interacted with a spiking neural network model that       controls the lip and jaw muscles of a speech synthesizer. the model learns using       spike-timing dependent plasticity that is greater when reinforcement is received.       first the humans each selectively reinforced the model, encouraging it to more       frequently produce vocalizations with speech-like syllabic elements. afterwards,       for each human-reinforced simulation a yoked control simulation was generated.       all the sounds produced during the course of learning for all human-reinforced       and all yoked control simulations were then judged on a four-point syllable       quality scale by all three listeners (sounds were presented in random order). in       all cases, these judgments indicated that the human-reinforced models produced       more sophisticated babbling over the course of learning whereas the yoked control       simulations did not. the results support this model of how canonical babbling, a       major developmental milestone, may develop.
models of decision making neglect the impact of emotions on       information processing. here we present  a model of decision strategy selection       that can account for the differences in the use of two strategies, the       take-the-best heuristic (ttb) and the weighted additive rule (wadd) in a       probabilistic inference task. how can such a model incorporate emotions? our       model assumes attentional weighting of cues, controlled by the activity of locus       coeruleus  – a brainstem nucleus associated with physiological arousal.       using hierarchical bayesian modeling, the model was evaluated on data from a       study where participants performed a probabilistic inference task and emotional       stress was manipulated with highly aversive slides. for each participant we       estimated the parameter that controls cue weighting. this parameter correlated       positively with the proportion of choices consistent with ttb and negatively with       the proportion of choices consistent with wadd. moreover, this parameter was       sensitive to the emotional stress manipulation.        
languages exhibit statistical regularities concerning the       frequencies and co-occurrences of words. language users learn from such patterns       without being consciously aware of them. we investigated statistical properties       of the language used on television news in discussing politicians. we compiled       corpora consisting of language used on four networks (msnbc, abcnews, cnn,       foxnews) from 2007-2012. we analyzed the frequencies with which 500       affectively-valenced words co-occurred with politicians' names (obama, mccain,       romney) during the run-ups to the 2008 and 2012 elections. we used these       co-occurrences to derive a summary measure, their net positivity score.       positivity scores for candidates changed over time in ways that reflect       real-world events. positivity towards candidates differed across networks. net       positivity toward president obama during his first term was strongly correlated       with approval ratings. the results show that statistical aspects of language, of       which people are not consciously aware, convey varying attitudes on network       news.
spoken words are phonologically reduced through various processes       (e.g., assimilation) in fluent speech. the reduced forms of words give rise to       perceptual difficulties for nonnative speakers. this study examined whether       accent types (general american and received pronunciation (pr) british englishes)       of native english fluent speech affect fluent speech perception in chinese       speakers. a representative sample of sixty undergraduate students were tested       with listening comprehension tests (recordings produced by american and british       english speakers), reduced forms dictation test (with american- and       british-accented speech as stimuli) and fluent speech production task. based on       correlational analyses, it is shown that listening comprehension was       significantly correlated with both fluent speech perception and production skills       among the chinese speakers. importantly, these correlations were observed within       the same accent type and across the two accents. however, our regression analyses       showed that speech perception rather than production significantly predicted the       outcome of listening comprehension. 
the present research aimed at identifying cognitive processing       that works at the initial stage of letter identification. first, we used the word       superiority effect task to set the baseline of visual detection rate and then we       used the letter matching task to evaluate the phonemic transference rate of the       particpants. it was hypothesized that physically-different letters required       longer processing time as the judgment depended not only on visual detection, but       also on a process of phonemic transference. our results found that the control       group had a higher letter identification rate than the dyslexic group, showing       that visual detection rate was a good predictor of reading disability. however,       phonemic transference rate was not a good predictor of dyslexia. one of the       reasons may be that the process of letter identification involved cognitive       skills other than that of phonemic transference alone.
inflectional morphology has proven a test case for evaluating       theoretical approaches to language processing. the bulk of empirical data has       been acquired using the inflection from stem task, which approximates more       naturalistic speech production only if mandatory stem retrieval is assumed. yet       work with adults reveals quite different results when inflection proceeds instead       from meaning. connectionist computational models of inflection have simulated       these task differences, but the extent to which they accurately reflect       development remains unknown. for the first time, we consider the impact of task       type upon inflectional development of 908 children aged between 2 and 4 years. we       then present a revised version of a connectionist model of inflection, which has       been trained in a manner consistent with child directed speech in order to       capture the children’s performance. taken together, this work demonstrates       the progression of the field to more ecologically and developmentally valid       approaches to inflection.         
selective rehearsal of memories through conversation shapes       subsequent recall for both speakers and listeners. interactional memory acts have       typically been studied in dyadic conversation or small groups; however, as       christakis and fowler (2009) point out, humans don’t just belong to groups,       we are more precisely enmeshed in social networks. this study extends coman and       hirst’s (2012) work on propagation of socially-shared retrieval-induced       forgetting (cuc, koppel, and hirst, 2007) and social contagion (roediger, meade,       & bergman, 2001) across a series of conversations. we move from dyadic networks       to a dynamically self-assembling social network of 46 undergraduates over a       nine-week period. using a framework derived from kauffman’s (1994) models       of adaptive fitness landscapes in evolution, we trace mnemonic convergence as it       emerges from the interplay of “internal” cognitive factors and       dynamics attributable to network connectivity. contributions to the cognitive       psychology of collective memory are discussed. 
people have a strong confirmatory bias, which is remarkably       difficult to overcome. in this research, we investigated how we could help people       rectify the confirmatory bias, using wason(1960)’s 2-4-6 task. 195       university and middle school students participated in our study, in which they       were to find out the rule “increasing 3 numbers,” starting from the       2-4-6 number sequence. prior to the task, the participants were assigned to one       of the four training conditions: (1)“counter-examples”, in which       participants were instructed to create the positive and counter-examples for the       current hypothesis; (2) “two-hypotheses”, in which participants were       instructed to create examples for two different hypotheses; (3)       “counter-examples-and-two-hypotheses; (4) control, in which participants       were told to think about examples consistent with their hypothesis. we found that       the training to think counter-examples facilitates attempts to falsify the       current hypothesis and subsequent hypothesis change, but creating examples for       two different hypothesis did not.
this research presents a computational model that simulates       inference generation during reading comprehension. inferences refer to       information that readers generate from their background knowledge in order to       clarify, connect, and elaborate textual information. the computational model       integrates latent semantic analysis (lsa), which simulates general knowledge by       computing the strength of semantic association between concepts (landauer &       dumais, 1997), with the landscape model, a dynamic model of reading comprehension       that simulates fluctuations of concepts' activation and the emergence of episodic       connections between them (yeari and van den broek, 2011). the extended model was       used to simulate behavioral data from a large number of studies on inference       generation. successful simulations of the various findings demonstrate the unique       roles of semantic associations, episodic inter-textual relations, and working       memory (limitation of concepts' activation sum) in the activation of different       types of inferences (i.e., elaborative and bridging inferences).     
expected words/constituents are often processed faster than       unexpected words/constituents. in languages like english that verbs are placed       before arguments that they encode, the occurrence of verbs pre-activates upcoming       arguments, suggesting that verbs’ arguments are expected upon the       recognition of verbs. however, this is not the case for languages like korean       that verbs are placed after the arguments associated with verbs. this study       investigated whether argument order might play a role in cuing upcoming       arguments. using hong et al.’s materials, we conducted a completion study.       we found that patients were expected when recipients were introduced before,       whereas recipients were not expected when patients were introduced before,       suggesting that comprehenders might expect encountering patients after recipients       but not vice versa. the probability of patients/recipients was correlated with       the frequency of regressions that hong et al. observed. we will further examine       the role of probability and uncertainty in processing in terms of expectation.       
social-interactive cognition in russia builds on the ideas of       cultural-historical psychology by l. vygotsky, a. leontyev, a. luria, as well as       communicative aspect of cognition introduced by m. bakhtin in his theory of       dialogism which, in its turn, laid the ground for the studies of social and       situated cognition. since 1980-s cognitive-discursive paradigm in russia,       introduced by e. kubryakova, has attracted attention of cognitive science       scholars. within this paradigm cognitive approaches to pragmatics of       communication and agentivity have been developed (v.zabotkina, e. pozdnyakova).        the given study introduces further development of the field, based on a       multi-modal corpus built with recorded live communication data. presently       it’s the biggest multi-modal corpus of emotional communication, so it       ensures completeness and accuracy of research, conducted on its basis. two- and       three-dimensional computer agents (a. kotov) operate a set of speech patterns in       a complex of restricted communication situations, simulating real-life emotional       social interaction.
the aim of the study was to investigate confidence in       classification accuracy during category learning with three levels of       categorization difficulty based on a simple logical, conjunctive or complex rule.       twenty five psychology students participated in the study. stimuli were       geometrical figures that varied on three dimensions: shape, colour, and size. we       analysed differences in absolute accuracy of confidence judgments with respect to       task difficulty (three levels), learning phase (early, late) and performance       groups (slow and fast learners). for the simple logical task, we obtained a       significant main effect of phase and a significant interaction between phase and       group, suggesting that fast learners achieved higher accuracy earlier. for the       conjunctive task, the significant main effect of the group showed higher accuracy       of fast learners. for the complex task, there was a significant interaction       between phase and group showing that judgment accuracy in slow learners did not       improve during learning. 
we investigated the effects of strategy use and rule complexity on       multivariable inductive judgments. participants (n=274) made judgments about       which of two cars presented on a computer screen was faster. participants were       randomly assigned to a complex rule or a simple rule. for the complex rule, three       of five variables affected speed; for the simple rule one variable affected       speed. participants were instructed to make explicit (try to discover the rules       governing speed) or implicit (speeded intuitive) judgments for 300 trials with       feedback.        a 2 (complexity) x 2 (strategy instruction) anova revealed main effects of       complexity, f(1,270)=6.17, p=.014, and task instruction, f(1,270)=11.69, p=.001,       and a significant interaction, f(1,270)=7.38, p=.007. the explicit strategy led       to better performance for the simple rule only, but no differences were found for       the implicit strategy. these findings run counter to recent work showing an       advantage for implicit processing of complex rules (zimmerman & pretz, 2012).
when people judge whether others are telling the truth, they act       differently if they are working alone or in a group. the current experiment       explored this finding. participants (working alone or in pairs) provided either a       binary truth/lie decision, or a binary decision and a set of reasons chosen from       a list, or an open ended discussion/explanation. being alone or in a pair had no       significant effect on accuracy, but confidence was higher in pairs. a truth bias       was found in the single condition but was eliminated for pairs when they       specified a reason or had a discussion. accuracy was highest when stating a       reason chosen from a list, while confidence increased with the amount of       information provided. these findings improve our understanding of the effect of       pair decision making, illustrating how varying levels of information can have       different effect on decision making and deception detection.
